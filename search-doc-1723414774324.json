{"searchDocs":[{"title":"Advanced topic in SQL","type":0,"sectionRef":"#","url":"/2023/12/25/Advanced-Topics-in-SQL","content":"","keywords":"","version":null},{"title":"SQL Clauses​","type":1,"pageTitle":"Advanced topic in SQL","url":"/2023/12/25/Advanced-Topics-in-SQL#sql-clauses","content":"WHERE, ORDER BY, GROUP BY, and HAVING: Crafting strategic queries.Today's exploration: INNER JOIN, OUTER JOIN, EXCLUDING JOIN, SELF JOIN, CROSS JOIN, UNION, and UNION ALL. ","version":null,"tagName":"h2"},{"title":"Why Do We Need JOIN?​","type":1,"pageTitle":"Advanced topic in SQL","url":"/2023/12/25/Advanced-Topics-in-SQL#why-do-we-need-join","content":"Combining data from multiple tables based on matching conditions for comprehensive analysis. ","version":null,"tagName":"h2"},{"title":"INNER JOIN: A Deeper Dive​","type":1,"pageTitle":"Advanced topic in SQL","url":"/2023/12/25/Advanced-Topics-in-SQL#inner-join-a-deeper-dive","content":"-- Example of INNER JOIN SELECT c.CustomerID, c.FullName, o.FoodName FROM Customer c INNER JOIN CustomerOrder o ON c.CustomerID = o.CustomerID;  In this practice, we retrieve customer information along with their corresponding orders using INNER JOIN. ","version":null,"tagName":"h2"},{"title":"JOIN More Than 2 Tables​","type":1,"pageTitle":"Advanced topic in SQL","url":"/2023/12/25/Advanced-Topics-in-SQL#join-more-than-2-tables","content":"-- Example of INNER JOIN with 3 tables SELECT c.CustomerID, c.FullName, o.FoodName, d.FullAddress FROM Customer c INNER JOIN CustomerOrder o ON c.CustomerID = o.CustomerID INNER JOIN DeliveryAddress d ON d.ID = o.DeliveryAddressID;  Extending the concept of INNER JOIN to involve three tables for a more comprehensive result set. ","version":null,"tagName":"h2"},{"title":"LEFT JOIN: Embracing Incompleteness​","type":1,"pageTitle":"Advanced topic in SQL","url":"/2023/12/25/Advanced-Topics-in-SQL#left-join-embracing-incompleteness","content":"-- Example of LEFT JOIN SELECT c.CustomerID, c.FullName, o.FoodName FROM Customer c LEFT JOIN CustomerOrder o ON c.CustomerID = o.CustomerID;  Incorporating LEFT JOIN to include all customers, even those without orders. ","version":null,"tagName":"h2"},{"title":"RIGHT JOIN: Balancing the Equation​","type":1,"pageTitle":"Advanced topic in SQL","url":"/2023/12/25/Advanced-Topics-in-SQL#right-join-balancing-the-equation","content":"-- Example of RIGHT JOIN SELECT c.CustomerID, c.FullName, o.FoodName FROM Customer c RIGHT JOIN CustomerOrder o ON c.CustomerID = o.CustomerID;  Implementing RIGHT JOIN to include all orders, even those without customers. ","version":null,"tagName":"h2"},{"title":"FULL JOIN: Embracing Completeness​","type":1,"pageTitle":"Advanced topic in SQL","url":"/2023/12/25/Advanced-Topics-in-SQL#full-join-embracing-completeness","content":"-- Example of FULL JOIN SELECT c.CustomerID, c.FullName, o.FoodName FROM Customer c FULL JOIN CustomerOrder o ON c.CustomerID = o.CustomerID;  Utilizing FULL JOIN to encompass all customers and orders, regardless of matches. ","version":null,"tagName":"h2"},{"title":"LEFT EXCLUDING JOIN: Seeking the Unique​","type":1,"pageTitle":"Advanced topic in SQL","url":"/2023/12/25/Advanced-Topics-in-SQL#left-excluding-join-seeking-the-unique","content":"-- Example of LEFT EXCLUDING JOIN SELECT c.CustomerID, c.FullName, o.FoodName FROM Customer c LEFT JOIN CustomerOrder o ON c.CustomerID = o.CustomerID WHERE o.CustomerID IS NULL;  Applying LEFT EXCLUDING JOIN to identify customers without orders. ","version":null,"tagName":"h2"},{"title":"RIGHT EXCLUDING JOIN: Excluding to the Right​","type":1,"pageTitle":"Advanced topic in SQL","url":"/2023/12/25/Advanced-Topics-in-SQL#right-excluding-join-excluding-to-the-right","content":"-- Example of RIGHT EXCLUDING JOIN SELECT c.CustomerID, c.FullName, o.FoodName FROM Customer c RIGHT JOIN CustomerOrder o ON c.CustomerID = o.CustomerID WHERE c.CustomerID IS NULL;  Implementing RIGHT EXCLUDING JOIN to identify orders without customers. ","version":null,"tagName":"h2"},{"title":"OUTER EXCLUDING JOIN: Excluding in Unison​","type":1,"pageTitle":"Advanced topic in SQL","url":"/2023/12/25/Advanced-Topics-in-SQL#outer-excluding-join-excluding-in-unison","content":"-- Example of OUTER EXCLUDING JOIN SELECT c.CustomerID, c.FullName, o.FoodName FROM Customer c FULL JOIN CustomerOrder o ON c.CustomerID = o.CustomerID WHERE c.CustomerID IS NULL OR o.CustomerID IS NULL;  Integrating OUTER EXCLUDING JOIN to identify unmatched records from both tables. ","version":null,"tagName":"h2"},{"title":"SELF JOIN: Connecting Within​","type":1,"pageTitle":"Advanced topic in SQL","url":"/2023/12/25/Advanced-Topics-in-SQL#self-join-connecting-within","content":"-- Example of SELF JOIN SELECT emp.ID, emp.FullName, manager.FullName AS Manager FROM Employee emp INNER JOIN Employee manager ON emp.ManagerID = manager.ID;  Demonstrating the concept of SELF JOIN to connect records within the same table. ","version":null,"tagName":"h2"},{"title":"CROSS JOIN: Expanding Horizons​","type":1,"pageTitle":"Advanced topic in SQL","url":"/2023/12/25/Advanced-Topics-in-SQL#cross-join-expanding-horizons","content":"-- Example of CROSS JOIN SELECT * FROM A CROSS JOIN B;  Expanding horizons with CROSS JOIN to combine each row from one table with each row from another. ","version":null,"tagName":"h2"},{"title":"UNION: Merging Similarities​","type":1,"pageTitle":"Advanced topic in SQL","url":"/2023/12/25/Advanced-Topics-in-SQL#union-merging-similarities","content":"-- Example of UNION SELECT FromColumnTableA FROM A UNION SELECT FromColumnTableB FROM B;  Merging similarities with UNION to combine result-sets from two tables. ","version":null,"tagName":"h2"},{"title":"UNION ALL: Embracing All​","type":1,"pageTitle":"Advanced topic in SQL","url":"/2023/12/25/Advanced-Topics-in-SQL#union-all-embracing-all","content":"-- Example of UNION ALL SELECT FromColumnTableA FROM A UNION ALL SELECT FromColumnTableB FROM B;  Embracing all with UNION ALL, including duplicates in the result set. ","version":null,"tagName":"h2"},{"title":"Sub Queries and Advanced Operators​","type":1,"pageTitle":"Advanced topic in SQL","url":"/2023/12/25/Advanced-Topics-in-SQL#sub-queries-and-advanced-operators","content":"Exploring the power of subqueries.Advanced operators: EXISTS, ALL, IN, ANY. ","version":null,"tagName":"h2"},{"title":"What We Will Explore Today?​","type":1,"pageTitle":"Advanced topic in SQL","url":"/2023/12/25/Advanced-Topics-in-SQL#what-we-will-explore-today","content":"Sub queries, advanced operators, rules of subqueries, and practical exercises. ","version":null,"tagName":"h2"},{"title":"Subquery Basics​","type":1,"pageTitle":"Advanced topic in SQL","url":"/2023/12/25/Advanced-Topics-in-SQL#subquery-basics","content":"A sub-query, or inner query, nested inside a larger query.Works independently within the outer query.Execution sequence: Inner query executes first, results stored, and outer query runs on stored results.Exception: Correlated subqueries reference outer query columns. ","version":null,"tagName":"h2"},{"title":"Example 1: Subquery for Average​","type":1,"pageTitle":"Advanced topic in SQL","url":"/2023/12/25/Advanced-Topics-in-SQL#example-1-subquery-for-average","content":"-- Example of Subquery USE LECTURE4_FUNCTION SELECT LastName, Physic, (SELECT AVG(Physic * 1.0) FROM Student) AS 'AVG OF Physic' FROM Student;  ","version":null,"tagName":"h2"},{"title":"Example 2: Subquery in WHERE Clause​","type":1,"pageTitle":"Advanced topic in SQL","url":"/2023/12/25/Advanced-Topics-in-SQL#example-2-subquery-in-where-clause","content":"-- Example of Subquery in WHERE USE LECTURE5_JOIN_DEMO SELECT CustomerID, FullName FROM Customer WHERE CustomerID IN (SELECT CustomerID FROM CustomerOrder);  ","version":null,"tagName":"h2"},{"title":"Types of Subqueries​","type":1,"pageTitle":"Advanced topic in SQL","url":"/2023/12/25/Advanced-Topics-in-SQL#types-of-subqueries","content":"Single-row subquery.Multiple-row subquery.Multiple-column subquery.Correlated subquery.Nested subquery. ","version":null,"tagName":"h2"},{"title":"Single-Row Subquery​","type":1,"pageTitle":"Advanced topic in SQL","url":"/2023/12/25/Advanced-Topics-in-SQL#single-row-subquery","content":"-- Example of Single-Row Subquery USE LECTURE5_JOIN_DEMO; SELECT CustomerID, FullName FROM Customer WHERE CustomerID = (SELECT CustomerID FROM CustomerOrder WHERE FoodName = 'Heo Quay');  ","version":null,"tagName":"h2"},{"title":"Exercise: Single-Row Subquery​","type":1,"pageTitle":"Advanced topic in SQL","url":"/2023/12/25/Advanced-Topics-in-SQL#exercise-single-row-subquery","content":"Query CustomerID, OrderID, FoodName from CustomerOrder with Delivery FullAddress = 'TP. HCM' using a single-row subquery. ","version":null,"tagName":"h2"},{"title":"Multiple-Row Subquery​","type":1,"pageTitle":"Advanced topic in SQL","url":"/2023/12/25/Advanced-Topics-in-SQL#multiple-row-subquery","content":"-- Example of Multiple-Row Subquery USE LECTURE5_JOIN_DEMO SELECT CustomerID, FullName FROM Customer WHERE CustomerID IN (SELECT CustomerID FROM CustomerOrder);  ","version":null,"tagName":"h2"},{"title":"Exercise: Multiple-Row Subquery​","type":1,"pageTitle":"Advanced topic in SQL","url":"/2023/12/25/Advanced-Topics-in-SQL#exercise-multiple-row-subquery","content":"Query CustomerID, OrderID, FoodName from CustomerOrder with Delivery FullAddress = 'TP. HCM' or 'TP. HA NOI' using a multiple-row subquery. ","version":null,"tagName":"h2"},{"title":"Multiple-Column Subquery​","type":1,"pageTitle":"Advanced topic in SQL","url":"/2023/12/25/Advanced-Topics-in-SQL#multiple-column-subquery","content":"-- Example of Multiple-Column Subquery USE LECTURE5_JOIN_DEMO; SELECT CustomerID, FullName FROM Customer WHERE EXISTS (SELECT CustomerID, OrderID, FoodName FROM CustomerOrder WHERE CustomerOrder.CustomerID = Customer.CustomerID);  ","version":null,"tagName":"h2"},{"title":"Exercise: Multiple-Column Subquery​","type":1,"pageTitle":"Advanced topic in SQL","url":"/2023/12/25/Advanced-Topics-in-SQL#exercise-multiple-column-subquery","content":"Create a database, perform a self-join on the Employee table, and query managers with at least 1 employee. ","version":null,"tagName":"h2"},{"title":"Correlated Subquery​","type":1,"pageTitle":"Advanced topic in SQL","url":"/2023/12/25/Advanced-Topics-in-SQL#correlated-subquery","content":"Normal subquery executes first and provides a value to the outer query.Correlated subquery references a column in the outer query and executes the subquery once for each row in the outer query. -- Example of Correlated Subquery USE LECTURE5_JOIN_DEMO; SELECT CustomerID, FullName FROM Customer WHERE EXISTS (SELECT CustomerID, OrderID, FoodName FROM CustomerOrder WHERE CustomerOrder.CustomerID = Customer.CustomerID);  ","version":null,"tagName":"h2"},{"title":"Exercise: Correlated Subquery​","type":1,"pageTitle":"Advanced topic in SQL","url":"/2023/12/25/Advanced-Topics-in-SQL#exercise-correlated-subquery","content":"Create a database, perform a self-join on the Employee table, and query managers with at least 1 employee. ","version":null,"tagName":"h2"},{"title":"Nested Subquery​","type":1,"pageTitle":"Advanced topic in SQL","url":"/2023/12/25/Advanced-Topics-in-SQL#nested-subquery","content":"-- Example of Nested Subquery USE LECTURE5_JOIN_DEMO; SELECT CustomerID, FullName FROM Customer WHERE CustomerID IN (SELECT CustomerID FROM CustomerOrder WHERE DeliveryAddressID = (SELECT ID FROM DeliveryAddress WHERE FullAddress = 'TP. HA NOI'));  ","version":null,"tagName":"h2"},{"title":"Rules of Subqueries​","type":1,"pageTitle":"Advanced topic in SQL","url":"/2023/12/25/Advanced-Topics-in-SQL#rules-of-subqueries","content":"Enclose a subquery in parentheses.Must include a SELECT clause and a FROM clause.Subqueries that return more than one row can only be used with multiple-value operators.Can include WHERE, GROUP BY, and HAVING clauses.Can include an ORDER BY clause only with a TOP clause.Can nest subqueries up to 32 levels. ","version":null,"tagName":"h2"},{"title":"Advanced Operators: EXISTS​","type":1,"pageTitle":"Advanced topic in SQL","url":"/2023/12/25/Advanced-Topics-in-SQL#advanced-operators-exists","content":"Used to test for the existence of any record in a subquery. -- Example of EXISTS USE LECTURE5_JOIN_DEMO; SELECT CustomerID, FullName FROM Customer WHERE EXISTS (SELECT CustomerID, OrderID, FoodName FROM CustomerOrder WHERE CustomerOrder.CustomerID = Customer.CustomerID);  ","version":null,"tagName":"h2"},{"title":"Advanced Operators: ALL​","type":1,"pageTitle":"Advanced topic in SQL","url":"/2023/12/25/Advanced-Topics-in-SQL#advanced-operators-all","content":"Returns TRUE if ALL of the subquery values meet the condition. -- Example of ALL USE LECTURE5_JOIN_DEMO; SELECT CustomerID, FullName FROM Customer WHERE CustomerID = ALL (SELECT CustomerID FROM CustomerOrder);  ","version":null,"tagName":"h2"},{"title":"Advanced Operators: IN​","type":1,"pageTitle":"Advanced topic in SQL","url":"/2023/12/25/Advanced-Topics-in-SQL#advanced-operators-in","content":"Allows specifying multiple values in a WHERE clause. -- Example of IN USE LECTURE5_JOIN_DEMO; SELECT CustomerID, FullName FROM Customer WHERE CustomerID IN (SELECT CustomerID FROM CustomerOrder);  ","version":null,"tagName":"h2"},{"title":"Advanced Operators: ANY​","type":1,"pageTitle":"Advanced topic in SQL","url":"/2023/12/25/Advanced-Topics-in-SQL#advanced-operators-any","content":"Allows performing a comparison between a single column value and a range of other values. -- Example of ANY USE LECTURE5_JOIN_DEMO; SELECT CustomerID, FullName FROM Customer WHERE CustomerID = ANY (SELECT CustomerID FROM CustomerOrder);  ","version":null,"tagName":"h2"},{"title":"Entity framework core","type":0,"sectionRef":"#","url":"/2024/1/18/EF-core","content":"","keywords":"","version":null},{"title":"Introduction​","type":1,"pageTitle":"Entity framework core","url":"/2024/1/18/EF-core#introduction","content":"Entity Framework Core is an ORM framework, open-source, lightweight and cross-platform developed by Microsoft.It enables developers to work with databases using .NET object and EF Core is built on top of ADO.NET ","version":null,"tagName":"h2"},{"title":"Relationship​","type":1,"pageTitle":"Entity framework core","url":"/2024/1/18/EF-core#relationship","content":"","version":null,"tagName":"h2"},{"title":"One-to-One Relationship​","type":1,"pageTitle":"Entity framework core","url":"/2024/1/18/EF-core#one-to-one-relationship","content":"modelBuilder.Entity&lt;Author&gt;() .HasOne(a =&gt; a.Book) // Author has one Book .WithOne(b =&gt; b.Author) // Book has one Author .HasForeignKey&lt;Book&gt;(b =&gt; b.AuthorId); // Foreign key in Book referencing AuthorId  ","version":null,"tagName":"h3"},{"title":"One-to-Many Relationship​","type":1,"pageTitle":"Entity framework core","url":"/2024/1/18/EF-core#one-to-many-relationship","content":"modelBuilder.Entity&lt;Author&gt;() .HasMany(a =&gt; a.Books) // Author has many Books .WithOne(b =&gt; b.Author) // Book has one Author .HasForeignKey(b =&gt; b.AuthorId); // Foreign key in Book referencing AuthorId  ","version":null,"tagName":"h3"},{"title":"Many-to-Many Relationship​","type":1,"pageTitle":"Entity framework core","url":"/2024/1/18/EF-core#many-to-many-relationship","content":"modelBuilder.Entity&lt;StudentCourse&gt;() .HasKey(sc =&gt; new { sc.StudentId, sc.CourseId }); // Define composite primary key for the join table modelBuilder.Entity&lt;StudentCourse&gt;() .HasOne(sc =&gt; sc.Student) .WithMany(s =&gt; s.Courses) .HasForeignKey(sc =&gt; sc.StudentId); // Foreign key in join table referencing StudentId modelBuilder.Entity&lt;StudentCourse&gt;() .HasOne(sc =&gt; sc.Course) .WithMany(c =&gt; c.Students) .HasForeignKey(sc =&gt; sc.CourseId); // Foreign key in join table referencing CourseId  ","version":null,"tagName":"h3"},{"title":"DeleteBehavior​","type":1,"pageTitle":"Entity framework core","url":"/2024/1/18/EF-core#deletebehavior","content":"The DeleteBehavior enum in EF Core includes the following options: Cascade: Deleting the principal/parent entity will cause the dependent/child entities to be deleted as well. OnDelete(DeleteBehavior.Cascade) SetNull: Deleting the principal/parent entity will set the foreign key properties in the dependent/child entities to null. OnDelete(DeleteBehavior.SetNull) SetDefault: Deleting the principal/parent entity will set the foreign key properties in the dependent/child entities to their default values. OnDelete(DeleteBehavior.SetDefault) Restrict: Prevents the deletion of the principal/parent entity if there are dependent/child entities. OnDelete(DeleteBehavior.Restrict) . An exception will be thrown. NoAction: Similar to Restrict, it is used to specify no action on delete. OnDelete(DeleteBehavior.NoAction) and you'll need to handle constraints in your application logic. For example: modelBuilder.Entity&lt;ParentEntity&gt;() .HasMany(p =&gt; p.ChildEntities) .WithOne(c =&gt; c.ParentEntity) .OnDelete(DeleteBehavior.Restrict);  This configuration would set the delete behavior for the relationship between ParentEntity and ChildEntity to Restrict. ","version":null,"tagName":"h2"},{"title":"Best pratices​","type":1,"pageTitle":"Entity framework core","url":"/2024/1/18/EF-core#best-pratices","content":"Indexing: Creating indexes on frequently accessed columns can improve query performance. Proper data modeling: Designing tables and relationships properly can improve query performance and prevent performance issues. Caching: Storing frequently accessed data in a cache can reduce database calls and improve application performance. Query optimization: Writing efficient queries can improve performance. Techniques such as avoiding unnecessary joins and reducing the number of returned columns can help. Connection pooling: Reusing database connections instead of creating new ones can improve performance. Batch processing: Performing multiple operations in a single database call can improve performance and reduce overhead. Asynchronous programming: Using asynchronous programming techniques can improve performance by allowing the application to continue executing while waiting for database calls to complete. ","version":null,"tagName":"h2"},{"title":"Data structure and algorithms","type":0,"sectionRef":"#","url":"/2024/2/28/data-structure-and-algorithms","content":"","keywords":"","version":null},{"title":"State 1 • 4 weeks​","type":1,"pageTitle":"Data structure and algorithms","url":"/2024/2/28/data-structure-and-algorithms#state-1--4-weeks","content":"Lesson 1: Introduction to Data Structures Introduction to the Data Structures course.Lesson 2: Arrays and Linked Lists Learn about Arrays and Linked ListsLesson 3: Stacks and Queues Build Stacks and QueuesLesson 4: Recursion Apply Recursion to ProblemsLesson 5: Trees Learn about basic tree's, tree traversal and binary search trees.Lesson 6: Maps and Hashing Explore the concepts of maps and hashes.Lesson 7 • Project: Show Me the Data Structures Solve a series of open-ended practice problems. Hone your skills to identify and implement appropriate data structures and corresponding methods that meet given constraints. ","version":null,"tagName":"h2"},{"title":"State 2 • 4 weeks​","type":1,"pageTitle":"Data structure and algorithms","url":"/2024/2/28/data-structure-and-algorithms#state-2--4-weeks","content":"Basic Algorithms Learn about the basic algorithms used in programming. Lesson 1: Basic Algorithms Start out with some elementary algorithms such as binary search, tries, heaps and more.Lesson 2: Sorting Algorithms Learn about the most common sorting algorithms.Lesson 3: Faster Divide &amp; Conquer Algorithms Go deeper into algorithms with faster divide and conquer algorithms.Lesson 4 • Project: Problems vs. Algorithms A series of real-world open ended problems which train you to apply suitable data structures and algorithms under different context. ","version":null,"tagName":"h2"},{"title":"State 3 • 4 weeks​","type":1,"pageTitle":"Data structure and algorithms","url":"/2024/2/28/data-structure-and-algorithms#state-3--4-weeks","content":"Advanced Algorithms Learn about the basic algorithms used in programming. Lesson 1: Greedy Algorithms Get familiar with and practice greedy algorithms.Lesson 2: Graph Algorithms Learn about the many aspects of graph algorithms!Lesson 3: Dynamic Programming Learn about dynamic programming and apply your learnings to challenging exercises.Lesson 4: A*Lesson 5 • Project: Route Planner ","version":null,"tagName":"h2"},{"title":"Exploring Dynamic Distance Calculation with Delegates: A Proof of Concept","type":0,"sectionRef":"#","url":"/2024/1/18/Delegate","content":"","keywords":"","version":null},{"title":"Why Delegates?​","type":1,"pageTitle":"Exploring Dynamic Distance Calculation with Delegates: A Proof of Concept","url":"/2024/1/18/Delegate#why-delegates","content":"Delegates in C# are powerful constructs that allow us to treat methods as first-class citizens. Leveraging this capability, our PoC demonstrates how to dynamically resolve distance calculation services at runtime. This flexibility opens the door to easily switch between different providers based on specific conditions or user preferences. ","version":null,"tagName":"h2"},{"title":"Key Features​","type":1,"pageTitle":"Exploring Dynamic Distance Calculation with Delegates: A Proof of Concept","url":"/2024/1/18/Delegate#key-features","content":"","version":null,"tagName":"h2"},{"title":"Dynamic Resolution with Delegates​","type":1,"pageTitle":"Exploring Dynamic Distance Calculation with Delegates: A Proof of Concept","url":"/2024/1/18/Delegate#dynamic-resolution-with-delegates","content":"The heart of this project lies in the DistanceCalculator class, which uses a delegate (DistanceProviderResolver) to dynamically resolve the distance calculation service. This allows us to switch between Google and PCMiler providers with ease, providing a seamless and extensible solution. var distanceCalculator = new DistanceCalculator(); var distanceService = distanceCalculator.ResolveDistanceProvider(DistanceProvider.Google); double distance = distanceService.CalculateDistance(&quot;Origin&quot;, &quot;Destination&quot;);  ","version":null,"tagName":"h3"},{"title":"Configurability​","type":1,"pageTitle":"Exploring Dynamic Distance Calculation with Delegates: A Proof of Concept","url":"/2024/1/18/Delegate#configurability","content":"Experiment with different distance calculation providers by customizing the Program.cs file. This configurability makes it easy to adapt the PoC to various scenarios and requirements. ","version":null,"tagName":"h3"},{"title":"Limitations and Roadmap​","type":1,"pageTitle":"Exploring Dynamic Distance Calculation with Delegates: A Proof of Concept","url":"/2024/1/18/Delegate#limitations-and-roadmap","content":"As a Proof of Concept, it's important to note that this project currently uses simulated distance calculation logic with dummy values. While it showcases the concept effectively, it may lack certain features expected in a production-ready application. We encourage you to explore, experiment, and contribute. If you encounter issues or have ideas for improvements, please open an issue on our GitHub repository. ","version":null,"tagName":"h2"},{"title":"Demo​","type":1,"pageTitle":"Exploring Dynamic Distance Calculation with Delegates: A Proof of Concept","url":"/2024/1/18/Delegate#demo","content":"Clone the Repository : git clone https://github.com/nhonvo/delegate-poc.git cd delegate-poc  ","version":null,"tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"Exploring Dynamic Distance Calculation with Delegates: A Proof of Concept","url":"/2024/1/18/Delegate#conclusion","content":"Dynamic distance calculation with delegates offers a glimpse into the world of flexible and configurable service resolution. We hope this PoC sparks ideas and discussions about how such a concept could be integrated into real-world applications. Feel free to dive into the code, contribute your insights, and join us on this exploration of dynamic resolution in C#. Happy coding! ","version":null,"tagName":"h2"},{"title":"gitflow-and-githubflow","type":0,"sectionRef":"#","url":"/2023/12/31/gitflow-and-githubflow","content":"","keywords":"","version":null},{"title":"docker command","type":0,"sectionRef":"#","url":"/2023/12/29/docker-cheatsheet","content":"","keywords":"","version":null},{"title":"Images​","type":1,"pageTitle":"docker command","url":"/2023/12/29/docker-cheatsheet#images","content":"docker images # List all images docker pull &lt;image_name&gt; # Pull an image from Docker Hub docker build -t &lt;image_name&gt; . # Build an image from the current directory docker rmi &lt;image_id&gt; # Remove an image  ","version":null,"tagName":"h2"},{"title":"Containers​","type":1,"pageTitle":"docker command","url":"/2023/12/29/docker-cheatsheet#containers","content":"docker ps # List running containers docker ps -a # List all containers docker run &lt;image_name&gt; # Create and start a container docker exec -it &lt;container_id&gt; bash # Access a running container's shell docker stop &lt;container_id&gt; # Stop a running container docker rm &lt;container_id&gt; # Remove a container  ","version":null,"tagName":"h2"},{"title":"Volumes​","type":1,"pageTitle":"docker command","url":"/2023/12/29/docker-cheatsheet#volumes","content":"docker volume ls # List all volumes docker volume create &lt;volume_name&gt; # Create a volume docker run -v &lt;volume_name&gt;:/path/in/container &lt;image_name&gt; # Mount a volume to a container  ","version":null,"tagName":"h2"},{"title":"Networks​","type":1,"pageTitle":"docker command","url":"/2023/12/29/docker-cheatsheet#networks","content":"docker network ls # List all networks docker network create &lt;network_name&gt; # Create a network docker run --network=&lt;network_name&gt; &lt;image_name&gt; # Connect a container to a network  ","version":null,"tagName":"h2"},{"title":"Compose​","type":1,"pageTitle":"docker command","url":"/2023/12/29/docker-cheatsheet#compose","content":"docker-compose up # Start services defined in a docker-compose.yml docker-compose down # Stop and remove services defined in a docker-compose.yml  ","version":null,"tagName":"h2"},{"title":"Registry​","type":1,"pageTitle":"docker command","url":"/2023/12/29/docker-cheatsheet#registry","content":"docker login # Log in to a Docker registry docker push &lt;image_name&gt; # Push an image to a registry docker pull &lt;registry&gt;/&lt;image_name&gt; # Pull an image from a registry  ","version":null,"tagName":"h2"},{"title":"System​","type":1,"pageTitle":"docker command","url":"/2023/12/29/docker-cheatsheet#system","content":"docker info # Display system-wide information docker version # Show the Docker version docker system prune # Remove all stopped containers, unused networks, and dangling images  ","version":null,"tagName":"h2"},{"title":"Dockerize Applications​","type":1,"pageTitle":"docker command","url":"/2023/12/29/docker-cheatsheet#dockerize-applications","content":"docker build -t &lt;image_name&gt; . # Build a Docker image docker run -p &lt;host_port&gt;:&lt;container_port&gt; &lt;image_name&gt; # Run a Docker container  ","version":null,"tagName":"h2"},{"title":"Hangfire - Enqueueing Background Jobs","type":0,"sectionRef":"#","url":"/2024/2/8/hangfire","content":"","keywords":"","version":null},{"title":"Getting Started​","type":1,"pageTitle":"Hangfire - Enqueueing Background Jobs","url":"/2024/2/8/hangfire#getting-started","content":"Hangfire provides a straightforward way to execute background tasks using a fire-and-forget approach. Let's look at a quick example: BackgroundJob.Enqueue(() =&gt; Console.WriteLine(&quot;Hello, world!&quot;));  In this example, BackgroundJob.Enqueue is used to queue a background job that prints &quot;Hello, world!&quot; to the console. The job is not executed immediately; instead, it goes through a serialization process and is stored persistently. ","version":null,"tagName":"h2"},{"title":"The Hangfire Workflow​","type":1,"pageTitle":"Hangfire - Enqueueing Background Jobs","url":"/2024/2/8/hangfire#the-hangfire-workflow","content":"Hangfire operates on a workflow that involves the following key components: Enqueuing Jobs: Jobs are enqueued using BackgroundJob.Enqueue.The method and its arguments are serialized, creating a background job. Persistent Storage: The serialized job information is stored in a persistent storage (e.g., a database). Hangfire Server: The Hangfire Server continually checks the persistent storage for enqueued jobs.It performs the jobs in a reliable way, ensuring they are executed even if the process is terminated during execution. Worker Threads: Enqueued jobs are handled by a dedicated pool of worker threads.Each worker fetches, performs, and removes jobs from the queue. Guaranteed Processing: Jobs are only removed from the queue after successful processing.Hangfire includes compensation logic to guarantee the processing of each job. BackgroundJob.Enqueue(() =&gt; Console.WriteLine(&quot;Hello, world!&quot;)) graph TD subgraph Enqueue A[User] --&gt;|Enqueue| B[print `hello world` jobs] end subgraph Background Job Processing B --&gt;|Serialize| C[Create Background Job] C --&gt;|Save to Storage| D[Persistent Storage] D --&gt;|Enqueue| E[Queue] end subgraph Hangfire Server E --&gt;|Check for Jobs| F[Hangfire Server] end subgraph Worker Threads F --&gt;|Fetch Job| G[Worker Thread] G --&gt;|Perform Job| H[Perform Job and Filters] H --&gt;|Remove from Queue| I[Remove Job from Queue] end  ","version":null,"tagName":"h2"},{"title":"Benefits of Hangfire​","type":1,"pageTitle":"Hangfire - Enqueueing Background Jobs","url":"/2024/2/8/hangfire#benefits-of-hangfire","content":"Hangfire offers several advantages for background job processing: Simplicity: Enqueuing jobs is as simple as passing a lambda expression.Reliability: Jobs are processed reliably, even in the face of process terminations.Asynchronous Execution: Background tasks can be executed asynchronously, improving application responsiveness.Monitoring and Management: Hangfire provides a dashboard for monitoring and managing background jobs. ","version":null,"tagName":"h2"},{"title":"Design-database","type":0,"sectionRef":"#","url":"/2024/2/6/Design-database","content":"","keywords":"","version":null},{"title":"Mongo with csharp","type":0,"sectionRef":"#","url":"/2024/3/1/mongo-with-csharp","content":"","keywords":"","version":null},{"title":"Working with MongoDB Documents in Csharp​","type":1,"pageTitle":"Mongo with csharp","url":"/2024/3/1/mongo-with-csharp#working-with-mongodb-documents-in-csharp","content":"Review the following code, which demonstrates how to represent a document in Csharp. ","version":null,"tagName":"h2"},{"title":"BsonDocument​","type":1,"pageTitle":"Mongo with csharp","url":"/2024/3/1/mongo-with-csharp#bsondocument","content":"Use MongoDB.Bson to represent a document with BsonDocument. Here's an example: using MongoDB.Bson; var document = new BsonDocument { { &quot;account_id&quot;, &quot;MDB829001337&quot; }, { &quot;account_holder&quot;, &quot;Linus Torvalds&quot; }, { &quot;account_type&quot;, &quot;checking&quot; }, { &quot;balance&quot;, 50352434 } };  ","version":null,"tagName":"h3"},{"title":"Csharp Class (POCOs)​","type":1,"pageTitle":"Mongo with csharp","url":"/2024/3/1/mongo-with-csharp#csharp-class-pocos","content":"Each public property maps to a field in the BSON document. The BsonId attribute specifies a field that must always be unique.The BsonRepresentation attribute maps a Csharp type to a specific BSON type.The BsonElement attribute maps to the BSON field name. Here's an example: internal class Account { [BsonId] [BsonRepresentation(MongoDB.Bson.BsonType.ObjectId)] public string Id { get; set; } [BsonElement(&quot;account_id&quot;)] public string AccountId { get; set; } [BsonElement(&quot;account_holder&quot;)] public string AccountHolder { get; set; } [BsonElement(&quot;account_type&quot;)] public string AccountType { get; set; } [BsonRepresentation(BsonType.Decimal128)] [BsonElement(&quot;balance&quot;)] public decimal Balance { get; set; } [BsonElement(&quot;transfers_complete&quot;)] public string[] TransfersCompleted { get; set; } }   ","version":null,"tagName":"h3"},{"title":"Using MongoDB Aggregation Stages with Csharp: Match and Group​","type":1,"pageTitle":"Mongo with csharp","url":"/2024/3/1/mongo-with-csharp#using-mongodb-aggregation-stages-with-csharp-match-and-group","content":"Review the following code, which demonstrates how to use the Match and Group aggregation methods in MongoDB. ","version":null,"tagName":"h2"},{"title":"Match by Using Csharp Class​","type":1,"pageTitle":"Mongo with csharp","url":"/2024/3/1/mongo-with-csharp#match-by-using-csharp-class","content":"Match filters documents that match the specified conditions and passes them to the next stage of the pipeline. In following code, we request all documents where the Balance field has a value that's less than or equal to 1000. We can view the results by casting the aggregate object to a list. var matchStage = Builders&lt;Accounts&gt;.Filter.Lte(u =&gt; u.Balance, 1000); var aggregate = accountsCollection.Aggregate() .Match(matchStage); var results = aggregate.ToList(); foreach (var account in results) { Console.WriteLine(account.Balance); }  ","version":null,"tagName":"h3"},{"title":"Match by Using BsonDocument​","type":1,"pageTitle":"Mongo with csharp","url":"/2024/3/1/mongo-with-csharp#match-by-using-bsondocument","content":"Match filters documents that match the specified conditions to the next stage of the pipeline. When you're working with BsonDocuments, the process is identical, except that we use a builder of type BsonDocument. Also, we can’t use LINQ to define the properties that we want to filter on. Here's an example: var matchStage = Builders&lt;BsonDocument&gt;.Filter.Lte(&quot;balance&quot;, 1000); var aggregate = accountsCollection.Aggregate() .Match(matchStage); var results = aggregate.ToList(); foreach (var account in results) { Console.WriteLine(account.Balance); }  ","version":null,"tagName":"h3"},{"title":"Group Stage​","type":1,"pageTitle":"Mongo with csharp","url":"/2024/3/1/mongo-with-csharp#group-stage","content":"The Group stage separates documents into groups according to a group key. The output of this stage is one document for each unique group key. In the following code, we use a LINQ expression and create a new generic object with the fields we want. We keep the same names for the first three properties: AccountId, AccountType, and Balance. We also create a new field called GBP, which is calculated by dividing the current Balance field by 1.3. var matchStage = Builders&lt;BsonDocument&gt;.Filter.Lte(&quot;balance&quot;, 1000); var aggregate = accountCollection.Aggregate() .Match(matchStage) .Group( a =&gt; a.AccountType, r =&gt; new { accountType = r.Key, total = r.Sum(a =&gt; 1) } ); var results = aggregate.ToList(); foreach (var account in results) { Console.WriteLine(account.Balance); }   ","version":null,"tagName":"h3"},{"title":"Querying a MongoDB Collection in Csharp Applications​","type":1,"pageTitle":"Mongo with csharp","url":"/2024/3/1/mongo-with-csharp#querying-a-mongodb-collection-in-csharp-applications","content":"Review the following code, which demonstrates how to query documents in MongoDB with Csharp. ","version":null,"tagName":"h2"},{"title":"Find a Document with FirstOrDefault​","type":1,"pageTitle":"Mongo with csharp","url":"/2024/3/1/mongo-with-csharp#find-a-document-with-firstordefault","content":"In the following example, the Find() command with a LINQ expression matches the AccountID field. The FirstOrDefault() method returns the first or default result. var account = accountsCollection .Find(a =&gt; a.AccountId == &quot;MDB829001337&quot;) .FirstOrDefault();  ","version":null,"tagName":"h3"},{"title":"Find a Document with FindAsync and FirstOrDefault​","type":1,"pageTitle":"Mongo with csharp","url":"/2024/3/1/mongo-with-csharp#find-a-document-with-findasync-and-firstordefault","content":"The FindAsync() command with a LINQ expression matches the AccountID field. The FirstOrDefault() method returns the first or default result. For example: var accounts = await accountsCollection .FindAsync(a =&gt; a.AccountId == &quot;MDB829001337&quot;); var account = accounts.FirstOrDefault();  ","version":null,"tagName":"h3"},{"title":"Find a Document with ToList​","type":1,"pageTitle":"Mongo with csharp","url":"/2024/3/1/mongo-with-csharp#find-a-document-with-tolist","content":"The Find() command with a LINQ expression matches all documents in the collection. The ToList() method returns a list of results. For example: var accounts = accountsCollection.Find(_ =&gt; true).ToList();  ","version":null,"tagName":"h3"},{"title":"Find a Document with Multiple LINQ Methods​","type":1,"pageTitle":"Mongo with csharp","url":"/2024/3/1/mongo-with-csharp#find-a-document-with-multiple-linq-methods","content":"The Find() command with a LINQ expression filters documents by AccountType (in this case, “checking”), sorts the results in descending order by the Balance, skips the first 5 results, and returns only 20 documents due to the limit. accountsCollection .Find(a =&gt; a.AccountType == &quot;checking&quot;) .SortByDescending(a =&gt; a.Balance) .Skip(5) .Limit(20);  ","version":null,"tagName":"h3"},{"title":"Find a Document with the Builders Class​","type":1,"pageTitle":"Mongo with csharp","url":"/2024/3/1/mongo-with-csharp#find-a-document-with-the-builders-class","content":"Use the Builders class to match all documents in the collection with an _id field equal to the specified value. For example: var filter = Builders&lt;BsonDocument&gt; .Filter .Eq(&quot;_id&quot;, new ObjectId(&quot;62d6e04ecab6d8e1304974ae&quot;)); var document = accountsCollection .Find(filter) .FirstOrDefault();  Use the Builders class to match all documents in the collection with a balance field greater than 1000. For example: var filter = Builders&lt;BsonDocument&gt; .Filter .Gt(&quot;balance&quot;, 1000); var documents = await accountsCollection .FindAsync(filter);   Lesson 4: Updating Documents in Csharp Applications / Learn​ ","version":null,"tagName":"h3"},{"title":"Updating Documents in Csharp Applications​","type":1,"pageTitle":"Mongo with csharp","url":"/2024/3/1/mongo-with-csharp#updating-documents-in-csharp-applications","content":"Review the following code, which demonstrates how to update documents in MongoDB with Csharp. ","version":null,"tagName":"h2"},{"title":"Update a Single Document​","type":1,"pageTitle":"Mongo with csharp","url":"/2024/3/1/mongo-with-csharp#update-a-single-document","content":"The following example demonstrates how to update a single document. First, create a filter definition with the .Filter method on the Builders class, which returns the account with an AccountId equal to “MDB951086017”. Next, create an update definition that will set the balance to 5000. Finally, use the UpdateOne() method to update the document. var filter = Builders&lt;Account&gt; .Filter .Eq(a =&gt; a.AccountId, &quot;MDB951086017&quot;); var update = Builders&lt;Account&gt; .Update .Set(a=&gt;a.Balance, 5000); var result = accountCollection.UpdateOne(filter, update); Console.WriteLine(result.ModifiedCount);  ","version":null,"tagName":"h3"},{"title":"Update a Single Document Asynchronously​","type":1,"pageTitle":"Mongo with csharp","url":"/2024/3/1/mongo-with-csharp#update-a-single-document-asynchronously","content":"The UpdateOneAsync() command updates a single document in the collection asynchronously. For example: var result = await accountsCollection.UpdateOneAsync(filter, update); Console.WriteLine(result.ModifiedCount);  ","version":null,"tagName":"h3"},{"title":"Update Multiple Documents​","type":1,"pageTitle":"Mongo with csharp","url":"/2024/3/1/mongo-with-csharp#update-multiple-documents","content":"Use the UpdateMany() method to update multiple documents in a single operation. Just like the UpdateOne() method, the UpdateMany() method accepts a query and an update. Here's an example: var filter = Builders&lt;Account&gt; .Filter .Eq(a =&gt; a.AccountType, &quot;checking&quot;); var update = Builders&lt;Account&gt; .Update .Inc(a =&gt; a.Balance, 5); var updateResult = accountCollection .UpdateMany(filter, update); Console.WriteLine(updateResult.ModifiedCount);  ","version":null,"tagName":"h3"},{"title":"Update Multiple Documents Asynchronously​","type":1,"pageTitle":"Mongo with csharp","url":"/2024/3/1/mongo-with-csharp#update-multiple-documents-asynchronously","content":"The UpdateManyAsync() command updates multiple documents in the collection asynchronously. For example: var filter = Builders&lt;BsonDocument&gt; .Filter .Lt(&quot;balance&quot;, 500); var update = Builders&lt;BsonDocument&gt; .Update .Inc(&quot;balance&quot;, 10); var result = await accountsCollection .UpdateManyAsync(filter, update); Console.WriteLine(result.ModifiedCount);   ","version":null,"tagName":"h3"},{"title":"Deleting Documents in Csharp Applications​","type":1,"pageTitle":"Mongo with csharp","url":"/2024/3/1/mongo-with-csharp#deleting-documents-in-csharp-applications","content":"Review the following code, which demonstrates how to delete documents in MongoDB with Csharp. ","version":null,"tagName":"h2"},{"title":"Delete a Single Document​","type":1,"pageTitle":"Mongo with csharp","url":"/2024/3/1/mongo-with-csharp#delete-a-single-document","content":"To delete a single document, use the DeleteOne() method, which accepts a query filter that matches the document that you want to delete. DeletedCount tells you how many documents were found by the filter and were deleted. Here's an example: var accountsCollection = database.GetCollection&lt;Account&gt;(&quot;Account&quot;); var result = accountsCollection .DeleteOne(a =&gt; a.AccountId == &quot;MDB333829449&quot;); Console.WriteLine(result.DeletedCount);  ","version":null,"tagName":"h3"},{"title":"Delete a Single Document Asynchronously​","type":1,"pageTitle":"Mongo with csharp","url":"/2024/3/1/mongo-with-csharp#delete-a-single-document-asynchronously","content":"To delete a single document asynchronously, use the DeleteOneAsync() method, which accepts a query filter that matches the document that you want to delete. We use a Builders class that matches a document based on the specified _id. Async methods can be used with builders or LINQ. Here's an example: var filter = Builders&lt;BsonDocument&gt; .Filter .Eq(&quot;_id&quot;, new ObjectId(&quot;63050518546c1e9d2d16ce4d&quot;)); var accounts = await accountsCollection .DeleteOneAsync(filter);  ","version":null,"tagName":"h3"},{"title":"Delete Multiple Documents​","type":1,"pageTitle":"Mongo with csharp","url":"/2024/3/1/mongo-with-csharp#delete-multiple-documents","content":"To delete multiple documents, use the DeleteMany() method, which accepts a query filter that matches the documents that you want to delete. Once the documents are successfully deleted, the method returns an instance of DeleteResult, which enables the retrieval of information such as the number of documents that were deleted. For example: var deleteResult = accountCollection .DeleteMany(a =&gt; a.Balance &lt; 500); Console.WriteLine(result.DeleteCount)  ","version":null,"tagName":"h3"},{"title":"Delete Multiple Documents Asynchronously​","type":1,"pageTitle":"Mongo with csharp","url":"/2024/3/1/mongo-with-csharp#delete-multiple-documents-asynchronously","content":"To delete multiple documents asynchronously, use the DeleteMany() method, which accepts a query filter that matches the documents that you want to delete. Once the documents are successfully deleted, the method returns an instance of DeleteResult, which enables the retrieval of information such as the number of documents that were deleted. We use a Builders class that matches a document based on the specified account_type. Async methods can be used with builders or LINQ. For example: var filter = Builders&lt;BsonDocument&gt; .Filter .Eq(&quot;account_type&quot;, &quot;checking&quot;); var deleteResult = await accountsCollection .DeleteManyAsync(filter); Console.WriteLine(deleteResult.DeletedCount);   ","version":null,"tagName":"h3"},{"title":"Creating MongoDB Transactions in Csharp Applications​","type":1,"pageTitle":"Mongo with csharp","url":"/2024/3/1/mongo-with-csharp#creating-mongodb-transactions-in-csharp-applications","content":"Review the following code, which demonstrates how to create a multi-document transaction in MongoDB with Csharp. ","version":null,"tagName":"h2"},{"title":"Multi-Document Transaction​","type":1,"pageTitle":"Mongo with csharp","url":"/2024/3/1/mongo-with-csharp#multi-document-transaction","content":"The following are the steps and the code to create a multi-document transaction in MongoDB with Csharp. The transaction is started by using the session’s WithTransaction() method. Then, we define the sequence of operations to perform inside the transaction. Here are the steps: Start a new session.Begin a transaction with the WithTransaction() method on the session.Create variables that will be used in the transaction.Obtain the user accounts information that will be used in the transaction.Create the transfer document.Update the user accounts.Insert the transfer document.Commit the transaction. Here's the code: using (var session = client.StartSession()) { // Define the sequence of operations to perform inside the transactions session.WithTransaction( (s, ct) =&gt; { var fromId = &quot;MDB310054629&quot;; var toId = &quot;MDB546986470&quot;; // Create the transfer_id and amount being transfered var transferId = &quot;TR02081994&quot;; var transferAmount = 20; // Obtain the account that the money will be coming from var fromAccountResult = accountsCollection.Find(e =&gt; e.AccountId == fromId).FirstOrDefault(); // Get the balance and id of the account that the money will be coming from var fromAccountBalance = fromAccountResult.Balance - transferAmount; var fromAccountId = fromAccountResult.AccountId; Console.WriteLine(fromAccountBalance.GetType()); // Obtain the account that the money will be going to var toAccountResult = accountsCollection.Find(e =&gt; e.AccountId == toId).FirstOrDefault(); // Get the balance and id of the account that the money will be going to var toAccountBalance = toAccountResult.Balance + transferAmount; var toAccountId = toAccountResult.AccountId; // Create the transfer record var transferDocument = new Transfers { TransferId = transferId, ToAccount = toAccountId, FromAccount = fromAccountId, Amount = transferAmount }; // Update the balance and transfer array for each account var fromAccountUpdateBalance = Builders&lt;Accounts&gt;.Update.Set(&quot;balance&quot;, fromAccountBalance); var fromAccountFilter = Builders&lt;Accounts&gt;.Filter.Eq(&quot;account_id&quot;, fromId); accountsCollection.UpdateOne(fromAccountFilter, fromAccountUpdateBalance); var fromAccountUpdateTransfers = Builders&lt;Accounts&gt;.Update.Push(&quot;transfers_complete&quot;, transferId); accountsCollection.UpdateOne(fromAccountFilter, fromAccountUpdateTransfers); var toAccountUpdateBalance = Builders&lt;Accounts&gt;.Update.Set(&quot;balance&quot;, toAccountBalance); var toAccountFilter = Builders&lt;Accounts&gt;.Filter.Eq(&quot;account_id&quot;, toId); accountsCollection.UpdateOne(toAccountFilter, toAccountUpdateBalance); var toAccountUpdateTransfers = Builders&lt;Accounts&gt;.Update.Push(&quot;transfers_complete&quot;, transferId); // Insert transfer doc transfersCollection.InsertOne(transferDocument); Console.WriteLine(&quot;Transaction complete!&quot;); return &quot;Inserted into collections in different databases&quot;; }); }  ","version":null,"tagName":"h3"},{"title":"Using MongoDB Aggregation Stages with Csharp: Sort and Project​","type":1,"pageTitle":"Mongo with csharp","url":"/2024/3/1/mongo-with-csharp#using-mongodb-aggregation-stages-with-csharp-sort-and-project","content":"Review the following code, which demonstrates how to use the Sort and Project aggregation methods in MongoDB. ","version":null,"tagName":"h2"},{"title":"Sort Stage​","type":1,"pageTitle":"Mongo with csharp","url":"/2024/3/1/mongo-with-csharp#sort-stage","content":"A Sort stage sorts all input documents and passes them to the next pipeline stage in the sorted order.This can be a numeric value, strings arranged in alphabetical order, dates, or timestamps. You can define the sort as a LINQ statement within the .SortBy() or .SortByDescending() methods. For example: var matchStage = Builders&lt;Accounts&gt;.Filter.Lt(user =&gt; user.Balance, 1500); var aggregate = accountsCollection.Aggregate() .Match(matchBalanceStage) .SortByDescending(u =&gt; u.Balance): var results = aggregate.ToList(); foreach (var account in results) { Console.WriteLine(account.Balance); }  Sort by Using BsonDocument​ A Sort stage sorts all input documents and passes them to the next pipeline stage in the sorted order. This can be a numeric value, strings arranged in alphabetical order, dates, or timestamps. For example: var matchBalanceStage = Builders&lt;BsonDocument&gt;.Filter.Lt(&quot;balance&quot;, 1500); var sort = Builders&lt;BsonDocument&gt;.Sort.Descending(&quot;balance&quot;); var aggregate = accountsCollection.Aggregate() .Match(matchBalanceStage) .Sort(sort); var results = aggregate.ToList(); foreach (var account in results) { Console.WriteLine(account.ToString()); }  ","version":null,"tagName":"h3"},{"title":"Project Stage​","type":1,"pageTitle":"Mongo with csharp","url":"/2024/3/1/mongo-with-csharp#project-stage","content":"To create a projection, we use the ProjectionDefinitionBuilder. We use the Expression method to define the output of the Project stage. In the following code, we use a LINQ expression to create a new generic object with the fields we want. We keep the same names for the first three properties: AccountId, AccountType, and Balance. We create a new field called GBP, which is calculated by dividing the current Balance field by 1.3. var matchBalanceStage = Builders&lt;Accounts&gt;.Filter.Lt(user =&gt; user.Balance, 1500); var projectStage = Builders&lt;Accounts&gt;.Projection.Expression(u =&gt; new { AccountId = u.AccountId, AccountType = u.AccountType, Balance = u.Balance, GBP = u.Balance / 1.30M }); var aggregate = accountsCollection.Aggregate() .Match(matchBalanceStage) .SortByDescending(u =&gt; u.Balance) .Project(projectStage); var results = aggregate.ToList(); foreach (var account in results) { Console.WriteLine(account.Balance); }  ","version":null,"tagName":"h3"},{"title":"Sample​","type":1,"pageTitle":"Mongo with csharp","url":"/2024/3/1/mongo-with-csharp#sample","content":"IMongoDatabase db = dbClient.GetDatabase(&quot;postal_data&quot;); var zipEntries = db.GetCollection&lt;ZipEntry&gt;(&quot;zip_entries&quot;); var builder = Builders&lt;ZipEntry&gt;.Filter; var filter = builder.Eq(x =&gt; x.State, &quot;AL&quot;) &amp; builder.Gt(x =&gt; x.Population, 2000); var sort = Builders&lt;ZipEntry&gt;.Sort.Ascending(x =&gt; x.City); var projection = Builders&lt;ZipEntry&gt;.Projection.Include(x =&gt; x.City).Exclude(x =&gt; x.Zip); var results = zipEntries.Find(filter).Sort(sort).Project(projection).ToList();   ","version":null,"tagName":"h3"},{"title":"MongoDB Aggregation with Csharp​","type":1,"pageTitle":"Mongo with csharp","url":"/2024/3/1/mongo-with-csharp#mongodb-aggregation-with-csharp","content":"In this unit, you learned how to: Define an aggregation pipeline and its stages and operators.Build the Match and Group stages of an aggregation pipeline.Build the Sort and Project stages of an aggregation pipeline. ","version":null,"tagName":"h2"},{"title":"Resources​","type":1,"pageTitle":"Mongo with csharp","url":"/2024/3/1/mongo-with-csharp#resources","content":"Use the following resources to learn more about performing basic aggregation with Csharp: ","version":null,"tagName":"h3"},{"title":"Git command","type":0,"sectionRef":"#","url":"/2023/12/29/git-cheatsheet","content":"","keywords":"","version":null},{"title":"Git Basics​","type":1,"pageTitle":"Git command","url":"/2023/12/29/git-cheatsheet#git-basics","content":"git init git clone &lt;repository_url&gt; git status  ","version":null,"tagName":"h2"},{"title":"Staging and Commits​","type":1,"pageTitle":"Git command","url":"/2023/12/29/git-cheatsheet#staging-and-commits","content":"git add &lt;file(s)&gt; git commit -m &quot;Commit message&quot; git reset --soft HEAD^ // Undo Last Commit (Keep Changes) git reset --hard HEAD^ // Undo Last Commit (Discard Changes)  ","version":null,"tagName":"h2"},{"title":"Branching​","type":1,"pageTitle":"Git command","url":"/2023/12/29/git-cheatsheet#branching","content":"git branch &lt;branch_name&gt; git checkout &lt;branch_name&gt; git checkout -b &lt;branch_name&gt; git merge &lt;branch_name&gt; git branch -d &lt;branch_name&gt;  ","version":null,"tagName":"h2"},{"title":"Remote Repositories​","type":1,"pageTitle":"Git command","url":"/2023/12/29/git-cheatsheet#remote-repositories","content":"git remote add &lt;remote_name&gt; &lt;repository_url&gt; git push &lt;remote_name&gt; &lt;branch_name&gt; git pull &lt;remote_name&gt; &lt;branch_name&gt;  ","version":null,"tagName":"h2"},{"title":"Logging and History​","type":1,"pageTitle":"Git command","url":"/2023/12/29/git-cheatsheet#logging-and-history","content":"git log git show &lt;commit_hash&gt; git diff  ","version":null,"tagName":"h2"},{"title":"Miscellaneous​","type":1,"pageTitle":"Git command","url":"/2023/12/29/git-cheatsheet#miscellaneous","content":"touch .gitignore // Ignore Files (Create .gitignore) git checkout -- &lt;file(s)&gt; // Undo Changes in Working Directory git reset HEAD &lt;file(s)&gt; // Undo Staged Changes  ","version":null,"tagName":"h2"},{"title":"Cherry-pick​","type":1,"pageTitle":"Git command","url":"/2023/12/29/git-cheatsheet#cherry-pick","content":"git cherry-pick &lt;commit_hash&gt;  ","version":null,"tagName":"h2"},{"title":"Rebase​","type":1,"pageTitle":"Git command","url":"/2023/12/29/git-cheatsheet#rebase","content":"git rebase &lt;base_branch&gt; git rebase -i &lt;base_branch&gt; // Interactive rebase  ","version":null,"tagName":"h2"},{"title":"Squash Commits during Rebase​","type":1,"pageTitle":"Git command","url":"/2023/12/29/git-cheatsheet#squash-commits-during-rebase","content":"// Change &quot;pick&quot; to &quot;squash&quot; for the commits you want to squash // Follow on-screen instructions to edit the commit messages git rebase -i &lt;base_branch&gt;  ","version":null,"tagName":"h2"},{"title":"Amend the Last Commit​","type":1,"pageTitle":"Git command","url":"/2023/12/29/git-cheatsheet#amend-the-last-commit","content":"git commit --amend  ","version":null,"tagName":"h2"},{"title":"Stash Changes​","type":1,"pageTitle":"Git command","url":"/2023/12/29/git-cheatsheet#stash-changes","content":"git stash git stash save &quot;Stash message&quot;  ","version":null,"tagName":"h2"},{"title":"Apply Stashed Changes​","type":1,"pageTitle":"Git command","url":"/2023/12/29/git-cheatsheet#apply-stashed-changes","content":"git stash apply git stash pop // Apply and remove from stash  ","version":null,"tagName":"h2"},{"title":"View Stash List​","type":1,"pageTitle":"Git command","url":"/2023/12/29/git-cheatsheet#view-stash-list","content":"git stash list  ","version":null,"tagName":"h2"},{"title":"Show Differences with Stash​","type":1,"pageTitle":"Git command","url":"/2023/12/29/git-cheatsheet#show-differences-with-stash","content":"git stash show -p &lt;stash_id&gt;  ","version":null,"tagName":"h2"},{"title":"Discard Stashed Changes​","type":1,"pageTitle":"Git command","url":"/2023/12/29/git-cheatsheet#discard-stashed-changes","content":"git stash drop &lt;stash_id&gt; git stash clear // Remove all stashes  ","version":null,"tagName":"h2"},{"title":"Tagging​","type":1,"pageTitle":"Git command","url":"/2023/12/29/git-cheatsheet#tagging","content":"git tag &lt;tag_name&gt; // Create lightweight tag git tag -a &lt;tag_name&gt; -m &quot;Tag message&quot; // Create annotated tag git push origin &lt;tag_name&gt; // Push tag to remote  ","version":null,"tagName":"h2"},{"title":"Submodules​","type":1,"pageTitle":"Git command","url":"/2023/12/29/git-cheatsheet#submodules","content":"git submodule add &lt;repository_url&gt; &lt;path&gt; // Add submodule git submodule update --init --recursive // Initialize submodules git submodule foreach git pull origin master // Update submodules  ","version":null,"tagName":"h2"},{"title":"Git Configurations​","type":1,"pageTitle":"Git command","url":"/2023/12/29/git-cheatsheet#git-configurations","content":"git config --global user.name &quot;Your Name&quot; git config --global user.email &quot;your@email.com&quot;  ","version":null,"tagName":"h2"},{"title":"Show Configurations​","type":1,"pageTitle":"Git command","url":"/2023/12/29/git-cheatsheet#show-configurations","content":"git config --list  ","version":null,"tagName":"h2"},{"title":"Fundamentals-SQL","type":0,"sectionRef":"#","url":"/2023/12/25/Fundamentals-SQL","content":"","keywords":"","version":null},{"title":"Exploring MongoDB and mongosh in Bash","type":0,"sectionRef":"#","url":"/2024/1/1/Exploring-MongoDB-and-mongosh-in-Bash-Senior-note","content":"","keywords":"","version":null},{"title":"MongoDB Node.js Driver - Connection String Options​","type":1,"pageTitle":"Exploring MongoDB and mongosh in Bash","url":"/2024/1/1/Exploring-MongoDB-and-mongosh-in-Bash-Senior-note#mongodb-nodejs-driver---connection-string-options","content":"MongoDB supports various connection string options, including: MaxPoolSizeMinPoolSizemaxIdleTimeMS ","version":null,"tagName":"h2"},{"title":"MongoDB Data Types - BSON Types​","type":1,"pageTitle":"Exploring MongoDB and mongosh in Bash","url":"/2024/1/1/Exploring-MongoDB-and-mongosh-in-Bash-Senior-note#mongodb-data-types---bson-types","content":"MongoDB uses BSON types to represent data. Here are some key BSON types: Double: MongoDB uses Double; there is no Float.StringObject32-Integer64-IntegerObjectIdBooleanDateTimestampDecimal128Array Data types ObjectId init from timestamp, increment, machineId, randomNumber ","version":null,"tagName":"h2"},{"title":"Querying MongoDB​","type":1,"pageTitle":"Exploring MongoDB and mongosh in Bash","url":"/2024/1/1/Exploring-MongoDB-and-mongosh-in-Bash-Senior-note#querying-mongodb","content":"MongoDB provides powerful querying capabilities. Let's explore some query operations: Collection.findOne(query, options) Collection.find().project().sort().skip().limit().count() Comparison: The following operators can be used in queries to compare values: {field:{operator:value}} $eq: Values are equal$ne: Values are not equal$gt: Value is greater than another value$gte: Value is greater than or equal to another value$lt: Value is less than another value$lte: Value is less than or equal to another value$in: Value is matched within an array {&quot;salary&quot;:{$in:[5,10]}}$nin: Value not in$all: find in an array all elements matching in finding ['Smartphones', 'iOS'] Eg: db.trips.find({&quot;id&quot;:{$in:[1,20]}}) Logical: The following operators can logically compare multiple queries. operator:[{condition1},{condition2},..] $and: Returns documents where both queries match$or: Returns documents where either query matches$nor: Returns documents where both queries fail to match$not: Returns documents where the query does not match Eg: db.trips.find({$or:[&quot;id&quot;:{$gt:10},&quot;price&quot;:{$lt:19}]}) Evaluation: The following operators assist in evaluating documents. $regex: Allows the use of regular expressions when evaluating field values $text: Performs a text search $where: Uses a JavaScript expression to match documents $expr: $expr: {operator:[field, value]} $elemMatch: find an object in an array of objects only, cannot find in a field ot an array $size: find the number of elements in an array {$scores: {$size: 6}} Collection.find().count() Collection.countDocuments() Collection.aggregate() [{$match:{}}, {$group:{}}, {$sort: {}}, {$skip: 10}, {$limit}]Group: total, averageVar pipeline = [state1, state2, state3]{$count: &quot;total&quot;} Collection.listIndexes() Collection.countDocuments(query) FindAndModify(query:{}, update: {}, {new: true}): new = true: return a modified document Expression: db.movies.find({$expr:{$gt: [&quot;$idbm.votes&quot;, &quot;$year&quot;]}}) Db.products.find(&quot;name&quot;:&quot;Smartphone&quot;).count(); { &quot;customer.gender&quot;: &quot;M&quot;, items: { $elemMatch: { name: 'printer paper' } } }  ","version":null,"tagName":"h3"},{"title":"Working with Documents - Insert, Update, and Delete​","type":1,"pageTitle":"Exploring MongoDB and mongosh in Bash","url":"/2024/1/1/Exploring-MongoDB-and-mongosh-in-Bash-Senior-note#working-with-documents---insert-update-and-delete","content":"Inserting Documents Collection.insertOne(document, option): Option = { writeConcern: { w : &quot;majority&quot;, wtimeout : 100 } } Db.insert({}, {returnId: true}) Db.insert([]) Collection.insertMany() Updating Documents Collection.updateOne(filter, update, option) Filter = queryUpdate = {$set: {}} or {$inc: {balance: 1000}}Update = {$push: {readings: {v: 10, t: new Date()}}}Option = {upsert: true} upsert not $upsert Collection.update() Collection.updateMany() await salesCollection.updateMany({items: {$elemMatch: {name: &quot;printer paper&quot;}}},{$set: {&quot;items.$.price&quot;: 20 }}); Deleting Documents deleteMany(query): If the query = {} delete all documents in the collection deleteOne(): return ({acknowledge:true, deleteCount: 1}) deleteMany().deletedCount ","version":null,"tagName":"h3"},{"title":"MongoDB Indexing​","type":1,"pageTitle":"Exploring MongoDB and mongosh in Bash","url":"/2024/1/1/Exploring-MongoDB-and-mongosh-in-Bash-Senior-note#mongodb-indexing","content":"MongoDB offers various indexing options to optimize query performance: Single Index Compound Index MultiKey Index Unique Index vs Non-Unique Index Sparse Index vs Non-Sparse Index Geography index: createIndex({locationField:'2dsphere'}) Example Query: You can perform geospatial queries using operators like $near, $geoWithin, $geoIntersects, and others to find documents based on their geographical proximity or containment. ","version":null,"tagName":"h3"},{"title":"MongoDB Aggregation Framework​","type":1,"pageTitle":"Exploring MongoDB and mongosh in Bash","url":"/2024/1/1/Exploring-MongoDB-and-mongosh-in-Bash-Senior-note#mongodb-aggregation-framework","content":"MongoDB's Aggregation Framework is a powerful tool for data transformation and analysis. Let's explore some aggregation stages: $match$addFields$group$sample: {size: 10} get random 10 documents$project: {total_avg: $round {number, place}}$sortByCount: &quot;$city&quot; =&gt; descending = $group $sort descending$lookup:{from: , localField:, foreignField, as:}$out: to another collection must be in the same database =&gt; Last stage only$bucketAuto :{groupBy: &quot;$tripduration&quot;, buckets:5, output: {}}$bucket: {groupBy:&quot;$tripduration&quot;,boundaries: [10,100,1000,1000,100000], default: &quot;other&quot;, output} ","version":null,"tagName":"h3"},{"title":"Full Text Search in MongoDB​","type":1,"pageTitle":"Exploring MongoDB and mongosh in Bash","url":"/2024/1/1/Exploring-MongoDB-and-mongosh-in-Bash-Senior-note#full-text-search-in-mongodb","content":"MongoDB supports full-text search with various options for tokenization and fuzzy searching. ","version":null,"tagName":"h3"},{"title":"Static Search​","type":1,"pageTitle":"Exploring MongoDB and mongosh in Bash","url":"/2024/1/1/Exploring-MongoDB-and-mongosh-in-Bash-Senior-note#static-search","content":"{ &quot;mappings&quot;: { &quot;dynamic&quot;: false, &quot;fields&quot;: { &quot;company&quot;: { &quot;type&quot;: &quot;string&quot; }, &quot;title&quot;: { &quot;type&quot;: &quot;string&quot; } } } }  ","version":null,"tagName":"h2"},{"title":"Tokenization and Fuzzy Options​","type":1,"pageTitle":"Exploring MongoDB and mongosh in Bash","url":"/2024/1/1/Exploring-MongoDB-and-mongosh-in-Bash-Senior-note#tokenization-and-fuzzy-options","content":"EdgeGram beginning of the wordrightEdgeGramnGram Fuzzy option: maxEditsMaxExpansionsprefixLength ","version":null,"tagName":"h2"},{"title":"MongoDB Transactions​","type":1,"pageTitle":"Exploring MongoDB and mongosh in Bash","url":"/2024/1/1/Exploring-MongoDB-and-mongosh-in-Bash-Senior-note#mongodb-transactions","content":"MongoDB provides support for transactions, ensuring data consistency in complex operations. // Transaction Session startSession() UpdateOne({}, {$inc: {balance: -30}}) CommitTransaction AbortTransaction  ","version":null,"tagName":"h2"},{"title":"MongoDB Sharding and Replica Set​","type":1,"pageTitle":"Exploring MongoDB and mongosh in Bash","url":"/2024/1/1/Exploring-MongoDB-and-mongosh-in-Bash-Senior-note#mongodb-sharding-and-replica-set","content":"Sharding and Replica Set are essential concepts for scaling and ensuring high availability in MongoDB. ","version":null,"tagName":"h2"},{"title":"Sharding​","type":1,"pageTitle":"Exploring MongoDB and mongosh in Bash","url":"/2024/1/1/Exploring-MongoDB-and-mongosh-in-Bash-Senior-note#sharding","content":"Sharding distributes data across multiple servers to improve read and write scalability. ","version":null,"tagName":"h3"},{"title":"Replica Set​","type":1,"pageTitle":"Exploring MongoDB and mongosh in Bash","url":"/2024/1/1/Exploring-MongoDB-and-mongosh-in-Bash-Senior-note#replica-set","content":"A Replica Set consists of multiple nodes with one primary node and two replicate nodes. ","version":null,"tagName":"h3"},{"title":"MongoDB Best Practices​","type":1,"pageTitle":"Exploring MongoDB and mongosh in Bash","url":"/2024/1/1/Exploring-MongoDB-and-mongosh-in-Bash-Senior-note#mongodb-best-practices","content":"MongoDB offers various best practices and considerations for efficient data modeling and management. ","version":null,"tagName":"h2"},{"title":"Data Model Patterns​","type":1,"pageTitle":"Exploring MongoDB and mongosh in Bash","url":"/2024/1/1/Exploring-MongoDB-and-mongosh-in-Bash-Senior-note#data-model-patterns","content":"There are 12 data model patterns, including Computed Pattern, Attribute Pattern, Polymorphic pattern, Bucket, Outline, and others. ","version":null,"tagName":"h3"},{"title":"Capped Collection​","type":1,"pageTitle":"Exploring MongoDB and mongosh in Bash","url":"/2024/1/1/Exploring-MongoDB-and-mongosh-in-Bash-Senior-note#capped-collection","content":"db.createCollection(&quot;&quot;, {capped: true, size: 10, max: 3})  Capped collection has a Limit size. ","version":null,"tagName":"h3"},{"title":"Read and Write Concern​","type":1,"pageTitle":"Exploring MongoDB and mongosh in Bash","url":"/2024/1/1/Exploring-MongoDB-and-mongosh-in-Bash-Senior-note#read-and-write-concern","content":"Read Concern: Available, Majority, LocalWrite Concern: Majority ","version":null,"tagName":"h3"},{"title":"MongoDB Views​","type":1,"pageTitle":"Exploring MongoDB and mongosh in Bash","url":"/2024/1/1/Exploring-MongoDB-and-mongosh-in-Bash-Senior-note#mongodb-views","content":"Creating and working with views in MongoDB: Db.createView(&quot;view_name&quot;,&quot;source_collection&quot;,[pipeline],collation) Db.createView(&quot;name&quot;, &quot;source&quot;, [])  Cannot update to view. ","version":null,"tagName":"h2"},{"title":"MongoDB Administration and Tools​","type":1,"pageTitle":"Exploring MongoDB and mongosh in Bash","url":"/2024/1/1/Exploring-MongoDB-and-mongosh-in-Bash-Senior-note#mongodb-administration-and-tools","content":"MongoDB provides tools and commands for administrative tasks, backup, and restore. ","version":null,"tagName":"h2"},{"title":"mongorestore​","type":1,"pageTitle":"Exploring MongoDB and mongosh in Bash","url":"/2024/1/1/Exploring-MongoDB-and-mongosh-in-Bash-Senior-note#mongorestore","content":"Use mongorestore to restore a dump file to MongoDB. ","version":null,"tagName":"h3"},{"title":"Cursor Method and Indexing​","type":1,"pageTitle":"Exploring MongoDB and mongosh in Bash","url":"/2024/1/1/Exploring-MongoDB-and-mongosh-in-Bash-Senior-note#cursor-method-and-indexing","content":"Choose the appropriate cursor method, like Cursor.hint(), to force MongoDB to use a specific index for a query. ","version":null,"tagName":"h3"},{"title":"MongoDB Security​","type":1,"pageTitle":"Exploring MongoDB and mongosh in Bash","url":"/2024/1/1/Exploring-MongoDB-and-mongosh-in-Bash-Senior-note#mongodb-security","content":"Ensure the security of your MongoDB instance by understanding the importance of the &quot;admin&quot; database and controlling user access. ","version":null,"tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"Exploring MongoDB and mongosh in Bash","url":"/2024/1/1/Exploring-MongoDB-and-mongosh-in-Bash-Senior-note#conclusion","content":"In conclusion, MongoDB offers a robust and flexible database solution with a wide range of features for efficient data management and querying. Understanding the various concepts and best practices will empower you to make the most out of MongoDB in your projects. Happy coding! ","version":null,"tagName":"h2"},{"title":"Azure Cloud","type":0,"sectionRef":"#","url":"/2024/4/13/azure-cloud","content":"Your users want to sign-in to devices, apps, and services from anywhere. They want to sign-in using an organizational work or school account instead of a personal account. You must ensure corporate assets are protected and that devices meet standards for security and compliance. Specifically, you need to be able to enable or disable a device. What should you do? (1 Point) a. Enable the device in Azure AD. b. Join the device to Azure AD. c. Register the device with Azure AD. Correct Answer: b. Join the device to Azure AD. A dedicated and trusted instance of Azure AD is referred to as: (1 Point) a. An Azure tenant b. An Azure identity c. An Azure account Correct Answer: a. An Azure tenant You are configuring Self-service Password Reset. Which of the following is not a validation method? (1 Point) a. An email notification. b. A text or code sent to a user's mobile or office phone c. A paging service. d. A set of security questions Correct Answer: c. A paging service. You would like to add a user who has a Microsoft account to your subscription. Which type of user account is this? (1 Point) a. Cloud identity b. Directory-Synchronized identity c. Guest User Correct Answer: c. Guest User If you delete a user account by mistake, can it be restored? (1 Point) a. When a user account is deleted, it's gone forever and can't be restored. b. The user account can be restored, but only when it's created within the last 30 days. c. The user account can be restored, but only when it's deleted within the last 30 days. Correct Answer: c. The user account can be restored, but only when it's deleted within the last 30 days. Your company financial comptroller wants to be notified whenever the company is halfway to spending the money allocated for cloud services. What should you do? (1 Point) a. Create an Azure reservation. b. Create a budget and a spending threshold. c. Create a management group. d. Enter workloads in the Total Cost of Ownership calculator. Correct Answer: b. Create a budget and a spending threshold. What tool can you use to gain greater visibility into your spending patterns? (1 Point) a. Cost Insights b. Cost Analysis c. Your invoice Correct Answer: b. Cost Analysis Your company is concerned about cost and provisioning too many virtual machines at once. What's the best way to control resource provisioning? (1 Point) a. Change your subscription to pay as you go. b. Apply spending limits to the development team's Azure subscription. c. Verbally give the managers a budget and hold them accountable for overages. Correct Answer: b. Apply spending limits to the development team's Azure subscription. The leadership team wants information on resource costs by departments. What's the best way to categorize costs by department? (1 Point) a. Apply a tag to each resource that identifies the appropriate billing department. b. Split the cost evenly between departments. c. Keep a spreadsheet that lists each team's resources Correct Answer: a. Apply a tag to each resource that identifies the appropriate billing department. An Azure subscription ................................... (1 Point) a. is a logical container used to provision resources in Azure b. is associated with a single department or organization c. represents a single domain Correct Answer: a. is a logical container used to provision resources in Azure Your organization has several Azure policies that they would like to create and enforce for a new branch office. What should you do? (1 Point) a. Create a policy initiative b. Create a management group c. Create a new subscription Correct Answer: b. Create a management group You would like to categorize resources and billing for different departments like IT and HR. The billing needs to be consolidated across multiple resource groups and you need to ensure everyone complies with the solution. You have created tags for each department, like department:HR. What should you do next? (1 Point) a. Create a billing group for each department b. Create an Azure policy c. Create a subscription account rule Correct Answer: b. Create an Azure policy Your company wants to ensure that only cost-effective virtual machine SKU sizes are deployed. What should you do? (1 Point) a. Periodically inspect the deployment to see which SKU sizes are used b. Create an Azure RBAC role that defines the allowed virtual machine SKU sizes c. Create a policy in Azure Policy that specifies the allowed SKU sizes Correct Answer: c. Create a policy in Azure Policy that specifies the allowed SKU sizes Which of the following can be used to manage governance across multiple Azure subscriptions? (1 Point) a. Azure initiatives b. Resource groups c. Management groups Correct Answer: c. Management groups Your company hires a new IT administrator. She needs to manage a resource group with first-tier web servers including assigning permissions. However, she should not have access to other resource groups inside the subscription. You need to configure role-based access. What should you do? (1 Point) a. Assign her as a Subscription Contributor. b. Assign her as a Resource Group Owner. c. Assign her as a Resource Group Contributor. Correct Answer: c. Assign her as a Resource Group Contributor. You have three virtual machines (VM1, VM2, and VM3) in a resource group. The Helpdesk hires a new employee. The new employee must be able to modify the settings on VM3, but not on VM1 and VM2. Your solution must minimize administrative overhead. What should you do? (1 Point) a. Assign the user to the Contributor role on the resource group b. Assign the user to the Contributor role on VM3. c. Move VM3 to a new resource group and assign the user to the Contributor role on VM3. Correct Answer: b. Assign the user to the Contributor role on VM3. Your company wants to allow some users to control the virtual machines in each environment. These users should be prevented from modifying networking and other resources in the same resource group or Azure subscription. What should you do? (1 Point) a. Create a policy in Azure Policy that audits resource usage b. Split the environment into separate resource groups c. Create a role assignment through Azure RBAC Correct Answer: c. Create a role assignment through Azure RBAC Suppose a team member can't view resources in a resource group. Where would the administrator go to check the team member's access? (1 Point) a. Check the team member's permissions by going to their Azure profile &gt; My permissions b. Go to the resource group and select Access control (IAM) &gt; Role assignments. c. Go to one of the resources in the resource group and select Role assignments. Correct Answer: b. Go to the resource group and select Access control (IAM) &gt; Role assignments. A user who had Owner access to a subscription is leaving the company. No one else has access to this subscription. How can you grant another employee access to this subscription? (1 Point) a. Use the Azure portal to elevate your own access b. Ask the former employee for their password. c. Ask the former employee to sign in and select a different employee to grant their permissions to. Correct Answer: a. Use the Azure portal to elevate your own access Which of the following is not true about the Cloud Shell? (1 Point) a. Authenticates automatically for instant access to your resources. b. Cloud Shell is assigned multiple machines per user account. c. Provides both Bash and PowerShell sessions. Correct Answer: b. Cloud Shell is assigned multiple machines per user account. You are managing Azure locally using PowerShell. You have launched the app as an Administrator. Which of the following commands would you do first? (1 Point) a. Connect-AzAccount b. Get-AzResourceGroup c. Get-AzSubscription Correct Answer: a. Connect-AzAccount Suppose you are building a video-editing application that will offer online storage for user-generated video content. You will store the videos in Azure Blobs, so you need to create an Azure storage account to contain the blobs. Once the storage account is in place, it is unlikely you would remove and recreate it because this would delete all the user videos. Which tool is likely to offer the quickest and easiest way to create the storage account? (1 Point) a. Azure portal b. Azure CLI c. Azure PowerShell Correct Answer: a. Azure portal You have a new Azure subscription and need to move resources to that subscription. Which of the following resources cannot be moved? (1 Point) a. Key vault b. Storage account c. Tenant Correct Answer: c. Tenant You are reviewing your virtual machine usage. You notice that you have reached the limit for virtual machines in the US East region. Which of the following provides the easiest solution? (1 Point) a. Add another resource group b. Change your subscription plan c. Request support increase your limit Correct Answer: c. Request support increase your limit Which of the following would be a good example of when to use a resource lock? (1 Point) a. A ExpressRoute circuit with connectivity back to your on-premises network. b. A non-production virtual machine used to test occasional application builds. c. A storage account used to temporarily store images processed in a development environment Correct Answer: a. A ExpressRoute circuit with connectivity back to your on-premises network. Your manager asks you to explain how Azure uses resource groups. You provide all of the following information, except? (1 Point) a. Resources can be in only one resource group. b. Resources can be moved from one resource group to another resource group. c. Resource groups can be nested. Correct Answer: c. Resource groups can be nested. Which of the following best describes the format of an Azure Resource Manager template? (1 Point) a. A JSON document with key-value pairs b. A TXT document with key-value pairs c. An XML document with element-value pairs Correct Answer: a. A JSON document with key-value pairs Azure Resource Manager templates are idempotent. This means that if you run a template with no changes a second time ... (1 Point) a. Azure Resource Manager will deploy new resources as copies of the previously deployed resources. b. Azure Resource Manager won't make any changes to the deployed resources. c. Azure Resource Manager will delete the previously deployed resources and redeploy them. Correct Answer: b. Azure Resource Manager won't make any changes to the deployed resources. You are planning your Azure network implementation to support your company's migration to Azure. Your first task is to prepare for the deployment of the first set of VMs. For these machines, consumers on the internet must be able to communicate directly with the web application on the VMs. Also, the IP configuration must be zone redundant. You should minimize costs, whenever possible, while still meeting the requirements. What should you do? (1 Point) a. Create a standard public IP address. During the creation of the first VM, associate the public IP address with the VM's NIC. b. Create a standard public IP address. After the first VM is created, remove the private IP address and assign the public IP address to the NIC. c. Create a basic public IP address. During the creation of the first VM, associate the public IP address with the VM. Correct Answer: a. Create a standard public IP address. During the creation of the first VM, associate the public IP address with the VM's NIC. You have a VM with two NICs named NIC1 and NIC2. NIC1 is connected to the 10.10.8.0/24 subnet. NIC2 is connected to the 10.20.8.0/24 subnet. You plan enable direct communication from the internet to TCP port 443. You would like to maintain existing communication across the 10.10.8.0/24 and 10.20.8.0/24 subnets. To support the new functionality and keep things simple. What should you do? (1 Point) a. Remove the private IP address from NIC2 and then assign a public IP address to it. Then, create an inbound security rule. b. Associate a public IP address to NIC2 and create an inbound security rule. c. Create an inbound security rule for TCP port 443. Correct Answer: b. Associate a public IP address to NIC2 and create an inbound security rule.","keywords":"","version":null},{"title":"net 8 and c# 12 big change","type":0,"sectionRef":"#","url":"/2024/4/12/net-8","content":"","keywords":"","version":null},{"title":"Net8​","type":1,"pageTitle":"net 8 and c# 12 big change","url":"/2024/4/12/net-8#net8","content":". NET 8, was released on November 14, 2023, along with C# 12 and Visual Studio 17.8. .NET 8 will be supported for three years as a long-term support (LTS) release. You can download .NET 8 here. The .NET 8 runtime includes improvements to performance, garbage collection, and the core and extension libraries. Some update summaries: The .NET 8 runtime includes improvements to performance, garbage collection, and the core and extension libraries. ASP.NET Core includes improvements to Blazor, SignalR, minimal APIs, Native AOT, Kestrel and HTTP.sys servers, and authentication and authorization. .NET MAUI includes new functionality for controls, gesture recognizers, Windows apps, navigation, and platform integration. Entity Framework Core includes improvements to complex type objects, collections of primitive types, JSON column mapping, raw SQL queries, lazy loading, tracked-entity access, model building, math translations, and other features. Windows Forms includes improvements to data binding, Visual Studio DPI, and high DPI. Windows Presentation Foundation (WPF) adds the ability to use hardware acceleration and a new OpenFolderDialog control.  ","version":null,"tagName":"h2"},{"title":"C# 12​","type":1,"pageTitle":"net 8 and c# 12 big change","url":"/2024/4/12/net-8#c-12","content":"C# 12 is supported on .NET 8. C# 12 includes the following new features. Primary constructors - Introduced in Visual Studio 2022 version 17.6 Preview 2. Primary constructors provide a concise syntax for initializing properties in C# classes. They allow you to declare and initialize properties directly in the constructor parameter list, reducing boilerplate code. public class Person(string _name) { public string Name = _name; } Person person = new Person(&quot;John&quot;); Console.WriteLine(person.Name); // Output: John  old style: public class Person { public string Name { get; } public int Age { get; } public Person(string name, int age) { Name = name; Age = age; } }  Collection expressions - Introduced in Visual Studio 2022 version 17.7 Preview 5. Collection expressions introduce a new terse syntax to create common collection values. Inlining other collections into these values is possible using a spread operator ... The following examples show uses of collection expressions: // Create an array: int[] a = [1, 2, 3, 4, 5, 6, 7, 8]; // Create a list: List&lt;string&gt; b = [&quot;one&quot;, &quot;two&quot;, &quot;three&quot;]; // Create a span Span&lt;char&gt; c = ['a', 'b', 'c', 'd', 'e', 'f', 'h', 'i']; // Create a jagged 2D array: int[][] twoD = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]; // Create a jagged 2D array from variables: int[] row0 = [1, 2, 3]; int[] row1 = [4, 5, 6]; int[] row2 = [7, 8, 9]; int[][] twoDFromVariables = [row0, row1, row2];  The spread operator, .. in a collection expression replaces its argument with the elements from that collection. The argument must be a collection type. The following examples show how the spread operator works: int[] row0 = [1, 2, 3]; int[] row1 = [4, 5, 6]; int[] row2 = [7, 8, 9]; int[] single = [.. row0, .. row1, .. row2]; foreach (var element in single) { Console.Write($&quot;{element}, &quot;); } // output: // 1, 2, 3, 4, 5, 6, 7, 8, 9,  Inline arrays - Introduced in Visual Studio 2022 version 17.7 Preview 3. Inline arrays enable a developer to create an array of fixed size in a struct type An inline array is declared similar to the following struct: [System.Runtime.CompilerServices.InlineArray(10)] public struct Buffer { private int _element0; }  You use them like any other array: var buffer = new Buffer(); for (int i = 0; i &lt; 10; i++) { buffer[i] = i; } foreach (var i in buffer) { Console.WriteLine(i); }  Optional parameters in lambda expressions - Introduced in Visual Studio 2022 version 17.5 Preview 2. You can now define default values for parameters on lambda expressions. The syntax and rules are the same as adding default values for arguments to any method or local function. // Define a lambda expression with default parameters Func&lt;int, int, int&gt; add = (x, y = 0) =&gt; x + y; // Call the lambda expression with one argument int result1 = add(5); Console.WriteLine(&quot;Result1: &quot; + result1); // Output: 5 // Call the lambda expression with two arguments int result2 = add(5, 3); Console.WriteLine(&quot;Result2: &quot; + result2); // Output: 8  ref readonly parameters - Introduced in Visual Studio 2022 version 17.8 Preview 2. pass parameters by reference while ensuring that the referenced value cannot be modified within the method. ref readonly parameters enables more clarity for APIs int[] numbers = { 1, 2, 3, 4, 5 }; int sum = Plus(numbers); Console.WriteLine(&quot;Sum: &quot; + sum); public static int Plus(ref readonly int[] arr) { int sum = 0; foreach (int num in arr) { sum += num; } return sum; }  Alias any type - Introduced in Visual Studio 2022 version 17.6 Preview 3. use the using alias directive to alias any type, not just named types. That means you can create semantic aliases for tuple types, array types, pointer types, or other unsafe types. Pair pair = (1, &quot;apple&quot;); int number = pair.Item1; string fruit = pair.Item2; Console.WriteLine($&quot;Number: {number}, Fruit: {fruit}&quot;); // using alias with tuple types: using Pair = (int, string);  Experimental attribute - Introduced in Visual Studio 2022 version 17.7 Preview 3. The System.Diagnostics.CodeAnalysis.ExperimentalAttribute allows developers to mark types, methods, or assemblies as experimental features. This attribute serves as a way to communicate to other developers that the marked feature is still under development or testing, and its API or behavior may change in future releases. [Experimental(&quot;Experimental feature: FeatureName&quot;)] public static void ExperimentalMethod() { // Experimental feature implementation } public static void Main() { // Call the experimental method ExperimentalMethod(); }  Interceptors - Preview feature Introduced in Visual Studio 2022 version 17.7 Preview 3. Interceptors are an experimental feature, available in preview mode with C# 12. ","version":null,"tagName":"h2"},{"title":"Risk upgrading from .net6 to .net 8​","type":1,"pageTitle":"net 8 and c# 12 big change","url":"/2024/4/12/net-8#risk-upgrading-from-net6-to-net-8","content":"Compatibility: third-party libraries Some libraries or packages may not yet support the latest version,development team may need time to familiarize themselves with the new features and changes introduced in .NET 8update code, refactor components, and test thoroughly to ensure everything works as expected.current version ready proxy c#12 ","version":null,"tagName":"h2"},{"title":"Querying and Data Modification","type":0,"sectionRef":"#","url":"/2023/12/25/Querying-and-Data-Modification","content":"","keywords":"","version":null},{"title":"Data Manipulation Language (DML) Operations:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#data-manipulation-language-dml-operations","content":"DML operations involve the manipulation of data within a database. ","version":null,"tagName":"h2"},{"title":"INSERT Data:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#insert-data","content":"-- Single Record INSERT INTO Student(ID, FullName, Email, PhoneNumber, Math) VALUES(5, 'HUY', 'HUY@gmail.com', '0123456789', 5); -- Multiple Records INSERT INTO Student(ID, FullName, Email, PhoneNumber, DateOfBirth, Math) VALUES (4, 'LAN', 'LAN@gmail.com', '0123456789', '1/30/1999', 7), (3, 'HAO', 'HAO@gmail.com', '0123456789', '12/15/2000', 8);  The INSERT statement adds new records to a table. ","version":null,"tagName":"h3"},{"title":"UPDATE Data:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#update-data","content":"-- Update Single Record UPDATE Student SET FullName = 'I AM A GOOD BOY' WHERE ID = 3; -- Update Multiple Records UPDATE Student SET FullName = 'Updated Name' WHERE Math &gt; 5;  The UPDATE statement modifies existing records in a table. ","version":null,"tagName":"h3"},{"title":"DELETE Data:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#delete-data","content":"-- Delete Single Record DELETE FROM Student WHERE ID = 3; -- Delete All Records with a Condition DELETE FROM Student WHERE Math &gt; 5; -- Truncate Table (Remove all records) TRUNCATE TABLE Parent;  The DELETE statement removes records from a table.  ","version":null,"tagName":"h3"},{"title":"Operators:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#operators","content":"Operators perform various operations in SQL. ","version":null,"tagName":"h2"},{"title":"Arithmetic Operators:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#arithmetic-operators","content":"SELECT 30 + 20 AS 'ADDITION'; SELECT 30 - 20 AS 'SUBTRACTION'; SELECT 30 * 20 AS 'MULTIPLICATION'; SELECT 30 / 20 AS 'DIVISION'; SELECT 30 % 20 AS 'MODULO';  Arithmetic operators perform mathematical operations. ","version":null,"tagName":"h3"},{"title":"Comparison Operators:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#comparison-operators","content":"-- Equal To SELECT ID, FullName FROM Student WHERE FullName = 'Lan Anh'; -- Greater Than SELECT ID, FullName, Math FROM Student WHERE Math &gt; 5;  Comparison operators compare values for equality, inequality, etc. ","version":null,"tagName":"h3"},{"title":"Logical Operators:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#logical-operators","content":"-- AND Operator SELECT ID, FullName FROM Student WHERE FullName = 'Lan Anh' AND ID = 1010; -- OR Operator SELECT ID, FullName FROM Student WHERE FullName = 'Lan Anh' OR ID = 1005; -- NOT Operator SELECT ID, FullName, Math FROM Student WHERE NOT Math &gt; 5;  Logical operators combine conditions using AND, OR, and NOT. ","version":null,"tagName":"h3"},{"title":"BETWEEN - AND:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#between---and","content":"-- Values within a Range SELECT ID, FullName FROM Student WHERE ID BETWEEN 1003 AND 1005;  The BETWEEN - AND operator selects values within a specified range. ","version":null,"tagName":"h3"},{"title":"LIKE Operator:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#like-operator","content":"-- Pattern Matching SELECT FullName, Math FROM Student WHERE FullName LIKE '%U%';  The LIKE operator searches for a specified pattern in a column. ","version":null,"tagName":"h3"},{"title":"IS NULL:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#is-null","content":"-- Check for NULL Values SELECT ID, FullName, Math FROM Student WHERE Math IS NULL;  The IS NULL operator checks for NULL values in a column.  ","version":null,"tagName":"h3"},{"title":"SELECT Statement:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#select-statement","content":"The SELECT statement retrieves data from one or more tables. ","version":null,"tagName":"h2"},{"title":"ORDER BY Clause:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#order-by-clause","content":"-- Ascending Order SELECT * FROM Student ORDER BY FullName ASC; -- Descending Order SELECT * FROM Student ORDER BY FullName DESC; -- Order by Multiple Columns SELECT * FROM Student ORDER BY FullName ASC, Math ASC;  The ORDER BY clause sorts query results in ascending or descending order. ","version":null,"tagName":"h3"},{"title":"TOP, PERCENT, and WITH TIES:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#top-percent-and-with-ties","content":"-- SELECT TOP N Rows SELECT TOP 3 * FROM Student; -- SELECT TOP N Percent of Rows SELECT TOP 50 PERCENT ID, FullName FROM Student;  TOP limits the number of rows returned, and PERCENT filters by a percentage. ","version":null,"tagName":"h3"},{"title":"DISTINCT Keyword:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#distinct-keyword","content":"-- Select Distinct Values SELECT DISTINCT FullName FROM Student; -- Select Distinct Values for Multiple Columns SELECT DISTINCT ID, FullName FROM Student;  The DISTINCT keyword removes duplicate rows from query results. ","version":null,"tagName":"h3"},{"title":"SELECT INTO Statement:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#select-into-statement","content":"-- Create a New Table from SELECT Query SELECT ID, FullName INTO NewTable FROM Student; -- Select Data from Newly Created Table SELECT * FROM NewTable;  The SELECT INTO statement creates a new table from the result of a query.  ","version":null,"tagName":"h3"},{"title":"VIEW:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#view","content":"A view is a virtual table based on the result of a SELECT statement. ","version":null,"tagName":"h2"},{"title":"CREATE VIEW:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#create-view","content":"-- Create a View CREATE VIEW HelloView AS SELECT FullName, Math FROM Student WHERE Math &gt; 5; -- Select Data from the View SELECT * FROM HelloView;  Use CREATE VIEW to define a view. ","version":null,"tagName":"h3"},{"title":"SQL Operators (Continued):​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#sql-operators-continued","content":"Additional SQL operators and their applications. ","version":null,"tagName":"h2"},{"title":"NOT NULL and IS NOT NULL:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#not-null-and-is-not-null","content":"-- Records with NULL Values SELECT ID, FullName, Math FROM Student WHERE Math IS NULL; -- Records with Non-NULL Values SELECT ID, FullName, Math FROM Student WHERE Math IS NOT NULL;  Check for NULL or non-NULL values using IS NULL and IS NOT NULL . Wildcards in LIKE Operator: Utilize % and _ for pattern matching in the LIKE operator. ","version":null,"tagName":"h3"},{"title":"Wildcards in LIKE Operator:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#wildcards-in-like-operator","content":"-- Pattern Matching with Wildcards SELECT FullName, Math FROM Student WHERE FullName LIKE '%U%';  % represents zero or more characters, and _ represents a single character in pattern matching.  ","version":null,"tagName":"h3"},{"title":"JOIN Operation:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#join-operation","content":"The JOIN operation combines rows from two or more tables based on related columns. ","version":null,"tagName":"h2"},{"title":"JOIN Operation:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#join-operation-1","content":"-- Combine Rows from Two Tables SELECT Student.ID, Student.FullName, Course.CourseName FROM Student JOIN Course ON Student.CourseID = Course.CourseID;  Use the JOIN keyword with specified conditions for combining rows.  ","version":null,"tagName":"h3"},{"title":"GROUP BY and HAVING:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#group-by-and-having","content":"The GROUP BY clause groups rows that have the same values in specified columns, and HAVING applies conditions to grouped data. ","version":null,"tagName":"h2"},{"title":"GROUP BY and HAVING:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#group-by-and-having-1","content":"-- Group by CourseID and Calculate Average Math Score SELECT CourseID, AVG(Math) AS AvgMathScore FROM Student GROUP BY CourseID HAVING AVG(Math) &gt; 7;  Use the GROUP BY clause for grouping and apply conditions with HAVING.  ","version":null,"tagName":"h3"},{"title":"Authentic Operators:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#authentic-operators","content":"","version":null,"tagName":"h2"},{"title":"Arithmetic:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#arithmetic","content":"-- Mathematical Wonders SELECT 5 + 3 AS 'Addition', 10 - 4 AS 'Subtraction', 6 * 2 AS 'Multiplication', 16 / 4 AS 'Division', 17 % 5 AS 'Modulo';  In this example, we perform basic arithmetic operations on numerical values, showcasing the versatility of SQL in handling mathematical tasks. ","version":null,"tagName":"h3"},{"title":"Comparison:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#comparison","content":"-- Unveiling Equality and More SELECT ID, FullName FROM Students WHERE Age = 25 OR Age &gt; 30;  Here, we retrieve student records based on age, utilizing comparison operators to filter results for specific age criteria. ","version":null,"tagName":"h3"},{"title":"Logical:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#logical","content":"-- Crafting Conditions with AND, OR, and NOT SELECT ID, FullName FROM Students WHERE Age &gt; 25 AND Department = 'Engineering';  Crafting a query that combines logical operators to filter students who are older than 25 and belong to the Engineering department. ","version":null,"tagName":"h3"},{"title":"Selecting Wisely:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#selecting-wisely","content":"","version":null,"tagName":"h2"},{"title":"SELECT Syntax:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#select-syntax","content":"-- Crafting the Perfect SELECT Statement SELECT FirstName, LastName, Age FROM Employees;  In this example, we select specific columns from the Employees table, demonstrating the fundamental syntax of the SELECT statement. ","version":null,"tagName":"h3"},{"title":"TOP & PERCENT:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#top--percent","content":"-- Limiting and Filtering Rows SELECT TOP 5 ID, ProductName, Price FROM Products ORDER BY Price DESC;  Limiting query results to the top 5 rows, showcasing the use of TOP in conjunction with ORDER BY to filter and sort data effectively. ","version":null,"tagName":"h3"},{"title":"ALIAS & DISTINCT:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#alias--distinct","content":"-- Bringing Clarity to Your Results SELECT AVG(Salary) AS 'Average Salary' FROM Employees;  Calculating the average salary and assigning it an alias for clarity, highlighting the use of aliases in result sets. ","version":null,"tagName":"h3"},{"title":"FROM, WHERE, VIEW, SELECT INTO:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#from-where-view-select-into","content":"-- Mastering the Essentials SELECT EmployeeID, FirstName, LastName INTO NewEmployeeTable FROM Employees WHERE Department = 'IT';  Creating a new table named NewEmployeeTable by selecting specific columns from the Employees table and filtering results based on the IT department.  ","version":null,"tagName":"h3"},{"title":"SQL Built-in Functions: A Symphony of Capabilities​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#sql-built-in-functions-a-symphony-of-capabilities","content":"","version":null,"tagName":"h2"},{"title":"String Functions Showcase:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#string-functions-showcase","content":"","version":null,"tagName":"h2"},{"title":"LOWER & UPPER:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#lower--upper","content":"-- Transforming Case with Flair SELECT LOWER('Hello') AS 'lower function', UPPER('Hi there') AS 'UPPER FUNCTION';  Applying the LOWER and UPPER functions to manipulate text case, showcasing the versatility of string functions. ","version":null,"tagName":"h3"},{"title":"LEN & REVERSE:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#len--reverse","content":"-- Revealing Lengths and Reversing Strings SELECT LEN('Database') AS 'Length', REVERSE('SQL') AS 'Reversed';  Using LEN to find the length of a string and REVERSE to reverse the characters, demonstrating string manipulation capabilities. ","version":null,"tagName":"h3"},{"title":"CONCAT & SUBSTRING:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#concat--substring","content":"-- Crafting and Extracting Strings SELECT CONCAT('Hello', ' ', 'World') AS 'CONCAT FUNCTION', SUBSTRING('123456789', 3, 4) AS 'SUBSTRING FUNCTION';  Combining strings with CONCAT and extracting a substring, exemplifying the power of string functions in SQL. ","version":null,"tagName":"h3"},{"title":"LTRIM & RTRIM:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#ltrim--rtrim","content":"-- Trimming with Finesse SELECT '|' + LTRIM(' Hi') + '|' AS 'LTRIM FUNCTION', '|' + RTRIM('Hi ') + '|' AS 'RTRIM FUNCTION';  Trimming leading and trailing spaces using LTRIM and RTRIM, showcasing string manipulation for cleaner outputs. ","version":null,"tagName":"h3"},{"title":"Datetime Functions: Unraveling Time's Mysteries:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#datetime-functions-unraveling-times-mysteries","content":"","version":null,"tagName":"h2"},{"title":"MONTH, DAY, YEAR:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#month-day-year","content":"-- Extracting Temporal Insights SELECT MONTH('11/13/2022') AS 'MONTH FUNCTION', DAY('11/13/2022') AS 'DAY FUNCTION', YEAR('11/13/2022') AS 'YEAR FUNCTION';  Extracting month, day, and year components from a date, unraveling temporal insights using datetime functions. ","version":null,"tagName":"h3"},{"title":"GETDATE & ISDATE:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#getdate--isdate","content":"-- Unleashing the Power of Time SELECT GETDATE() AS 'GETDATE FUNCTION', ISDATE('11/13/2022') AS 'ISDATE FUNCTION';  Utilizing GETDATE to retrieve the current date and time, along with ISDATE to validate a date string. ","version":null,"tagName":"h3"},{"title":"DATEPART:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#datepart","content":"-- Precision in Date and Time SELECT DATEPART(HOUR, '11/13/2022 19:20') AS 'DATEPART HOUR', DATEPART(MINUTE, '11/13/2022 19:20') AS 'DATEPART MINUTE';  Extracting specific components like hour and minute using DATEPART, providing precision in date and time manipulation. ","version":null,"tagName":"h3"},{"title":"Date Manipulation with DATEDIFF:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#date-manipulation-with-datediff","content":"-- Exploring the Gap Between Dates SELECT DATEDIFF(MONTH, '10/15/2020', '11/25/2022') AS 'DATEDIFF MONTHS';  Calculating the difference in months between two dates using DATEDIFF, demonstrating date manipulation capabilities. ","version":null,"tagName":"h3"},{"title":"Aggregate Functions: Bringing Data Together​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#aggregate-functions-bringing-data-together","content":"","version":null,"tagName":"h2"},{"title":"SUM & AVG:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#sum--avg","content":"-- Summing Up and Finding Averages SELECT SUM(Sales) AS 'Total Sales', AVG(Price) AS 'Average Price' FROM Products;  Aggregating data with SUM and AVG, showcasing their roles in summarizing numeric values. ","version":null,"tagName":"h3"},{"title":"MIN & MAX:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#min--max","content":"-- Uncovering Extremes SELECT MIN(Age) AS 'Minimum Age', MAX(Age) AS 'Maximum Age' FROM Employees;  Identifying the minimum and maximum values within a dataset using MIN and MAX aggregate functions. ","version":null,"tagName":"h3"},{"title":"COUNT:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#count","content":"-- Counting Rows Strategically SELECT COUNT(*) AS 'Total Records' FROM Customers;  Counting the total number of records in the Customers table, emphasizing the strategic use of COUNT. ","version":null,"tagName":"h3"},{"title":"Counting the COUNTs: Strategies Unveiled​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#counting-the-counts-strategies-unveiled","content":"","version":null,"tagName":"h3"},{"title":"COUNT(*) vs COUNT(1):​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#count-vs-count1","content":"-- Decoding the Mystery SELECT COUNT(*) AS 'Total Records', COUNT(1) AS 'Another Count' FROM Orders;  Comparing COUNT(*) and COUNT(1) to decode the mystery of counting rows effectively. ","version":null,"tagName":"h3"},{"title":"COUNT with DISTINCT:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#count-with-distinct","content":"-- Navigating Unique Territories SELECT COUNT(DISTINCT Department) AS 'Distinct Departments' FROM Employees;  Counting the distinct departments within the Employees table, illustrating the usage of COUNT with DISTINCT. ","version":null,"tagName":"h3"},{"title":"Ceiling & Floor: Elevating and Lowering Numbers​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#ceiling--floor-elevating-and-lowering-numbers","content":"","version":null,"tagName":"h3"},{"title":"CEILING & FLOOR:​","type":1,"pageTitle":"Querying and Data Modification","url":"/2023/12/25/Querying-and-Data-Modification#ceiling--floor","content":" -- Rounding Up and Down  ","version":null,"tagName":"h3"},{"title":"AWS cloud practitioner sample exam","type":0,"sectionRef":"#","url":"/2024/4/19/aws-cloud","content":"","keywords":"","version":null},{"title":"test​","type":1,"pageTitle":"AWS cloud practitioner sample exam","url":"/2024/4/19/aws-cloud#test","content":"Which compute option reduces costs when you commit to a consistent amount of compute usage for a 1-year or 3-year term? Spot Instances Savings Plans Reserved Instances Dedicated Hosts Which service enables you to consolidate and manage multiple AWS accounts from a central location? AWS Identity and Access Management (IAM) AWS Key Management Service (AWS KMS) AWS Organizations AWS Artifact Which action can you perform in Amazon CloudFront? Deliver content to customers through a global network of edge locations. Provision resources by using programming languages or a text file. Provision an isolated section of the AWS Cloud to launch resources in a virtual network that you define. Run infrastructure in a hybrid cloud approach. Which pillar of the AWS Well-Architected Framework focuses on using computing resources in ways that meet system requirements? Performance Efficiency Security Reliability Operational Excellence Which statement best describes Elastic Load Balancing? A service that provides data that you can use to monitor your applications, optimize resource utilization, and respond to system-wide performance changes A service that enables you to set up, manage, and scale a distributed in-memory or cache environment in the cloud A service that monitors your applications and automatically adds or removes capacity from your resource groups in response to changing demand A service that distributes incoming traffic across multiple targets, such as Amazon EC2 instances Which statement is TRUE for AWS Lambda? The first step in using AWS Lambda is provisioning a server. You pay only for compute time while your code is running. Before using AWS Lambda, you must prepay for your estimated compute time. To use AWS Lambda, you must configure the servers that run your code. You are running an Amazon EC2 instance and want to store data in an attached resource. Your data is temporary and will not be kept long term. Which resource should you use? Amazon Elastic Block Store (Amazon EBS) volume Subnet Amazon S3 bucket Instance store Which tool enables you to visualize, understand, and manage your AWS costs and usage over time? AWS Budgets AWS Artifact AWS Pricing Calculator AWS Cost Explorer Which tool is used to automate actions for AWS services and applications through scripts? AWS Command Line Interface Amazon QLDB AWS Snowball Amazon Redshift Which AWS Trusted Advisor category includes checks for high-utilization EC2 instances? Security Fault Tolerance Performance Cost Optimization Which virtual private cloud (VPC) component controls inbound and outbound traffic for Amazon EC2 instances? Internet gateway Security group Subnet Network access control list Which statement best describes AWS Marketplace? A resource that provides guidance, architectural reviews, and ongoing communication with your company as you plan, deploy, and optimize your applications A resource that can answer questions about best practices and assist with troubleshooting issues A digital catalog that includes thousands of software listings from independent software vendors An online tool that inspects your AWS environment and provides real-time guidance in accordance with AWS best practices Which service enables you to review details for user activities and API calls that have occurred within your AWS environment? AWS CloudTrail Amazon Inspector AWS Trusted Advisor Amazon CloudWatch You want Amazon S3 to monitor your objects’ access patterns. Which storage class should you use? Amazon S3 Intelligent-Tiering Amazon S3 One Zone-IA Amazon S3 Standard-IA Amazon S3 Glacier Flexible Retrieval In the S3 Intelligent-Tiering storage class, Amazon S3 moves objects between a frequent access tier and an infrequent access tier. Which storage classes are used for these tiers? (Select TWO.) Amazon S3 Glacier Flexible Retrieval Amazon S3 Standard-IA Amazon S3 One Zone-IA Amazon S3 Glacier Deep Archive Amazon S3 Standard Which service enables you to build the workflows that are required for human review of machine learning predictions? Amazon Augmented AI Amazon Aurora Amazon Textract Amazon Lex Which Perspective of the AWS Cloud Adoption Framework focuses on recovering IT workloads to meet the requirements of your business stakeholders? Operations Perspective Governance Perspective Business Perspective People Perspective Which Support plans include access to all AWS Trusted Advisor checks? (Select TWO.) Basic AWS Free Tier Enterprise Developer Business Which service is used to transfer up to 100 PB of data to AWS? AWS DeepRacer AWS Snowmobile Amazon Neptune Amazon CloudFront Which actions can you perform in Amazon Route 53? (Select TWO.) Manage DNS records for domain names. Access AWS security and compliance reports and select online agreements. Monitor your applications and respond to system-wide performance changes. Connect user requests to infrastructure in AWS and outside of AWS. Automate the deployment of workloads into your AWS environment. You want to store data in a key-value database. Which service should you use? Amazon Aurora Amazon RDS Amazon DocumentDB Amazon DynamoDB Which service is used to quickly deploy and scale applications on AWS? AWS Elastic Beanstalk Amazon CloudFront AWS Outposts AWS Snowball Which statement best describes Amazon GuardDuty? A service that lets you monitor network requests that come into your web applications A service that provides intelligent threat detection for your AWS infrastructure and resources A service that checks applications for security vulnerabilities and deviations from security best practices A service that helps protect your applications against distributed denial-of-service (DDoS) attacks Which component or service enables you to establish a dedicated private connection between your data center and virtual private cloud (VPC)? AWS Direct Connect Amazon CloudFront Internet gateway Virtual private gateway You want to send and receive messages between distributed application components. Which service should you use? Amazon ElastiCache AWS Snowball Amazon Route 53 Amazon Simple Queue Service (Amazon SQS) Which migration strategy involves changing how an application is architected and developed, typically by using cloud-native features? Repurchasing Rehosting Refactoring Replatforming Which tasks are the responsibilities of AWS? (Select TWO.) Creating IAM users and groups Maintaining virtualization infrastructure Training company employees on how to use AWS services Configuring AWS infrastructure devices Configuring security groups on Amazon EC2 instances Which service is used to run containerized applications on AWS? Amazon Elastic Kubernetes Service (Amazon EKS) Amazon Aurora Amazon SageMaker Amazon Redshift You want to store data in a volume that is attached to an Amazon EC2 instance. Which service should you use? Amazon ElastiCache AWS Lambda Amazon Simple Storage Service (Amazon S3) Amazon Elastic Block Store (Amazon EBS) Which statement best describes an Availability Zone? The server from which Amazon CloudFront gets your files A fully isolated portion of the AWS global infrastructure A site that Amazon CloudFront uses to cache copies of content for faster delivery to users at any location A separate geographical location with multiple locations that are isolated from each other  ","version":null,"tagName":"h2"},{"title":"Answer​","type":1,"pageTitle":"AWS cloud practitioner sample exam","url":"/2024/4/19/aws-cloud#answer","content":"Savings Plans 1.00 / 1 The correct response option is Savings Plans. Amazon EC2 Savings Plans enable you to reduce your compute costs by committing to a consistent amount of compute usage for a 1-year or 3-year term. This results in savings of up to 72% over On-Demand Instance costs. Any usage up to the commitment is charged at the discounted Savings Plan rate (for example, $10 an hour). Any usage beyond the commitment is charged at regular On-Demand Instance rates. The other response options are incorrect because: Reserved Instances are a billing discount that is applied to the use of On-Demand Instances in your account. You can purchase Standard Reserved and Convertible Reserved Instances for a one-year or three-year term, and Scheduled Reserved Instances for a one-year term. Unlike Savings Plans, Reserved Instances do not require you to commit to a consistent amount of compute usage over the duration of the contract. Spot Instances are ideal for workloads with flexible start and end times or that can withstand interruptions. Spot Instances leverage unused EC2 computing capacity and offer you cost savings at up to 90% of On-Demand Instance prices. Dedicated Hosts are physical servers with EC2 instance capacity that is fully dedicated to your use. You can use your existing per-socket, per-core, or per-VM software licenses to help maintain license compliance. You can purchase On-Demand Dedicated Hosts or Reserved Dedicated Hosts. Of all the Amazon EC2 options that were covered in this course, Dedicated Hosts are the most expensive. AWS Organizations 1.00 / 1 The correct response option is AWS Organizations. In AWS Organizations, you can centrally control permissions for the accounts in your organization by using service control policies (SCPs). Additionally, you can use the consolidated billing feature in AWS Organizations to combine usage and receive a single bill for multiple AWS accounts. The other response options are incorrect because: AWS Identity and Access Management (IAM) is a service that you can use to manage access to AWS services and resources. AWS Artifact is a service that enables you to access AWS security and compliance reports and special online agreements. AWS Key Management Service (AWS KMS) enables you to create, manage, and use cryptographic keys. [https://aws.amazon.com/organizations/: https://aws.amazon.com/organizations/] Deliver content to customers through a global network of edge locations. 1.00 / 1 The correct response is Deliver content to customers through a global network of edge locations. Amazon CloudFront is a content delivery service. It uses a network of edge locations to cache content and deliver content to customers all over the world. When content is cached, it is stored locally as a copy. This content might be video files, photos, webpages, and so on. The other response options are incorrect because: Run infrastructure in a hybrid cloud approach - This action can be performed with AWS Outposts. Provision resources by using programming languages or a text file - This action can be performed in AWS CloudFormation. Provision an isolated section of the AWS Cloud to launch resources in a virtual network that you define - This action can be performed in Amazon Virtual Private Cloud (Amazon VPC). [**Amazon CloudFront: https://aws.amazon.com/cloudfront/] Performance Efficiency 1.00 / 1** The correct response option is Performance Efficiency. The Performance Efficiency pillar focuses on using computing resources efficiently to meet system requirements, and to maintain that efficiency as demand changes and technologies evolve. The other responses are incorrect because: The Operational Excellence pillar includes the ability to run workloads effectively, gain insights into their operations, and continuously improve supporting processes to deliver business value. The Security pillar focuses on protecting data, systems, and assets. It also focuses on using cloud technologies to improve the security of your workloads. The Reliability pillar focuses on the ability of a workload to consistently and correctly perform its intended functions. [AWS Well-Architected Framework: https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html] A service that distributes incoming traffic across multiple targets, such as Amazon EC2 instances 1.00 / 1 The correct response option is A service that distributes incoming traffic across multiple targets, such as Amazon EC2 instances. A load balancer acts as a single point of contact for all incoming web traffic to your Auto Scaling group. This means that as Amazon EC2 instances are added or removed in response to the amount of incoming traffic, these requests are routed to the load balancer first and then spread across multiple resources that will handle them. The other response options are incorrect because: A service that monitors your applications and automatically adds or removes capacity from your resource groups in response to changing demand - This response option describes AWS Auto Scaling. A service that provides data that you can use to monitor your applications, optimize resource utilization, and respond to system-wide performance changes - This response option describes Amazon CloudWatch. Although Elastic Load Balancing does optimize resource utilization by distributing incoming traffic across available resources, this would not be the best response option because Elastic Load Balancing does not provide all the other listed features. A service that enables you to set up, manage, and scale a distributed in-memory or cache environment in the cloud - This response option describes Amazon ElastiCache. [Elastic Load Balancing: https://aws.amazon.com/elasticloadbalancing/] You pay only for compute time while your code is running. 1.00 / 1 The correct response option is You pay only for compute time while your code is running. AWS Lambda is a service that lets you run code without needing to provision or manage servers. While using AWS Lambda, you pay only for the compute time that you consume. You are charged only when your code is running. With AWS Lambda, you can run code for virtually any type of application or backend service, all with zero administration. [AWS Lambda: https://aws.amazon.com/lambda/] Instance store 1.00 / 1 The correct response option is instance store. Instance stores are ideal for temporary data that does not need to be kept long term. When an Amazon EC2 instance is stopped or terminated, all the data that has been written to the attached instance store is deleted. The other response options are incorrect because: Amazon EBS volumes are ideal for data that needs to be retained. When an Amazon EC2 instance is stopped or terminated, all of the data on the attached EBS volume is still available. Amazon S3 buckets cannot be attached to Amazon EC2 instances. A subnet is a section of a virtual private cloud (VPC) in which you can group resources based on security or operational needs. [Amazon EC2 instance store: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html] AWS Cost Explorer 1.00 / 1 The correct response option is AWS Cost Explorer. With AWS Cost Explorer, you can quickly create custom reports to analyze your AWS cost and usage data. The other response options are incorrect because: AWS Budgets lets you set custom alerts that will notify you when your service usage exceeds (or is forecasted to exceed) the amount that you have budgeted. AWS Pricing Calculator lets you explore AWS services and create an estimate for the cost of your use cases on AWS. In the AWS Pricing Calculator, you can enter details for your cloud computing requirements and then receive a detailed estimate that can be exported and shared. AWS Artifact is a service that enables you to access AWS security and compliance reports and special online agreements. [AWS Cost Explorer: https://aws.amazon.com/aws-cost-management/aws-cost-explorer/] AWS Command Line Interface 1.00 / 1 The correct response option is AWS Command Line Interface. The AWS Command Line Interface (AWS CLI) enables you to control multiple AWS services directly from the command line within one tool. For example, you can use commands to start an Amazon EC2 instance, connect an Amazon EC2 instance to a specific Auto Scaling group, and more. The AWS CLI is available for users on Windows, macOS, and Linux. The other response options are incorrect because: Amazon Redshift is a data warehousing service that you can use for big data analytics. It offers the ability to collect data from many sources and help you to understand relationships and trends across your data. Amazon Quantum Ledger Database (Amazon QLDB) is a ledger database service. You can use Amazon QLDB to review a complete history of all the changes that have been made to your application data. AWS Snowball is a device that enables you to transfer large amounts of data into and out of AWS. [AWS Command Line Interface: https://aws.amazon.com/cli/] Security group 1.00 / 1 The correct response option is security group. A security group is a virtual firewall that controls inbound and outbound traffic for an Amazon EC2 instance. By default, a security group denies all inbound traffic and allows all outbound traffic. You can add custom rules to configure which traffic should be allowed or denied. The other response options are incorrect because: A subnet is a section of a VPC in which you can group resources based on security or operational needs. A network access control list (ACL) is a virtual firewall that controls inbound and outbound traffic at the subnet level. An internet gateway is a connection between a VPC and the internet. It allows public traffic from the internet to access a VPC. [Security groups for your VPC: https://docs.aws.amazon.com/vpc/latest/userguide/vpc-security-groups.html] A digital catalog that includes thousands of software listings from independent software vendors 1.00 / 1 The correct response option is A digital catalog that includes thousands of listings from independent software vendors. You can use AWS Marketplace to find, test, and buy software that runs on AWS. The other response options are incorrect because: A resource that can answer questions about best practices and assist with troubleshooting issues - This response option describes AWS Support. A resource that provides guidance, architectural reviews, and ongoing communication with your company as you plan, deploy, and optimize your applications - This response option describes a Technical Account Manager (TAM). An online tool that inspects your AWS environment and provides real-time guidance in accordance with AWS best practices - This response option describes AWS Trusted Advisor. [AWS Marketplace: https://aws.amazon.com/marketplace] AWS CloudTrail 1.00 / 1 The correct response option is AWS CloudTrail. With CloudTrail, you can view a complete history of user activity and API calls for your applications and resources. Events are typically updated in CloudTrail within 15 minutes after an API call was made. You can filter events by specifying the time and date that an API call occurred, the user who requested the action, the type of resource that was involved in the API call, and more. The other response options are incorrect because: Amazon CloudWatch is a service that provides data that you can use to monitor your applications, optimize resource utilization, and respond to system-wide performance changes. Amazon Inspector is a service that checks applications for security vulnerabilities and deviations from security best practices. AWS Trusted Advisor is an online tool that inspects your AWS environment and provides real-time guidance in accordance with AWS best practices. [AWS CloudTrail: https://aws.amazon.com/cloudtrail/] Amazon S3 Intelligent-Tiering 1.00 / 1 The correct response option is Amazon S3 Intelligent-Tiering. In the Amazon S3 Intelligent-Tiering storage class, Amazon S3 monitors objects access patterns. If you haven't accessed an object for 30 consecutive days, Amazon S3 automatically moves it to the infrequent access tier, Amazon S3 Standard-IA. If you access an object in the infrequent access tier, Amazon S3 automatically moves it to the frequent access tier, Amazon S3 Standard. The other response options are incorrect because: Amazon S3 Glacier Flexible Retrieval is a low-cost storage class that is ideal for data archiving. You can retrieve objects stored in the Amazon S3 Glacier Flexible Retrieval storage class within a few minutes to a few hours. The Amazon S3 Standard-IA storage class is ideal for data that is infrequently accessed but requires high availability when needed. Both Amazon S3 Standard and Amazon S3 Standard-IA store data in a minimum of three Availability Zones. Amazon S3 Standard-IA provides the same level of availability as Amazon S3 Standard but at a lower storage price. Amazon S3 One Zone-IA is ideal for infrequently accessed data that does not require high availability. [Amazon S3 storage classes: https://aws.amazon.com/s3/storage-classes/] Amazon Augmented AI 1.00 / 1 The correct response option is Amazon Augmented AI. Amazon Augmented AI (Amazon A2I) provides built-in human review workflows for common machine learning use cases, such as content moderation and text extraction from documents. With Amazon A2I, you can also create your own workflows for machine learning models built on Amazon SageMaker or any other tools. The other response options are incorrect because: Amazon Textract is a machine learning service that automatically extracts text and data from scanned documents. Amazon Lex is a service that enables you to build conversational interfaces using voice and text. Amazon Aurora is an enterprise-class relational database. [Amazon Augmented AI: https://aws.amazon.com/augmented-ai/] Operations Perspective 1.00 / 1 The correct response option is Operations Perspective. The Operations Perspective of the AWS Cloud Adoption Framework also includes principles for operating in the cloud by using agile best practices. The other response options are incorrect because: The Business Perspective helps you to move from a model that separates business and IT strategies into a business model that integrates IT strategy. The People Perspective helps Human Resources (HR) employees prepare their teams for cloud adoption by updating organizational processes and staff skills to include cloud-based competencies. The Governance Perspective helps you understand how to update the staff skills and organizational processes that are necessary to ensure business governance in the cloud. [Whitepaper: An Overview of the AWS Cloud Adoption Framework: https://d1.awsstatic.com/whitepapers/aws_cloud_adoption_framework.pdf] Enterprise;Business 1.00 / 1 The two correct response options are: Enterprise Business The other response options are incorrect because: The Basic and Developer Support plans provide access to a limited selection of AWS Trusted Advisor checks. The AWS Free Tier is not a Support plan. It is a program that consists of three types of offers that allow customers to use AWS services without incurring costs: Always free, 12 months free, and Trials. [**AWS Trusted Advisor: https://aws.amazon.com/premiumsupport/technology/trusted-advisor/] AWS Snowmobile 1.00 / 1** The correct response option is AWS Snowmobile. AWS Snowmobile is a service that is used for transferring up to 100 PB of data to AWS. Each Snowmobile is a 45-foot long shipping container that is pulled by a semi-trailer truck. The other response options are incorrect because: Amazon Neptune is a graph database service. You can use Amazon Neptune to build and run applications that work with highly connected datasets, such as recommendation engines, fraud detection, and knowledge graphs. Amazon CloudFront is a content delivery service. AWS DeepRacer is an autonomous 1/18 scale race car that you can use to test reinforcement learning models. [AWS Snow Family: https://aws.amazon.com/snow/] Manage DNS records for domain names.;Connect user requests to infrastructure in AWS and outside of AWS. 1.00 / 1 The correct two response options are: Connect user requests to infrastructure in AWS and outside of AWS. Manage DNS records for domain names. Amazon Route 53 is a DNS web service. It gives developers and businesses a reliable way to route end users to internet applications that are hosted in AWS. Additionally, you can transfer DNS records for existing domain names that are currently managed by other domain registrars, or register new domain names directly within Amazon Route 53. The other response options are incorrect because: Monitor your applications and respond to system-wide performance changes - These actions can be performed in Amazon CloudWatch. Access AWS security and compliance reports and special online agreements - This action can be performed in AWS Artifact. Automate the deployment of workloads into your AWS environment - This action can be performed with AWS Quick Starts. [**Amazon Route 53: https://aws.amazon.com/route53/] Amazon DynamoDB 1.00 / 1** The correct response option is Amazon DynamoDB. Amazon DynamoDB is a key-value database service. A key-value database might include data pairs such as Name: John Doe, Address: 123 Any Street, and City: Any town. In a key-value database, you can add or remove attributes from items in the table at any time. Additionally, not every item in the table has to have the same attributes. The other response options are incorrect because: Amazon Relational Database Service (Amazon RDS) and Amazon Aurora use structured query language (SQL) to store and query data. They are not key-value databases. Amazon DocumentDB is a document database service that supports MongoDB workloads. [Amazon DynamoDB: https://aws.amazon.com/dynamodb/] AWS Elastic Beanstalk 1.00 / 1 The correct response option is AWS Elastic Beanstalk. You upload your application, and Elastic Beanstalk automatically handles the deployment details of capacity provisioning, load balancing, auto-scaling, and application health monitoring. The other response options are incorrect because: AWS Outposts is a service that enables you to run infrastructure in a hybrid cloud approach. Amazon CloudFront is a content delivery service. AWS Snowball is a device that enables you to transfer large amounts of data into and out of AWS. [AWS Quick Starts: https://aws.amazon.com/quickstart/?solutions-all.sort-by=item.additionalFields.sortDate&amp;solutions-all.sort-order=desc&amp;awsf. filter-content-type=all&amp;awsf.filter-tech-category=all&amp;awsf.filter-industry=*all] A service that provides intelligent threat detection for your AWS infrastructure and resources 1.00 / 1 The correct response option is A service that provides intelligent threat detection for your AWS infrastructure and resources. AWS GuardDuty identifies threats by continually monitoring the network activity and account behavior within your AWS environment. The other response options are incorrect because: A service that helps protect your applications against distributed denial-of-service (DDoS) attacks - This response option describes AWS Shield. A service that checks applications for security vulnerabilities and deviations from security best practices - This response option describes Amazon Inspector. A service that lets you monitor network requests that come into your web applications - This response option describes AWS WAF. [Amazon GuardDuty: https://aws.amazon.com/guardduty/] AWS Direct Connect 1.00 / 1 The correct response option is AWS Direct Connect. AWS Direct Connect is a service that enables you to establish a dedicated private connection between your data center and VPC. The private connection that AWS Direct Connect provides helps you to reduce network costs and increase the amount of bandwidth that can travel through your network. The other response options are incorrect because: Amazon CloudFront is a content delivery service. It uses a network of edge locations to cache content and deliver content to customers all over the world. A virtual private gateway enables you to establish a virtual private network (VPN) connection between your VPC and a private network, such as an on-premises data center or internal corporate network. A virtual private gateway allows traffic into the VPC only if it is coming from an approved network. An internet gateway is a connection between a VPC and the internet. It allows public traffic from the internet to access a VPC. [AWS Direct Connect: https://aws.amazon.com/directconnect/] Amazon Simple Queue Service (Amazon SQS) 1.00 / 1 The correct response option is Amazon Simple Queue Service (Amazon SQS). Amazon SQS is a message queuing service. Using Amazon SQS, you can send, store, and receive messages between software components at any volume size, without losing messages or requiring other services to be available. In Amazon SQS, an application sends messages into a queue. A user or service retrieves a message from the queue, processes it, and then deletes it from the queue. The other response options are incorrect because: AWS Snowball is a device that enables you to transfer large amounts of data into and out of AWS. Amazon ElastiCache is a service that adds caching layers on top of your databases to help improve the read times of common requests. Amazon Route 53 is a DNS web service. It gives developers and businesses a reliable way to route end users to internet applications that are hosted in AWS. Additionally, you can transfer DNS records for existing domain names that are currently managed by other domain registrars or register new domain names directly in Amazon Route 53. [Amazon SQS: https://aws.amazon.com/sqs/] Refactoring 1.00 / 1 The correct response option is Refactoring. The other response options are incorrect because: Repurchasing involves replacing an existing application with a cloud-based version, such as software found in AWS Marketplace. Re-hosting involves moving an application to the cloud with little to no modifications to the application itself. It is also known as lift and shift. Re-platforming involves selectively optimizing aspects of an application to achieve benefits in the cloud without changing the core architecture of the application. It is also known as lift, tinker, and shift. [6 Strategies for Migrating Applications to the Cloud: https://aws.amazon.com/blogs/enterprise-strategy/6-strategies-for-migrating-applications-to-the-cloud/] Maintaining virtualization infrastructure;Configuring AWS infrastructure devices 1.00 / 1The two correct response options are: Maintaining virtualization infrastructure Configuring AWS infrastructure devices The other three response options are tasks that are the responsibilities of customers. [**AWS shared responsibility model: https://aws.amazon.com/compliance/shared-responsibility-model/] Amazon Elastic Kubernetes Service (Amazon EKS) 1.00 / 1** The correct response option is Amazon Elastic Kubernetes Service (Amazon EKS). Amazon EKS is a fully managed service that you can use to run Kubernetes on AWS. Kubernetes is open-source software that enables you to deploy and manage containerized applications at scale. Containers provide you with a standard way to package your application's code and dependencies into a single object. Containers are frequently used for processes and workflows in which there are essential requirements for security, reliability, and scalability. The other response options are incorrect because: Amazon SageMaker is a service that enables you to quickly build, train, and deploy machine learning models. Amazon Aurora is an enterprise-class relational database. Amazon Redshift is a data warehousing service that you can use for big data analytics. [Amazon EKS: https://aws.amazon.com/eks/] Amazon Elastic Block Store (Amazon EBS) 1.00 / 1 The correct response option is Amazon Elastic Block Store (Amazon EBS). Amazon EBS provides block-level storage volumes that you can use with Amazon EC2 instances. If you stop or terminate an Amazon EC2 instance, all the data on the attached EBS volume remains available. The other response options are incorrect because: Amazon Simple Storage Service (Amazon S3) is a service that provides object-level storage. Amazon S3 stores data as objects within buckets. AWS Lambda is a service that lets you run code without provisioning or managing servers. Amazon ElastiCache is a service that adds caching layers on top of your databases to help improve the read times of common requests. [Amazon EBS: https://aws.amazon.com/ebs/] A fully isolated portion of the AWS global infrastructure 1.00 / 1 The correct response option is A fully isolated portion of the AWS global infrastructure. An Availability Zone is a single data center or a group of data centers within a Region. Availability Zones are located tens of miles apart from each other. This helps them to provide inter-connectivity to support the services and applications that run within a Region. The other response options are incorrect because: A separate geographical location with multiple locations that are isolated from each other - This response option describes a Region. The server from which Amazon CloudFront gets your files - This response option describes an origin. A site that Amazon CloudFront uses to cache copies of content for faster delivery to users at any location - This response option describes an Edge location. [AWS global infrastructure: https://aws.amazon.com/about-aws/global-infrastructure/] ","version":null,"tagName":"h2"},{"title":"SQL FOR EVERYONE - THE DEFINITIVE GUIDE","type":0,"sectionRef":"#","url":"/2024/1/21/SQL-cheatsheet","content":"","keywords":"","version":null},{"title":"Introduction to SQL​","type":1,"pageTitle":"SQL FOR EVERYONE - THE DEFINITIVE GUIDE","url":"/2024/1/21/SQL-cheatsheet#introduction-to-sql","content":"SQL is a standard language designed for managing data in relational databases. It's commonly used to query, insert, update, and modify data. Most RDBMS (Relational Database Management System) like MySQL, SQLite, Oracle, and PostgreSQL use SQL. As a data analyst, you'll often work with large volumes of data stored in these databases. SQL becomes an essential tool to retrieve, manipulate, and analyze this data. ","version":null,"tagName":"h2"},{"title":"1.1 RDBMS and Tables​","type":1,"pageTitle":"SQL FOR EVERYONE - THE DEFINITIVE GUIDE","url":"/2024/1/21/SQL-cheatsheet#11-rdbms-and-tables","content":"In SQL, data is stored in tables, just like an Excel spreadsheet. A table is made up of rows (records) and columns (fields). Here's an example of a table, Employees: EmployeeID\tFirstName\tLastName\tPosition1\tJohn\tDoe\tAnalyst 2\tJane\tDoe\tEngineer 3\tMary\tJohnson\tManager ","version":null,"tagName":"h3"},{"title":"2. Basic SQL Syntax​","type":1,"pageTitle":"SQL FOR EVERYONE - THE DEFINITIVE GUIDE","url":"/2024/1/21/SQL-cheatsheet#2-basic-sql-syntax","content":"Let's look at the fundamental SQL commands: SELECT, FROM, WHERE, GROUP BY, HAVING, and ORDER BY. ","version":null,"tagName":"h2"},{"title":"2.1 SELECT and FROM​","type":1,"pageTitle":"SQL FOR EVERYONE - THE DEFINITIVE GUIDE","url":"/2024/1/21/SQL-cheatsheet#21-select-and-from","content":"The SELECT statement is used to select data from a database, and the FROMstatement specifies which table to get the data from. SELECT FirstName, LastName FROM Employees;  This query retrieves all first and last names from the Employees table. If you want to select all columns, use the * symbol: SELECT * FROM Employees;  ","version":null,"tagName":"h3"},{"title":"2.2 WHERE​","type":1,"pageTitle":"SQL FOR EVERYONE - THE DEFINITIVE GUIDE","url":"/2024/1/21/SQL-cheatsheet#22-where","content":"The WHERE clause is used to filter records: SELECT * FROM Employees WHERE Position = 'Analyst';  This query retrieves all data for employees who are analysts. ","version":null,"tagName":"h3"},{"title":"2.3 GROUP BY and HAVING​","type":1,"pageTitle":"SQL FOR EVERYONE - THE DEFINITIVE GUIDE","url":"/2024/1/21/SQL-cheatsheet#23-group-by-and-having","content":"GROUP BY groups rows that have the same values in specified columns into aggregated data. HAVING is used instead of WHERE with aggregated data. SELECT Position, COUNT(*) FROM Employees GROUP BY Position HAVING COUNT(*) &gt; 1;  This query shows positions held by more than one employee. ","version":null,"tagName":"h3"},{"title":"2.4 ORDER BY​","type":1,"pageTitle":"SQL FOR EVERYONE - THE DEFINITIVE GUIDE","url":"/2024/1/21/SQL-cheatsheet#24-order-by","content":"ORDER BY is used to sort the data in ascending or descending order: SELECT * FROM Employees ORDER BY LastName ASC;  This query sorts employees by their last name in ascending order. ","version":null,"tagName":"h3"},{"title":"3. Querying Data​","type":1,"pageTitle":"SQL FOR EVERYONE - THE DEFINITIVE GUIDE","url":"/2024/1/21/SQL-cheatsheet#3-querying-data","content":"The SELECT statement is not just for selecting simple rows. We can use it to perform calculations, concatenations, and more. SELECT FirstName || ' ' || LastName as FullName, Position FROM Employees; This query concatenates the first and last names, separated by a space, and displays it as FullName.  ","version":null,"tagName":"h2"},{"title":"4. Filtering and Sorting Data​","type":1,"pageTitle":"SQL FOR EVERYONE - THE DEFINITIVE GUIDE","url":"/2024/1/21/SQL-cheatsheet#4-filtering-and-sorting-data","content":"Apart from WHERE and ORDER BY, SQL offers BETWEEN, LIKE, and IN to filter data. ","version":null,"tagName":"h2"},{"title":"4.1 BETWEEN​","type":1,"pageTitle":"SQL FOR EVERYONE - THE DEFINITIVE GUIDE","url":"/2024/1/21/SQL-cheatsheet#41-between","content":"BETWEEN is used to filter by a range: SELECT * FROM Orders WHERE OrderDate BETWEEN '2023-01-01' AND '2023-12-31';  This query selects all orders placed in the year 2023. ","version":null,"tagName":"h3"},{"title":"4.2 LIKE and ILIKE​","type":1,"pageTitle":"SQL FOR EVERYONE - THE DEFINITIVE GUIDE","url":"/2024/1/21/SQL-cheatsheet#42-like-and-ilike","content":"LIKE is used in a WHERE clause to search for a specified pattern in a column. The &quot;%&quot; sign is used to define wildcards (missing letters) both before and after the pattern. Also, note that LIKE is case sensitive. ILIKE can be used for case-insensitive search. SELECT * FROM Employees WHERE FirstName LIKE 'J%';  This query selects all employees with a first name starting with 'J'. ","version":null,"tagName":"h3"},{"title":"4.3 IN​","type":1,"pageTitle":"SQL FOR EVERYONE - THE DEFINITIVE GUIDE","url":"/2024/1/21/SQL-cheatsheet#43-in","content":"IN allows you to specify multiple values in a WHERE clause: SELECT * FROM Employees WHERE Position IN ('Analyst', 'Engineer');  This query selects all analysts and engineers. ","version":null,"tagName":"h3"},{"title":"5. Joining Tables​","type":1,"pageTitle":"SQL FOR EVERYONE - THE DEFINITIVE GUIDE","url":"/2024/1/21/SQL-cheatsheet#5-joining-tables","content":"JOIN statements are used to combine rows from two or more tables based on a related column. The different types of joins include INNER JOIN, LEFT (OUTER) JOIN, RIGHT (OUTER) JOIN, and FULL (OUTER) JOIN. Consider this additional table, Departments: DepartmentID\tDepartmentName1\tIT 2\tSales 3\tHR And suppose we add a DepartmentID field to the Employees table. Here's how we can use different types of joins: ","version":null,"tagName":"h2"},{"title":"5.1 INNER JOIN​","type":1,"pageTitle":"SQL FOR EVERYONE - THE DEFINITIVE GUIDE","url":"/2024/1/21/SQL-cheatsheet#51-inner-join","content":"SELECT Employees.LastName, Employees.FirstName, Departments.DepartmentName FROM Employees INNER JOIN Departments ON Employees.DepartmentID = Departments.DepartmentID;  This query retrieves the list of employees along with their respective department names. JOIN More Than 2 Tables -- Example of INNER JOIN with 3 tables SELECT c.CustomerID, c.FullName, o.FoodName, d.FullAddress FROM Customer c INNER JOIN CustomerOrder o ON c.CustomerID = o.CustomerID INNER JOIN DeliveryAddress d ON d.ID = o.DeliveryAddressID;  Extending the concept of INNER JOIN to involve three tables for a more comprehensive result set. ","version":null,"tagName":"h3"},{"title":"5.2 LEFT (OUTER) JOIN​","type":1,"pageTitle":"SQL FOR EVERYONE - THE DEFINITIVE GUIDE","url":"/2024/1/21/SQL-cheatsheet#52-left-outer-join","content":"SELECT Employees.LastName, Employees.FirstName, Departments.DepartmentName FROM Employees LEFT JOIN Departments ON Employees.DepartmentID = Departments.DepartmentID;  This query retrieves all employees and their departments, including employees with no department (the DepartmentName for them will be NULL). ","version":null,"tagName":"h3"},{"title":"5.3 RIGHT (OUTER) JOIN​","type":1,"pageTitle":"SQL FOR EVERYONE - THE DEFINITIVE GUIDE","url":"/2024/1/21/SQL-cheatsheet#53-right-outer-join","content":"SELECT Employees.LastName, Employees.FirstName, Departments.DepartmentName FROM Employees RIGHT JOIN Departments ON Employees.DepartmentID = Departments.DepartmentID;  This query retrieves all departments and their employees, including departments with no employees. ","version":null,"tagName":"h3"},{"title":"5.4 FULL (OUTER) JOIN​","type":1,"pageTitle":"SQL FOR EVERYONE - THE DEFINITIVE GUIDE","url":"/2024/1/21/SQL-cheatsheet#54-full-outer-join","content":"SELECT Employees.LastName, Employees.FirstName, Departments.DepartmentName FROM Employees FULL JOIN Departments ON Employees.DepartmentID = Departments.DepartmentID;  This query retrieves all combinations of employees and departments, including employees with no department and departments with no employees. ","version":null,"tagName":"h3"},{"title":"6. Aggregation Functions​","type":1,"pageTitle":"SQL FOR EVERYONE - THE DEFINITIVE GUIDE","url":"/2024/1/21/SQL-cheatsheet#6-aggregation-functions","content":"SQL provides several functions to perform calculations on data, such as COUNT(), SUM(), AVG(), MIN(), MAX(), and GROUP_CONCAT(). SELECT COUNT(*) FROM Orders WHERE OrderDate BETWEEN '2023-01-01' AND '2023-12-31';  This query returns the total number of orders placed in the year 2023. ","version":null,"tagName":"h2"},{"title":"7. Subqueries and Nested Queries​","type":1,"pageTitle":"SQL FOR EVERYONE - THE DEFINITIVE GUIDE","url":"/2024/1/21/SQL-cheatsheet#7-subqueries-and-nested-queries","content":"A subquery is a SQL query nested inside a larger query. A subquery may occur in: A SELECT clauseA FROM clauseA WHERE clause The subquery can be nested inside a SELECT, INSERT, UPDATE, or DELETE statement or inside another subquery. SELECT EmployeeID, FirstName, Position FROM Employees WHERE EmployeeID IN (SELECT EmployeeID FROM Orders WHERE OrderTotal &gt; 1000);  This query selects all employees who have made orders totaling more than 1000. ","version":null,"tagName":"h2"},{"title":"8. Modifying Database Information​","type":1,"pageTitle":"SQL FOR EVERYONE - THE DEFINITIVE GUIDE","url":"/2024/1/21/SQL-cheatsheet#8-modifying-database-information","content":"SQL allows you to insert, update, and delete data with INSERT, UPDATE, and DELETE commands respectively. Be careful when using these commands as you can change your data permanently. ","version":null,"tagName":"h2"},{"title":"8.1 INSERT​","type":1,"pageTitle":"SQL FOR EVERYONE - THE DEFINITIVE GUIDE","url":"/2024/1/21/SQL-cheatsheet#81-insert","content":"INSERT INTO Employees (EmployeeID, FirstName, LastName, Position) VALUES (4, 'Mark', 'Anderson', 'Analyst');  This query adds a new row to the Employees table. ","version":null,"tagName":"h3"},{"title":"8.2 UPDATE​","type":1,"pageTitle":"SQL FOR EVERYONE - THE DEFINITIVE GUIDE","url":"/2024/1/21/SQL-cheatsheet#82-update","content":"UPDATE Employees SET Position = 'Senior Analyst' WHERE EmployeeID = 4;  This query changes Mark Anderson's position to Senior Analyst. ","version":null,"tagName":"h3"},{"title":"8.3 DELETE​","type":1,"pageTitle":"SQL FOR EVERYONE - THE DEFINITIVE GUIDE","url":"/2024/1/21/SQL-cheatsheet#83-delete","content":"DELETE FROM Employees WHERE EmployeeID = 4;  This query deletes Mark Anderson's record from the Employees table. ","version":null,"tagName":"h3"},{"title":"9. Advanced SQL Techniques​","type":1,"pageTitle":"SQL FOR EVERYONE - THE DEFINITIVE GUIDE","url":"/2024/1/21/SQL-cheatsheet#9-advanced-sql-techniques","content":"Let's delve into more complex techniques with the help of examples. ","version":null,"tagName":"h2"},{"title":"9.1 Handling NULL values​","type":1,"pageTitle":"SQL FOR EVERYONE - THE DEFINITIVE GUIDE","url":"/2024/1/21/SQL-cheatsheet#91-handling-null-values","content":"NULL value in SQL means no or zero value. Here's how you can use IS NULL and IS NOT NULL: SELECT * FROM Employees WHERE DepartmentID IS NULL;  This query selects all employees who don't belong to any department. SELECT * FROM Employees WHERE DepartmentID IS NOT NULL;  This query selects all employees who belong to a department. ","version":null,"tagName":"h3"},{"title":"9.2 String Functions​","type":1,"pageTitle":"SQL FOR EVERYONE - THE DEFINITIVE GUIDE","url":"/2024/1/21/SQL-cheatsheet#92-string-functions","content":"SQL offers several functions to manipulate strings. Some examples include: CONCAT(): Concatenates two or more strings.TRIM(): Removes leading and trailing spaces of a string. LENGTH(): Returns the length of a string. SELECT CONCAT(FirstName, ' ', LastName) as FullName, TRIM(Position), LENGTH(FirstName) as NameLength FROM Employees;  This query retrieves a full name by combining first and last names, the position after removing leading and trailing spaces, and the length of the first name. ","version":null,"tagName":"h3"},{"title":"9.3 Date and Time Functions​","type":1,"pageTitle":"SQL FOR EVERYONE - THE DEFINITIVE GUIDE","url":"/2024/1/21/SQL-cheatsheet#93-date-and-time-functions","content":"SQL provides many functions to work with date and time. Some examples include: NOW(): Returns the current date and time.CURDATE(): Returns the current date.CURTIME(): Returns the current time. SELECT OrderID, OrderTotal, NOW() as QueryTime FROM Orders WHERE OrderDate = CURDATE();  This query retrieves today's orders along with the query execution time. ","version":null,"tagName":"h3"},{"title":"9.4 Case Statements​","type":1,"pageTitle":"SQL FOR EVERYONE - THE DEFINITIVE GUIDE","url":"/2024/1/21/SQL-cheatsheet#94-case-statements","content":"Case statements help in implementing conditional logic in SQL: SELECT FirstName, Position, CASE WHEN Position = 'Analyst' THEN 'Junior Level' WHEN Position = 'Engineer' THEN 'Mid Level' ELSE 'Senior Level' END as JobLevel FROM Employees;  This query categorizes employees into job levels based on their positions. ","version":null,"tagName":"h3"},{"title":"9.5 Window Functions​","type":1,"pageTitle":"SQL FOR EVERYONE - THE DEFINITIVE GUIDE","url":"/2024/1/21/SQL-cheatsheet#95-window-functions","content":"Window functions perform calculations across a set of table rows that are related to the current row: SELECT FirstName, Position, Salary, RANK() OVER (PARTITION BY Position ORDER BY Salary DESC) as Rank FROM Employees;  This query ranks employees within their respective positions based on their salaries. ","version":null,"tagName":"h3"},{"title":"Optimization and Performance Tuning​","type":1,"pageTitle":"SQL FOR EVERYONE - THE DEFINITIVE GUIDE","url":"/2024/1/21/SQL-cheatsheet#optimization-and-performance-tuning","content":"Here are some examples demonstrating SQL optimization techniques: ","version":null,"tagName":"h2"},{"title":"10.1 EXPLAIN​","type":1,"pageTitle":"SQL FOR EVERYONE - THE DEFINITIVE GUIDE","url":"/2024/1/21/SQL-cheatsheet#101-explain","content":"Most SQL databases support the EXPLAIN command, which shows the execution plan of an SQL statement. This can help you understand how your SQL query will be executed and where you can optimize it. EXPLAIN SELECT * FROM Employees;  ","version":null,"tagName":"h3"},{"title":"10.2 Avoid SELECT​","type":1,"pageTitle":"SQL FOR EVERYONE - THE DEFINITIVE GUIDE","url":"/2024/1/21/SQL-cheatsheet#102-avoid-select","content":"Rather than using SELECT *, specify the columns you need. This reduces the amount of data that needs to be read from the disk. SELECT FirstName, LastName FROM Employees;  ","version":null,"tagName":"h3"},{"title":"10.3 Use LIMIT​","type":1,"pageTitle":"SQL FOR EVERYONE - THE DEFINITIVE GUIDE","url":"/2024/1/21/SQL-cheatsheet#103-use-limit","content":"If you only need a specific number of rows, use LIMIT to prevent reading unnecessary data. SELECT * FROM Employees ORDER BY Salary DESC LIMIT 10;  This query gets the top 10 employees with the highest salaries. 10.4 Index your data Indexing your data can significantly speed up data retrieval times. Here's how you can add an index: CREATE INDEX idx_employees_position ON Employees(Position);  ","version":null,"tagName":"h3"},{"title":"What's Next?​","type":1,"pageTitle":"SQL FOR EVERYONE - THE DEFINITIVE GUIDE","url":"/2024/1/21/SQL-cheatsheet#whats-next","content":"Practice, practice, practice: The best way to reinforce your SQL skills is by practicing. Websites like LeetCode, HackerRank, and SQLZoo provide hundreds of SQL problems that you can practice with.Learn Database Design: Understanding how databases are structured and designed will help you write better and more efficient SQL queries. Look into topics such as normalization, entity-relationship models, and data integrity.Explore Advanced SQL Topics: This tutorial covered the basics, but there's still a lot to learn. Delve into more advanced topics like stored procedures, triggers, views, and transaction control.Learn About Database Administration: Although not typically part of a Data Analyst's role, understanding how a database is administered can provide useful context. This can also open up new opportunities in the realm of database management.Understand SQL in the context of a programming language: If you are familiar with a programming language like Python or R, try to use SQL commands within these languages. This often gives you more flexibility and allows you to perform more complex operations with your data.Learn About Different SQL Databases: There are many different SQL databases, such as MySQL, SQLite, PostgreSQL, and Oracle. Each has its own unique features and syntax nuances. Familiarize yourself with the one that's most relevant to your work or interests.Apply SQL in Your Projects: The ultimate test of your skills will be applying SQL in your projects. Whether it's for cleaning data, data wrangling, or analysis, the practical application of SQL will solidify your learning and give you valuable experience. Remember, becoming proficient in SQL is a journey, not a destination. Enjoy the process of learning and experimenting. Happy querying! ","version":null,"tagName":"h2"},{"title":"dotnet command cheatsheat","type":0,"sectionRef":"#","url":"/2023/12/29/net-cheatsheet","content":"","keywords":"","version":null},{"title":"Create and Build Projects​","type":1,"pageTitle":"dotnet command cheatsheat","url":"/2023/12/29/net-cheatsheet#create-and-build-projects","content":"dotnet new console -n MyConsoleApp // Create a new console application dotnet new webapi -n MyWebApi // Create a new Web API project dotnet build // Build the project  ","version":null,"tagName":"h2"},{"title":"Run Applications​","type":1,"pageTitle":"dotnet command cheatsheat","url":"/2023/12/29/net-cheatsheet#run-applications","content":"dotnet run // Run the application dotnet run --project &lt;project_path&gt; // Run a specific project dotnet watch run // Run with file watching  ","version":null,"tagName":"h2"},{"title":"Add Dependencies​","type":1,"pageTitle":"dotnet command cheatsheat","url":"/2023/12/29/net-cheatsheet#add-dependencies","content":"dotnet add package &lt;package_name&gt; // Add a NuGet package dotnet restore // Restore dependencies  ","version":null,"tagName":"h2"},{"title":"Generate Code​","type":1,"pageTitle":"dotnet command cheatsheat","url":"/2023/12/29/net-cheatsheet#generate-code","content":"dotnet new classlib -n MyLibrary // Create a class library dotnet add reference &lt;project_path&gt; // Add a project reference dotnet publish -c Release // Publish the application  ","version":null,"tagName":"h2"},{"title":"Unit Testing​","type":1,"pageTitle":"dotnet command cheatsheat","url":"/2023/12/29/net-cheatsheet#unit-testing","content":"dotnet new xunit -n MyTests // Create xUnit test project dotnet test // Run tests  ","version":null,"tagName":"h2"},{"title":"Entity Framework Core​","type":1,"pageTitle":"dotnet command cheatsheat","url":"/2023/12/29/net-cheatsheet#entity-framework-core","content":"dotnet ef migrations add &lt;migration_name&gt; // Add a migration dotnet ef database update // Apply migrations  ","version":null,"tagName":"h2"},{"title":"Publish and Deploy​","type":1,"pageTitle":"dotnet command cheatsheat","url":"/2023/12/29/net-cheatsheet#publish-and-deploy","content":"dotnet publish -c Release --self-contained // Publish a self-contained application  ","version":null,"tagName":"h2"},{"title":"Package Management​","type":1,"pageTitle":"dotnet command cheatsheat","url":"/2023/12/29/net-cheatsheet#package-management","content":"dotnet nuget push -k &lt;api_key&gt; -s &lt;source&gt; &lt;package.nupkg&gt; // Publish a NuGet package  ","version":null,"tagName":"h2"},{"title":"ASP.NET Core Identity​","type":1,"pageTitle":"dotnet command cheatsheat","url":"/2023/12/29/net-cheatsheet#aspnet-core-identity","content":"dotnet new identity -n MyIdentityApp // Create an ASP.NET Core Identity project  ","version":null,"tagName":"h2"},{"title":"Azure Functions​","type":1,"pageTitle":"dotnet command cheatsheat","url":"/2023/12/29/net-cheatsheet#azure-functions","content":"dotnet new func -n MyFunction // Create an Azure Functions project  ","version":null,"tagName":"h2"},{"title":"Clean Up​","type":1,"pageTitle":"dotnet command cheatsheat","url":"/2023/12/29/net-cheatsheet#clean-up","content":"dotnet clean // Clean the build output  ","version":null,"tagName":"h2"},{"title":"Mongodb theory and examples code","type":0,"sectionRef":"#","url":"/2024/2/15/mongodb-theory-and-examples-code","content":"","keywords":"","version":null},{"title":"MONGODB PRACTICE SECTION 1​","type":1,"pageTitle":"Mongodb theory and examples code","url":"/2024/2/15/mongodb-theory-and-examples-code#mongodb-practice-section-1","content":"","version":null,"tagName":"h2"},{"title":"Part 1: Query Operators​","type":1,"pageTitle":"Mongodb theory and examples code","url":"/2024/2/15/mongodb-theory-and-examples-code#part-1-query-operators","content":"db.collection.findOne(query, projection) db.collection.find(query, projection) Case Sensitivity in MongoDB db.trips.FindOne() - is incorrect db.trips.Find() - is incorrect Query in Explorer  ","version":null,"tagName":"h3"},{"title":"Part 2: Logical Operators​","type":1,"pageTitle":"Mongodb theory and examples code","url":"/2024/2/15/mongodb-theory-and-examples-code#part-2-logical-operators","content":"$eq, $ne db.trips.find({&quot;tripduration&quot;:{$eq: 200}}) $gt, $gte db.trips.find({&quot;tripduration&quot;: {$lt: 200}}) $lt, $lte db.trips.find({&quot;tripduration&quot;: {$lt: 200}}) $in db.trips.find({&quot;start station id&quot;: {$in: [302, 536]}})  Query Comparison Operators Reference ","version":null,"tagName":"h3"},{"title":"Part 3: Projection and Embedded Documents​","type":1,"pageTitle":"Mongodb theory and examples code","url":"/2024/2/15/mongodb-theory-and-examples-code#part-3-projection-and-embedded-documents","content":"db.collection.find({query},{projection}); db.trips.find({query}, {tripduration:1, bikeid:1, _id:0})  {operator: [{condition1}, {condition2}...]} $and $or, $nor db.trips.find({$and: [{tripduration:{$gt: 400}}, {&quot;birth year&quot;: {$gt: 1988}}]}) db.accounts.find({$and: [{products: 'CurrencyService'}, {products: 'InvestmentStock'}, {products: {$size: 2}}]}) db.trips.find({$or: [{tripduration: {$lt: 400}}, {tripduration: {$gt:1900}}]}) db.inspections.find({$or: [{result: &quot;No Violation Issued&quot;}, {result: &quot;Violation Issued&quot;}]})  Logical Query Operators Reference ","version":null,"tagName":"h3"},{"title":"Part 4: Embedded Documents​","type":1,"pageTitle":"Mongodb theory and examples code","url":"/2024/2/15/mongodb-theory-and-examples-code#part-4-embedded-documents","content":"db.inspections.find({&quot;address.zip&quot;: 11427}) db.inspections.find({result: &quot;Pass&quot;,&quot;address.zip&quot;: {$in:[11427]}}, {result: 1, date:1, address:1}) db.inspections.updateMany({_id: ObjectId('56d61033a378eccde8a83569')}, {$set: {&quot;address.phone&quot;: {: '84', number: '999988778'}}}) Find 3 level of embedded documents db.inspections.find({&quot;address.phone.code&quot;: &quot;84&quot;});  ","version":null,"tagName":"h3"},{"title":"Part 5: Array Operators​","type":1,"pageTitle":"Mongodb theory and examples code","url":"/2024/2/15/mongodb-theory-and-examples-code#part-5-array-operators","content":"db.accounts.find({&quot;products&quot;:['Brokerage','InvestmentStock']}); $all db.accounts.find({&quot;products&quot;:{$all:['Brokerage','InvestmentStock']}}) $inc db.accounts.find({&quot;products&quot;:{$in:['Brokerage','InvestmentStock']}}) $size db.accounts.find({&quot;products&quot;:{$size: 3}}) $elemMatch db.grades.find({&quot;scores&quot;:{$elemMatch:{&quot;type&quot;:&quot;exam&quot;, &quot;score&quot;: {$gt: 80}}}})  Array Query Operators Reference ","version":null,"tagName":"h3"},{"title":"Part 6: Counting Documents​","type":1,"pageTitle":"Mongodb theory and examples code","url":"/2024/2/15/mongodb-theory-and-examples-code#part-6-counting-documents","content":"db.collection.countDocuments(); db.trips.countDocuments({tripduration: {$gt: 1000}}) db.collection.find({query}).count();  ","version":null,"tagName":"h3"},{"title":"Part 7: Sorting, Limiting, and Skipping​","type":1,"pageTitle":"Mongodb theory and examples code","url":"/2024/2/15/mongodb-theory-and-examples-code#part-7-sorting-limiting-and-skipping","content":"db.collection.find({query}).sort({field: 1}) =&gt; asc db.collection.find({query}).sort({field: -1}) =&gt; desc db.trips.find({}).sort({tripduration:1, &quot;start station id&quot;: -1}) db.collection.find({query}).limit(number); db.trips.find({tripduration: {$gt: 1400}}).limit(10) db.collection.find({query}).skip(number); db.trips.find({tripduration: {$gt: 1400}}).skip(5).limit(10);  ","version":null,"tagName":"h3"},{"title":"Part 8: Inserting Documents​","type":1,"pageTitle":"Mongodb theory and examples code","url":"/2024/2/15/mongodb-theory-and-examples-code#part-8-inserting-documents","content":"db.collection.insert([], {option}) db.testcollection.insert([{name:'test', age: 10}, {name:'test2', age: 12}]) db.collection.insertOne({}); We can insert empty object {}, it will generate _id for this object We cannot insert with the same _id db.testcollection.insertOne({_id: 1001, &quot;name&quot;: &quot;Test&quot;,&quot;scores&quot;:10}) db.collection.bulkWrite([ {insertOne:{_id:3, name:&quot;test&quot;}}, {insertOne:{_id:4, name:&quot;test2&quot;}} ]) db.collection.insertOne({date: new Date(&quot;2022-02-02T00:00:00Z&quot;)}) db.collection.insertOne({date: ISODate(&quot;2022-02-02T00:00:00Z&quot;)})  Insert Documents Tutorial ","version":null,"tagName":"h3"},{"title":"Part 9: Deleting Documents​","type":1,"pageTitle":"Mongodb theory and examples code","url":"/2024/2/15/mongodb-theory-and-examples-code#part-9-deleting-documents","content":"db.collection.deleteOne(); db.testcollection.deleteMany({name:&quot;test1&quot;}); db.collection.deleteMany(); db.testcollection.deleteMany({name:&quot;test1&quot;}); db.testcollection.deleteMany({name:&quot;test123&quot;}); db.collection.findOneAndDelete() Return a document after delete the document db.accounts.findOneAndDelete({account_id: 977774}) db.collection.drop()  Delete Methods Reference ","version":null,"tagName":"h3"},{"title":"Part 10: Updating Documents​","type":1,"pageTitle":"Mongodb theory and examples code","url":"/2024/2/15/mongodb-theory-and-examples-code#part-10-updating-documents","content":"db.collection.updateOne({filter}{update},{option}) db.collection.updateMany({filter},{update}, {option}) db.collection.findOneAndUpdate({filter},{update}, {option}) $set $inc db.zips.updateMany({city: &quot;MC CALLA&quot;}, {$inc: {pop: 1}}) $push = using to push an item embedded array of document db.grades.updateMany({student_id: 4}, {$push: {scores: {type: &quot;new exam&quot;, score: 100}}}) Update embedded array db.sales.updateMany({items: {$elemMatch: {name: &quot;printer paper&quot;}}},{$set: {&quot;items.$.price&quot;: 20 }}); db.grades.updateMany({scores:{$elemMatch:{score: {$gt : 33}}}}, {$set: {&quot;scores.$.type&quot;: &quot;exam2&quot;}}); db.trips.updateMany({tripduration: 199999},{$set: {usertype: 'Subscriber'}}) db.trips.updateMany({tripduration: 199999},{$set: {usertype: 'Subscriber'}}, {upsert: true}) db.collection.replaceOne({filter}, {replacement},{option}) Option: {upsert: true/false} db.accounts.replaceOne({account_id: &quot;unknown&quot;},{account_id: &quot;new account&quot;, limit: 2024}, {upsert: true})  Update Methods Reference  ","version":null,"tagName":"h3"},{"title":"MONGODB PRACTICE SECTION 2​","type":1,"pageTitle":"Mongodb theory and examples code","url":"/2024/2/15/mongodb-theory-and-examples-code#mongodb-practice-section-2","content":"","version":null,"tagName":"h2"},{"title":"Aggregation​","type":1,"pageTitle":"Mongodb theory and examples code","url":"/2024/2/15/mongodb-theory-and-examples-code#aggregation","content":"db.orders.aggregate( [ // Stage 1: Filter pizza order documents by pizza size { $match: { size: &quot;medium&quot; } }, // Stage 2: Group remaining documents by pizza name and calculate total quantity { $group: { _id: &quot;$name&quot;, totalQuantity: { $sum: &quot;$quantity&quot; } } }, // Stage 3: Select items having totalQuantity greater than 8 { $match: { totalQuantity: { $gt: 8 } } } ] )  Aggregation Reference Aggregation - Stage​ $match$group$project$sort$limit$skip$out Aggregation Pipeline Operators Reference Aggregation - Optimize​ $project + $match$project + $skip$sort + $match Aggregation Pipeline Optimization Another aggregation pipeline db.collection.aggregate.( [{ &quot;$search&quot;: { &quot;text&quot;: { &quot;path&quot;: &quot;name&quot;, &quot;query&quot;: &quot;cuban&quot; } }}])  db.collection.aggregate([$lookup: { from:'', localField:'', foreignField:'', as:'' }])  Aggregation - Exam Question​ Given the following documents: {&quot;_id&quot;:1, restaurant: &quot;Quesadillas Inc.&quot;, rating: 4.5 }, {&quot;_id&quot;:2, restaurant: &quot;Pasta Inc.&quot;, rating: 3.9}, {&quot;_id&quot;:3, restaurant: &quot;Tacos Inc.&quot;, rating: 2.5}  A developer wants to find the highest-rated restaurant in a list. An index has been created on the appropriate field. What query satisfies the requirements? (Choose 1) A. const pipeline = [ { $sort: { rating : -1, limit: 1 } } ]; const aggCursor = coll.runAggregation(pipeline);B. const pipeline = [ { $sort: { rating : -1 } }, { $limit: 1 } ]; const aggCursor = coll.runAggregation(pipeline);C. const pipeline = [ { $sort: { rating : -1 , limit: 1} } ]; const aggCursor = coll.aggregate(pipeline);D. const pipeline = [ { $sort: { rating : -1 } }, { $limit: 1 } ]; const aggCursor = coll.aggregate(pipeline); ","version":null,"tagName":"h3"},{"title":"Index​","type":1,"pageTitle":"Mongodb theory and examples code","url":"/2024/2/15/mongodb-theory-and-examples-code#index","content":"Index - Create​ db.collection.createIndex(&lt;keys&gt;, &lt;options&gt;) db.collection.createIndex({&quot;a&quot;: 1}) db.collection.createIndex({&quot;a&quot;: -1}) db.collection.createIndex({&quot;a&quot;: 1, &quot;b&quot;: 1}) db.collection.createIndex({&quot;a&quot;: 1}, {unique: true, expireAfterSeconds: 3600})  Keys: {&lt;field&gt;: &lt;1 / –1&gt;}  1 =&gt; ascending index -1 =&gt; descending index Options: unique, expireAfterSeconds Index Creation Reference Index - Get​ db.collection.getIndexes()  Index Retrieval Reference Index - Drop​ db.collection.dropIndex(&lt;index&gt;) db.products.dropIndex(&quot;name_1&quot;)  Index Deletion Reference Index - Hide​  db.collection.hideIndex(&lt;index&gt;)  Index Hiding Reference Index - Explain Query​ db.collection.explain(&lt;mode&gt;)  Modes: queryPlanner (default), executionStats, allPlansExecution Index Query Explanation Reference Index – Hint​ db.collection.find({&quot;a&quot;: &quot;some value&quot;}).hint({ a: 1 }) db.collection.find({&quot;a&quot;: &quot;some value&quot;}).hint(&quot;a_1&quot;)  Index Hinting Tutorial Index – Compound​ Given the following query: db.collection.find({ }).sort({ &quot;product&quot;: 1, &quot;price&quot;: 1 })  Which index will improve the performance of this query? (Choice 2) A. db.collection.createIndex( { &quot;product&quot;: 1, &quot;price&quot;: 1 } )B. db.collection.createIndex( { &quot;product&quot;: 1, &quot;price&quot;: -1 } )C. db.collection.createIndex( { &quot;product&quot;: -1, &quot;price&quot;: 1 } )D. db.collection.createIndex( { &quot;product&quot;: -1, &quot;price&quot;: -1 } ) Index – Behind the Scene​ Given a collection called collection: { &quot;a&quot;: 1, &quot;b&quot;: 1 } { &quot;a&quot;: 1, &quot;b&quot;: 2 } { &quot;a&quot;: 2, &quot;b&quot;: 1 } { &quot;a&quot;: 2, &quot;b&quot;: 2 } { &quot;a&quot;: 2, &quot;b&quot;: 3 } { &quot;a&quot;: 3, &quot;b&quot;: 1 } { &quot;a&quot;: 3, &quot;b&quot;: 2 }  Find a = 2, b &gt; 1 sorted by b. Index – ESR Rule​ The ESR (Equality, Sort, Range) Rule: db.cars.createIndex({ manufacturer: 1, model: 1, cost: 1 })  ESR Rule Explanation Reference Homework​ Review workshop recordPractice commands in this section with your sample collections in MDB_EDU database (cloud.mongodb.com)Follow and practice section 10, 12 in Udemy Course: MongoDB - The Complete Developer's GuidePreview Atlas search  ","version":null,"tagName":"h3"},{"title":"MONGODB PRACTICE SECTION 3​","type":1,"pageTitle":"Mongodb theory and examples code","url":"/2024/2/15/mongodb-theory-and-examples-code#mongodb-practice-section-3","content":"","version":null,"tagName":"h2"},{"title":"Exam - 43/53 to PASS​","type":1,"pageTitle":"Mongodb theory and examples code","url":"/2024/2/15/mongodb-theory-and-examples-code#exam---4353-to-pass","content":"","version":null,"tagName":"h3"},{"title":"What will be asked?​","type":1,"pageTitle":"Mongodb theory and examples code","url":"/2024/2/15/mongodb-theory-and-examples-code#what-will-be-asked","content":"CRUD 27 – 28 Mongo ShellCRUD functions (findOne, find, insertOne, insertMany, updateOne, updateMany, deleteOne, deleteMany, findAndModify...)Query in array fields, nested object fields ($in, $elemMatch)Aggregation ($match, $group, $out)Atlas Search index and query Index 9 – 10 Choose correct index for a queryFrom explain query output, identify if using index scanIndex with Nested object field Driver NodeJS / Java / C#/ Python / PHP 9 – 10 Driver significant features, URI, connection poolingDriver source code syntax: CRUD, Aggregation pipeline The Document Model 4 – 5 Which document can/cannot store in the same collectionBSON data type (Ex: Decimal128, not Float64) Data Modeling 1 – 2 Embedded or Referred relationship Atlas Tools 1 – 2 MongoDB Atlas UIData Explorer to query data ","version":null,"tagName":"h3"},{"title":"Data Modeling​","type":1,"pageTitle":"Mongodb theory and examples code","url":"/2024/2/15/mongodb-theory-and-examples-code#data-modeling","content":"Embedded Data Embedded documents store related data in a single document structure. A document can contain arrays and sub-documents with related data. References References store relationships between data by including links, called references, from one document to another. Ref: Data Modeling Guide Data Modeling - Embedded​ Model One-to-One Relationships Ref: Embedded One-to-One Relationships Model One-to-Many Relationships with Embedded Documents Receives all required information in a single read operationExample: Country to major cities, Author to books, Student to classesLimit size of a document: 16MBRef: Embedded One-to-Many Relationships Data Modeling - References​ Model One-to-Many Relationships with Document References To avoid repetition of the referred data, use referencesExample: Book and PublisherRef: Referenced One-to-Many Relationships ","version":null,"tagName":"h3"},{"title":"Atlas Search​","type":1,"pageTitle":"Mongodb theory and examples code","url":"/2024/2/15/mongodb-theory-and-examples-code#atlas-search","content":"Atlas Search – Index Field Mappings​ Dynamic Mapping Automatically index all supported field types using dynamic mappings Static Mapping Specify the fields to indexSyntax: { &quot;mappings&quot;: { &quot;dynamic&quot;: &lt;boolean&gt;, &quot;fields&quot;: { &quot;&lt;field-name&gt;&quot;: { &quot;type&quot;: &quot;&lt;field-type&gt;&quot;, } } } }  Ref: Atlas Search - Field Mappings Atlas Search – Index Analyzer​ Ref: Atlas Search AnalyzersAnalyzer Description: Standard: Uses the default analyzer for all Atlas Search indexes and queries.Simple: Divides text into searchable terms wherever it finds a non-letter character.Whitespace: Divides text into searchable terms wherever it finds a whitespace character.Language: Provides a set of language-specific text analyzers.Keyword: Indexes text fields as single terms. Atlas Search – Index Analyzer Tokenizer​ whitespacenGramedgeGram =&gt; AutocompleteregexCaptureGroupRef: Atlas Search - Tokenizers Atlas Search – Query​ Single Field SearchMultiple Field SearchNested Field SearchWildcard Field SearchRef: Atlas Search - Path ConstructionExample: $search: { &quot;text&quot;: { &quot;query&quot;: &quot;Ford&quot;, &quot;path&quot;: &quot;make&quot; } }  Atlas Search – Query Compound​ shouldmustmustNotfilterRef: Atlas Search - Compound ","version":null,"tagName":"h3"},{"title":"Node.js Driver​","type":1,"pageTitle":"Mongodb theory and examples code","url":"/2024/2/15/mongodb-theory-and-examples-code#nodejs-driver","content":"Connection Video: Connecting to MongoDB in Node.jsRef: Node.js Driver Connection CRUD​ Video: MongoDB CRUD Operations in Node.jsRef: Node.js Driver CRUD Aggregation driver​ Video: MongoDB Aggregation with Node.jsRef: Node.js Driver Aggregation MongoClient API​ Ref: MongoClient API Node.js Driver – Connection Pool​ Definition A connection pool is a cache of open, ready-to-use database connections maintained by the driver.Your application can seamlessly get connections from the pool, perform operations, and return connections back to the pool.Connection pools are thread-safe. Benefits Helps reduce application latency and the number of times new connections are created.A connection pool creates connections at startup.No need to manually return connections to the pool, connections return to the pool automatically.When requesting a connection and there’s an available connection in the pool, a new connection does not need to be created. Ref: Connection Pool Overview ","version":null,"tagName":"h3"},{"title":"Practice Questions​","type":1,"pageTitle":"Mongodb theory and examples code","url":"/2024/2/15/mongodb-theory-and-examples-code#practice-questions","content":"Practice Questions ","version":null,"tagName":"h3"},{"title":"Homework driver​","type":1,"pageTitle":"Mongodb theory and examples code","url":"/2024/2/15/mongodb-theory-and-examples-code#homework-driver","content":"Review workshop recordFollow the video of Node.js Driver and practice with your sample collections in MDB_EDU database (cloud.mongodb.com)Read document references in this slideReview all to prepare for the final test in the next week (53 questions, 80% to pass)Register and schedule for the exam ","version":null,"tagName":"h3"},{"title":"Reactjs basic note","type":0,"sectionRef":"#","url":"/2024/3/28/reactjs-note","content":"","keywords":"","version":null},{"title":"useState and useEffect​","type":1,"pageTitle":"Reactjs basic note","url":"/2024/3/28/reactjs-note#usestate-and-useeffect","content":"useState and useEffect are both hooks used in React, a JavaScript library for building user interfaces. useState is a hook that allows you to add state to a functional component. State is a way of storing and managing data within a component. With useState, you can declare a state variable and a function to update that variable. Every time the state variable is updated, React will re-render the component and update the UI. import React, { useState } from 'react'; function Counter() { const [count, setCount] = useState(0); const incrementCount = () =&gt; { setCount(count + 1); }; return ( &lt;div&gt; &lt;p&gt;Count: {count}&lt;/p&gt; &lt;button onClick={incrementCount}&gt;Increment&lt;/button&gt; &lt;/div&gt; ); }  useEffect is a hook used for side effects in React. Side effects are actions that happen outside of the normal flow of the component, such as fetching data, subscriptions, or manually manipulating the DOM. useEffect allows you to perform these side effects after the component has rendered. import React, { useState, useEffect } from 'react'; function Example() { const [count, setCount] = useState(0); useEffect(() =&gt; { document.title = `Count: ${count}`; }, [count]); return ( &lt;div&gt; &lt;p&gt;Count: {count}&lt;/p&gt; &lt;button onClick={() =&gt; setCount(count + 1)}&gt;Increment&lt;/button&gt; &lt;/div&gt; ); }  ","version":null,"tagName":"h2"},{"title":"class and interface​","type":1,"pageTitle":"Reactjs basic note","url":"/2024/3/28/reactjs-note#class-and-interface","content":"class create object with attribute and method. They facilitate code organization, encapsulation, and reusability through inheritance and polymorphism. class Car { brand: string; constructor(brand: string) { this.brand = brand; } accelerate(speed: number) { console.log(`${this.brand} is accelerating at ${speed} km/h.`); } } const myCar = new Car('Toyota'); myCar.accelerate(100);  inteface Interfaces in TypeScript define contracts for objects, specifying the structure of their properties and methods without providing implementation details. interface Animal { name: string; makeSound(): void; } class Dog implements Animal { name: string; constructor(name: string) { this.name = name; } makeSound() { console.log(`${this.name} barks.`); } } const myDog = new Dog('Buddy'); myDog.makeSound();  ","version":null,"tagName":"h2"},{"title":"useStore() and mobx​","type":1,"pageTitle":"Reactjs basic note","url":"/2024/3/28/reactjs-note#usestore-and-mobx","content":"store is where all the state of the application is stored. It contains important data and provides methods to change and access this data MobX is a state management library for JavaScript applications. It simplifies state management by using the observer pattern and automatically tracking state changes to update the user interface. import { makeAutoObservable } from 'mobx'; // Define a store class CounterStore { count = 0; constructor() { makeAutoObservable(this); // Automatically generate state management functions } increment() { this.count++; } decrement() { this.count--; } } // Create an object from the CounterStore class const counter = new CounterStore(); // Perform operations on the state counter.increment(); counter.decrement();  ","version":null,"tagName":"h2"},{"title":"Redux​","type":1,"pageTitle":"Reactjs basic note","url":"/2024/3/28/reactjs-note#redux","content":"Redux is a predictable state container for JavaScript apps. It helps in managing the state of your application in a predictable way, which is especially useful for larger applications with complex state management  ","version":null,"tagName":"h2"},{"title":"Store​","type":1,"pageTitle":"Reactjs basic note","url":"/2024/3/28/reactjs-note#store","content":"The Store holds the global state of the application.It allows access to the state via getState().State can be updated using dispatch(action).You can subscribe to changes using subscribe(listener). import { createStore } from 'redux'; import rootReducer from './reducers'; // Your root reducer const store = createStore(rootReducer);  ","version":null,"tagName":"h3"},{"title":"Actions​","type":1,"pageTitle":"Reactjs basic note","url":"/2024/3/28/reactjs-note#actions","content":"Actions are plain JavaScript objects that represent what happened.They are dispatched to update the state.Actions typically have a type property that describes the action being performed.They can optionally carry additional data in the payload. const incrementCounter = () =&gt; ({ type: 'INCREMENT_COUNTER' }); const decrementCounter = () =&gt; ({ type: 'DECREMENT_COUNTER' });  ","version":null,"tagName":"h3"},{"title":"Reducers​","type":1,"pageTitle":"Reactjs basic note","url":"/2024/3/28/reactjs-note#reducers","content":"Reducers are pure functions that specify how the application's state changes in response to actions.They take the current state and an action, and return a new state.They should not mutate the state, but return a new state object. const initialState = { counter: 0 }; const counterReducer = (state = initialState, action) =&gt; { switch (action.type) { case 'INCREMENT_COUNTER': return { ...state, counter: state.counter + 1 }; case 'DECREMENT_COUNTER': return { ...state, counter: state.counter - 1 }; default: return state; } }; export default counterReducer;  ","version":null,"tagName":"h3"},{"title":"TypeScript Basics​","type":1,"pageTitle":"Reactjs basic note","url":"/2024/3/28/reactjs-note#typescript-basics","content":"","version":null,"tagName":"h2"},{"title":"Variables and Data Types​","type":1,"pageTitle":"Reactjs basic note","url":"/2024/3/28/reactjs-note#variables-and-data-types","content":"let num: number = 10; let str: string = &quot;Hello, TypeScript!&quot;; let bool: boolean = true; let arr: number[] = [1, 2, 3]; let obj: { name: string, age: number } = { name: &quot;John&quot;, age: 30 }; let func: (x: number, y: number) =&gt; number = (x, y) =&gt; x + y;  ","version":null,"tagName":"h3"},{"title":"Functions and Arrow Functions​","type":1,"pageTitle":"Reactjs basic note","url":"/2024/3/28/reactjs-note#functions-and-arrow-functions","content":"function add(x: number, y: number): number { return x + y; } const multiply = (x: number, y: number): number =&gt; x * y;  ","version":null,"tagName":"h3"},{"title":"Interfaces and Types​","type":1,"pageTitle":"Reactjs basic note","url":"/2024/3/28/reactjs-note#interfaces-and-types","content":"interface Person { name: string; age: number; } type Point = { x: number; y: number; }  ","version":null,"tagName":"h3"},{"title":"Arrays and Tuples​","type":1,"pageTitle":"Reactjs basic note","url":"/2024/3/28/reactjs-note#arrays-and-tuples","content":"let numbers: number[] = [1, 2, 3]; let tuple: [string, number] = [&quot;apple&quot;, 10];  ","version":null,"tagName":"h3"},{"title":"Classes and Inheritance​","type":1,"pageTitle":"Reactjs basic note","url":"/2024/3/28/reactjs-note#classes-and-inheritance","content":"class Animal { constructor(public name: string) {} makeSound(): void { console.log(&quot;Some sound&quot;); } } class Dog extends Animal { constructor(name: string, public breed: string) { super(name); } makeSound(): void { console.log(&quot;Woof!&quot;); } } const dog = new Dog(&quot;Buddy&quot;, &quot;Labrador&quot;); dog.makeSound(); // Output: Woof!  ","version":null,"tagName":"h3"},{"title":"Advanced TypeScript Concepts​","type":1,"pageTitle":"Reactjs basic note","url":"/2024/3/28/reactjs-note#advanced-typescript-concepts","content":"","version":null,"tagName":"h3"},{"title":"Generics​","type":1,"pageTitle":"Reactjs basic note","url":"/2024/3/28/reactjs-note#generics","content":"function identity&lt;T&gt;(arg: T): T { return arg; } const result = identity&lt;string&gt;(&quot;Hello&quot;);  ","version":null,"tagName":"h3"},{"title":"Enums​","type":1,"pageTitle":"Reactjs basic note","url":"/2024/3/28/reactjs-note#enums","content":"enum Direction { Up, Down, Left, Right, } const move = (direction: Direction) =&gt; { switch (direction) { case Direction.Up: console.log(&quot;Moving Up&quot;); break; case Direction.Down: console.log(&quot;Moving Down&quot;); break; case Direction.Left: console.log(&quot;Moving Left&quot;); break; case Direction.Right: console.log(&quot;Moving Right&quot;); break; default: console.log(&quot;Unknown direction&quot;); } }; move(Direction.Left);  ","version":null,"tagName":"h3"},{"title":"Type Assertions​","type":1,"pageTitle":"Reactjs basic note","url":"/2024/3/28/reactjs-note#type-assertions","content":"let someValue: any = &quot;this is a string&quot;; let strLength: number = (someValue as string).length;  ","version":null,"tagName":"h3"},{"title":"Type Inference​","type":1,"pageTitle":"Reactjs basic note","url":"/2024/3/28/reactjs-note#type-inference","content":"let num = 10; // TypeScript infers 'number' type  ","version":null,"tagName":"h3"},{"title":"Decorators​","type":1,"pageTitle":"Reactjs basic note","url":"/2024/3/28/reactjs-note#decorators","content":"function Log(target: any, key: string) { console.log(`${key} was called`); } class Calculator { @Log add(x: number, y: number): number { return x + y; } } const calc = new Calculator(); calc.add(2, 3); // Output: add was called  ","version":null,"tagName":"h3"},{"title":"Lập trình cơ bản","type":0,"sectionRef":"#","url":"/basic-programming/","content":"","keywords":"","version":null},{"title":"Bài 1: Làm quen với C++​","type":1,"pageTitle":"Lập trình cơ bản","url":"/basic-programming/#bài-1-làm-quen-với-c","content":"Câu 1: Làm quen với cấu trúc chung của một chương trình C: Mở C-free/Dev-C, vào File/New/Source file.Lưu file với phần mở rộng là .cpp.Thêm #include &lt;iostream&gt;.Viết chương trình &quot;Hello, World!&quot; và các biến thể của nó, biên dịch và chạy chương trình. Câu 2: Viết thiệp mời dự sinh nhật có dạng: ******************************************* THIỆP MỜI Tôi dự lễ sinh nhật của mình Vào lúc 19h ngày 20/10/2016 Tại: 05/42 Vĩnh Viễn, TP. HCM Rất mong được đón tiếp! Hồ Lê Thu *******************************************  Câu 3: Viết chương trình nhập và xuất ra màn hình: Một số nguyên.Một số thực.Một ký tự.Hai số nguyên, tính tổng, hiệu của hai số và xuất kết quả ra màn hình. Nâng cao​ Câu 4: Viết chương trình nhập vào bán kính r của một hình tròn. Tính chu vi và diện tích của hình tròn. In các kết quả lên màn hình. Câu 5: Viết chương trình thực hiện: a. Nhập vào hai số nguyên. Xuất ra màn hình giá trị lớn nhất. b. Nhập vào ba số nguyên. Xuất ra màn hình giá trị lớn nhất. Câu 6: Nhập vào 3 số nguyên dương a, b, c. Kiểm tra xem 3 số đó có lập thành tam giác không? Nếu có, hãy tính chu vi và diện tích của tam giác theo công thức: Chu vi $CV = a + b + c$. Diện tích $S = sqrt(p (p - a) (p - b) * (p - c))$, trong đó: $p = CV / 2$. Xuất các kết quả ra màn hình. Câu 7: Viết chương trình đảo ngược một số nguyên dương có đúng 3 chữ số. hướng dẫn: Lần lượt lấy các chữ số dùng phép chia / và phép chia lấy phần dư % và in ra màn hình theo thứ tự: Chữ số hàng đơn vịChữ số hàng chụcChữ số hàng trăm. Ví dụ: Với số 234, thực hiện: 234 % 10 = 4 (lấy chữ số hàng đơn vị)234 / 10 = 2323 % 10 = 3 (lấy chữ số hàng chục)23 / 10 = 22 % 10 = 2 (lấy chữ số hàng trăm) kết quả Hàng đơn vị: 4Hàng chục: 3Hàng trăm: 2 ","version":null,"tagName":"h3"},{"title":"Bài 2: Cấu trúc điều kiện If và switch​","type":1,"pageTitle":"Lập trình cơ bản","url":"/basic-programming/#bài-2-cấu-trúc-điều-kiện-if-và-switch","content":"Câu 1: Viết chương trình giải phương trình bậc nhất $ax+b=0$ với a,b nhập từ bàn phím. Câu 2: Viết chương trình giải phương trình bậc hai $ax^2+bx+c=0$. Với a,b,c nhập từ bàn phím. Click to view full code ! # include &lt;iostream&gt; # include &lt;cmath&gt; int main() { float a, b, c; std::cout &lt;&lt; &quot;------Giai pt bac hai Ax^2+Bx+C=0------\\n&quot;; std::cout &lt;&lt; &quot;Nhap a: &quot;; std::cin &gt;&gt; a; std::cout &lt;&lt; &quot;Nhap b: &quot;; std::cin &gt;&gt; b; std::cout &lt;&lt; &quot;Nhap c: &quot;; std::cin &gt;&gt; c; if (a == 0) { if (b == 0) { if (c == 0) { std::cout &lt;&lt; &quot;Pt vo so nghiem&quot;; } else { std::cout &lt;&lt; &quot;Pt vo nghiem&quot;; } } else { std::cout &lt;&lt; &quot;Phuong trinh co nghiem x=-c/b=&quot; &lt;&lt; -c / b; } } else { float x1, x2, Delta; Delta = b * b - 4 * a * c; std::cout &lt;&lt; &quot;Delta=&quot; &lt;&lt; Delta; if (Delta &lt; 0) { std::cout &lt;&lt; &quot;\\nPt vo nghiem&quot;; } else if (Delta == 0) { std::cout &lt;&lt; &quot;\\nPhuong trinh co nghiem kep x=&quot; &lt;&lt; -b / (2 * a); } else { x1 = (-b + std::sqrt(Delta)) / (2 * a); x2 = (-b - std::sqrt(Delta)) / (2 * a); std::cout &lt;&lt; &quot;\\nPhuong trinh co 2 nghiem: x1=&quot; &lt;&lt; x1 &lt;&lt; &quot;, x2=&quot; &lt;&lt; x2; } } return 0; }  Câu 3: Nhập vào 3 số a,b,c. Kiểm tra xem 3 số có lập thành tam giác không? Nếu có, hãy cho biết loại tam giác. Câu 4: Viết chương trình hiển thị cách đọc số nguyên có hai chữ số. Ví dụ: 21 -&gt; &quot;hai mốt&quot;. Click to view full code ! #include &lt;iostream&gt; using namespace std; int main() { int n; cout &lt;&lt; &quot;Nhap vao so nguyen co hai chu so\\n&quot;; do { cout &lt;&lt; &quot;Enter number n: &quot;; cin &gt;&gt; n; if (n &lt; 0 || n &gt; 100) cout &lt;&lt; &quot;Nhap sai, nhap lai\\n&quot;; } while (n &lt; 0 || n &gt; 100); switch (n / 10) { case 1: cout &lt;&lt; &quot;Muoi&quot;; break; case 2: cout &lt;&lt; &quot;Hai Muoi&quot;; break; case 3: cout &lt;&lt; &quot;Ba Muoi&quot;; break; case 4: cout &lt;&lt; &quot;Bon Muoi&quot;; break; case 5: cout &lt;&lt; &quot;Nam Muoi&quot;; break; case 6: cout &lt;&lt; &quot;Sau Muoi&quot;; break; case 7: cout &lt;&lt; &quot;Bay Muoi&quot;; break; case 8: cout &lt;&lt; &quot;Tam Muoi&quot;; break; case 9: cout &lt;&lt; &quot;Chin Muoi&quot;; break; } switch (n % 10) { case 1: cout &lt;&lt; &quot; mot&quot;; break; case 2: cout &lt;&lt; &quot; hai&quot;; break; case 3: cout &lt;&lt; &quot; ba&quot;; break; case 4: cout &lt;&lt; &quot; bon&quot;; break; case 5: cout &lt;&lt; &quot; nam&quot;; break; case 6: cout &lt;&lt; &quot; sau&quot;; break; case 7: cout &lt;&lt; &quot; bay&quot;; break; case 8: cout &lt;&lt; &quot; tam&quot;; break; case 9: cout &lt;&lt; &quot; chin&quot;; break; } return 0; }  Câu 5: Viết chương trình nhập vào tháng của một năm và cho biết số ngày của tháng đó. Click to view full code ! #include &lt;iostream&gt; using namespace std; void calendar(int month) { int year; if (month == 1 || month == 3 || month == 5 || month == 7 || month == 8 || month == 10 || month == 12) { cout &lt;&lt; &quot;Day: 31&quot; &lt;&lt; endl; } else if (month == 4 || month == 6 || month == 9 || month == 11) { cout &lt;&lt; &quot;Day: 30&quot; &lt;&lt; endl; } else if (month == 2) { cout &lt;&lt; &quot;Enter year: &quot;; cin &gt;&gt; year; if (year % 4 == 0 &amp;&amp; (year % 100 != 0 || year % 400 == 0)) { cout &lt;&lt; &quot;Day: 29&quot; &lt;&lt; endl; } else { cout &lt;&lt; &quot;Day: 28&quot; &lt;&lt; endl; } } } int main() { int month; do { cout &lt;&lt; &quot;Enter month: &quot;; cin &gt;&gt; month; if (month &lt; 1 || month &gt; 12) { cout &lt;&lt; &quot;Enter again.&quot; &lt;&lt; endl; } } while (month &lt; 1 || month &gt; 12); calendar(month); return 0; }  Câu 6: Nhập một số, kiểm tra số đó có phải là số nguyên tố hay không? In kết quả ra màn hình. Câu 7: Viết chương trình tính tiền taxi dựa trên số km nhập vào. 1 km đầu tiên là 5000 đồng. Mỗi 200m tiếp theo là 1000 đồng. Nếu lớn hơn 30 km thì mỗi km thêm sẽ là 3000 đồng. Hãy nhập số km, sau đó in ra số tiền phải trả. Click to view full code ! #include &lt;iostream&gt; #include &lt;cmath&gt; // for std::ceil, if needed using namespace std; int main() { float n; cout &lt;&lt; &quot;Enter distance n: &quot;; cin &gt;&gt; n; cout &lt;&lt; &quot;\\n Distance is &quot; &lt;&lt; n &lt;&lt; &quot; km&quot; &lt;&lt; endl; if (n &lt;= 1) { int s = 5000; cout &lt;&lt; &quot; Fee: &quot; &lt;&lt; s &lt;&lt; &quot; VND&quot; &lt;&lt; endl; } else if (n &gt; 1 &amp;&amp; n &lt;= 30) { int t; int tien; int duong = static_cast&lt;int&gt;(n * 1000); if (duong % 200 == 0) { t = (duong - 1000) / 200; } else { t = (duong - 1000) / 200 + 1; } tien = t * 1000 + 5000; cout &lt;&lt; &quot; Fee: &quot; &lt;&lt; tien &lt;&lt; &quot; VND&quot; &lt;&lt; endl; } else if (n &gt; 30) { int tien = (static_cast&lt;int&gt;(n) - 30) * 3000 + 150000; cout &lt;&lt; &quot; Fee: &quot; &lt;&lt; tien &lt;&lt; &quot; VND&quot; &lt;&lt; endl; } return 0; }  ","version":null,"tagName":"h3"},{"title":"Bài 3: Cấu trúc lặp - do while, while và for​","type":1,"pageTitle":"Lập trình cơ bản","url":"/basic-programming/#bài-3-cấu-trúc-lặp---do-while-while-và-for","content":"Câu 1: Viết chương trình hiển thị 10 dòng: &quot;XIN CHÀO CÁC BẠN&quot;.Viết chương trình hiển thị n dòng: &quot;XIN CHÀO CÁC BẠN&quot;, với n nhập từ bàn phím. Câu 2: Viết chương trình hiển thị hình tam giác bằng dấu &quot;*&quot;. a. Tam giác cân.b. Tam giác vuông. Câu 3: Viết chương trình hiển thị các số chẵn trong khoảng từ 1 đến n. Viết chương trình liệt kê các số nguyên tố trong phạm vi từ 1 đến n. Viết chương trình tính tổng các chữ số của một số nguyên n. Câu 4: Viết chương trình kiểm tra một số có phải là số hoàn hảo hay không (số hoàn hảo là số bằng tổng các ước số của nó trừ chính nó). Câu 5: Viết chương trình nhập vào một số nguyên n &gt; 0, hãy: a. Xuất ra màn hình các số trong phạm vi từ 1 đến n.b. Xuất ra màn hình các số chẵn trong phạm vi từ 1 đến n.c. Xuất ra màn hình các số lẻ không chia hết cho 3 trong phạm vi từ 1 đến n.d. Tính các biểu thức sau: S3 = 1/2 + 2/3 + 3/4 + ... S4 = x^n (với x là số thực nhập từ bàn phím). e. Tính tổng các chữ số của n. Ví dụ: n = 125, tổng các chữ số là 1 + 2 + 5 = 8. Câu 6: Viết chương trình thực hiện: a. Nhập một số nguyên n sao cho 0 &lt; n &lt; 100. Nếu nhập sai thì yêu cầu nhập lại.b. Đếm số ước của n. Nếu đếm bằng 2 thì xuất ra màn hình &quot;n là số nguyên tố&quot;, ngược lại xuất ra &quot;n không phải là số nguyên tố&quot;.c. Tính tổng các ước của n (không tính chính nó). Nếu tổng các ước đúng bằng n thì xuất ra màn hình &quot;n là số hoàn thiện&quot;, ngược lại xuất ra &quot;n không là số hoàn thiện&quot;. Câu 7: Viết chương trình hiển thị bảng cửu chương ra màn hình. Click to view full code ! #include &lt;iostream&gt; using namespace std; int main() { int i, j, s; cout &lt;&lt; &quot;\\nBang cuu chuong\\n&quot;; for (i = 1; i &lt;= 10; i++) { cout &lt;&lt; &quot;Bang nhan &quot; &lt;&lt; i &lt;&lt; endl; for (j = 0; j &lt;= 10; j++) { s = i * j; cout &lt;&lt; i &lt;&lt; &quot; x &quot; &lt;&lt; j &lt;&lt; &quot; = &quot; &lt;&lt; s &lt;&lt; endl; } } return 0; }  Câu 8: Viết chương trình thực hiện: a. Nhập n &gt; 0.b. Liệt kê các số nguyên tố trong phạm vi từ 1 đến n.c. Đếm số lượng số nguyên tố trong phạm vi từ 1 đến n.d. Tính tổng các số nguyên tố trong phạm vi từ 1 đến n. Câu 9: Viết chương trình thực hiện: a. Nhập n &gt; 0.b. Tính tổng các chữ số của n. Ví dụ: với n = 12537 thì tổng là 1 + 2 + 5 + 3 + 7 = 18. ","version":null,"tagName":"h3"},{"title":"Bài 4: Hàm​","type":1,"pageTitle":"Lập trình cơ bản","url":"/basic-programming/#bài-4-hàm","content":"Câu 1: Viết chương trình thực hiện các chức năng sau (dùng hàm): a. Nhập vào một số nguyên n (0 &lt; n &lt; 100).b. Kiểm tra n có phải là số nguyên tố không?c. Liệt kê các số nguyên tố trong phạm vi từ 1 đến n.d. Đếm số lượng số nguyên tố trong phạm vi từ 1 đến n.e. Tính tổng các số nguyên tố trong phạm vi từ 1 đến n.f. Tính trung bình cộng các số nguyên tố trong phạm vi từ 1 đến n. Câu 2: Viết chương trình theo hàm cho phép thực hiện chọn lựa công việc: a. Giải phương trình bậc 1 ax + b = 0.b. Kiểm tra một số nguyên có là số hoàn thiện không?c. Liệt kê các số hoàn thiện trong phạm vi từ 1 đến n (n do người dùng nhập).d. Tìm ước chung lớn nhất của hai số nguyên a, b nhập từ bàn phím.e. Thoát khỏi chương trình. Câu 3: Viết chương trình nhập từ bàn phím 2 số a, b và một ký tự ch. Nếu: ch là &quot;+&quot; thì thực hiện phép tính a + b và in kết quả lên màn hình.ch là &quot;-&quot; thì thực hiện phép tính a - b và in kết quả lên màn hình.ch là &quot;&quot; thì thực hiện phép tính a b và in kết quả lên màn hình.ch là &quot;/&quot; thì thực hiện phép tính a / b và in kết quả lên màn hình. Câu 4: Viết chương trình tính tiền lương ngày cho công nhân, cho biết trước giờ vào ca, giờ ra ca của mỗi người. Giả sử: Tiền trả cho mỗi giờ trước 12 giờ là 6000 đồng và sau 12 giờ là 7500 đồng. Giờ vào ca sớm nhất là 6 giờ sáng và giờ ra ca trễ nhất là 18 giờ (Giờ sử dụng là giờ nguyên). Click to view full code ! #include &lt;iostream&gt; using namespace std; int salaryDay(int v, int r) { int s, n; if (r &lt; 0 || v &gt; 24) { cout &lt;&lt; &quot;Error. Enter again&quot; &lt;&lt; endl; } else { n = r - v; cout &lt;&lt; &quot;Total hour of day: &quot; &lt;&lt; n &lt;&lt; &quot;h&quot; &lt;&lt; endl; if (n &gt; 12) { s = n * 6000; s += (n - 12) * 7500; } else { s = n * 6000; } cout &lt;&lt; &quot;Today's salary: &quot; &lt;&lt; s &lt;&lt; &quot;d&quot; &lt;&lt; endl; } return s; } int main() { int n, r, v; cout &lt;&lt; &quot;Basic\\n ----------Hour in 6h---------\\n--------Hour out 18h-----------\\n&quot;; cout &lt;&lt; &quot;Enter hour in: &quot;; cin &gt;&gt; v; cout &lt;&lt; &quot;Enter hour out: &quot;; cin &gt;&gt; r; salaryDay(v, r); return 0; }  Câu 5: Viết chương trình sử dụng hàm để chuyển đổi số nguyên từ hệ thập phân sang hệ nhị phân. ","version":null,"tagName":"h3"},{"title":"Bài 5: Mảng - Array​","type":1,"pageTitle":"Lập trình cơ bản","url":"/basic-programming/#bài-5-mảng---array","content":"Câu 1: Thực hiện: a. Nhập mảng số nguyên gồm n phần tử (0 &lt; n &lt;= 10).b. Xuất mảng vừa nhập. Câu 2: Làm tiếp theo trong chương trình của câu 1 với các yêu cầu sau: a. Xuất các phần tử chia hết cho 3 có trong mảng.b. Đếm số lượng số dương có trong mảng.c. Tính tổng các số trong mảng.d. Tính trung bình cộng của mảng.e. Tính trung bình cộng các phần tử dương có trong mảng.f. Xuất các số nguyên tố có trong mảng.g. Đếm số lượng số nguyên tố có trong mảng.h. Tính tổng các số nguyên tố có trong mảng.j. Tính trung bình cộng các số nguyên tố có trong mảng.k. Tìm phần tử dương đầu tiên.l. Tìm phần tử dương cuối cùng.m. Tìm giá trị phần tử lớn nhất (nhỏ nhất) trong mảng. Câu 3: Viết chương trình thực hiện: a. Nhập vào mảng a gồm n phần tử, trong quá trình nhập kiểm tra các phần tử nhập vào không được trùng, nếu trùng thì thông báo và yêu cầu nhập lại.b. Xuất mảng.c. Xuất ra màn hình các phần tử là số chính phương nằm tại những vị trí lẻ trong mảng.d. Xuất ra vị trí của các phần tử có giá trị lớn nhất.e. Viết hàm tính tổng các phần tử nằm ở vị trí chẵn trong mảng.f. Viết hàm sắp xếp mảng theo thứ tự tăng dần. Click to view full code ! #include &lt;iostream&gt; #include &lt;cmath&gt; using namespace std; void nhapMang(int n, int a[]) { for (int i = 0; i &lt; n; i++) { cout &lt;&lt; &quot;a[&quot; &lt;&lt; i &lt;&lt; &quot;]: &quot;; cin &gt;&gt; a[i]; } } void mangChiaHetCho3(int n, int a[]) { cout &lt;&lt; &quot;Cac so chia het cho 3: &quot;; for (int i = 0; i &lt; n; i++) { if (a[i] % 3 == 0) { cout &lt;&lt; a[i] &lt;&lt; &quot; &quot;; } } cout &lt;&lt; endl; } int demSoDuong(int n, int a[]) { int cnt = 0; for (int i = 0; i &lt; n; i++) { if (a[i] &gt; 0) { cnt++; } } return cnt; } int tongMang(int n, int a[]) { int s = 0; for (int i = 0; i &lt; n; i++) { s += a[i]; } return s; } float trungBinhCong(int n, int a[]) { return static_cast&lt;float&gt;(tongMang(n, a)) / n; } float trungBinhCongSoDuong(int n, int a[]) { int s = 0, cnt = 0; for (int i = 0; i &lt; n; i++) { if (a[i] &gt; 0) { s += a[i]; cnt++; } } return (cnt &gt; 0) ? static_cast&lt;float&gt;(s) / cnt : 0; } bool ktnt(int n) { if (n &lt; 2) return false; for (int i = 2; i &lt;= sqrt(n); i++) { if (n % i == 0) return false; } return true; } void xuatSoNguyenTo(int n, int a[]) { cout &lt;&lt; &quot;Cac so nguyen to trong mang: &quot;; for (int i = 0; i &lt; n; i++) { if (ktnt(a[i])) { cout &lt;&lt; a[i] &lt;&lt; &quot; &quot;; } } cout &lt;&lt; endl; } int demSoNguyenTo(int n, int a[]) { int cnt = 0; for (int i = 0; i &lt; n; i++) { if (ktnt(a[i])) { cnt++; } } return cnt; } int tongSoNguyenTo(int n, int a[]) { int s = 0; for (int i = 0; i &lt; n; i++) { if (ktnt(a[i])) { s += a[i]; } } return s; } float tbcSoNguyenTo(int n, int a[]) { int cnt = demSoNguyenTo(n, a); return (cnt &gt; 0) ? static_cast&lt;float&gt;(tongSoNguyenTo(n, a)) / cnt : 0; } void ptuDuongDauTien(int n, int a[]) { cout &lt;&lt; &quot;Phan tu duong dau tien: &quot;; for (int i = 0; i &lt; n; i++) { if (a[i] &gt; 0) { cout &lt;&lt; a[i] &lt;&lt; endl; return; } } cout &lt;&lt; &quot;Khong co phan tu duong&quot; &lt;&lt; endl; } void ptuDuongCuoiCung(int n, int a[]) { cout &lt;&lt; &quot;Phan tu duong cuoi cung: &quot;; for (int i = n - 1; i &gt;= 0; i--) { if (a[i] &gt; 0) { cout &lt;&lt; a[i] &lt;&lt; endl; return; } } cout &lt;&lt; &quot;Khong co phan tu duong&quot; &lt;&lt; endl; } int Max(int n, int a[]) { int max = a[0]; for (int i = 1; i &lt; n; i++) { if (a[i] &gt; max) { max = a[i]; } } return max; } int Min(int n, int a[]) { int min = a[0]; for (int i = 1; i &lt; n; i++) { if (a[i] &lt; min) { min = a[i]; } } return min; } int main() { int n, a[10]; do { cout &lt;&lt; &quot;Enter N (1 &lt;= N &lt;= 10): &quot;; cin &gt;&gt; n; if (n &lt;= 0 || n &gt; 10) { cout &lt;&lt; &quot;Nhap sai, vui long nhap lai.&quot; &lt;&lt; endl; } } while (n &lt;= 0 || n &gt; 10); nhapMang(n, a); mangChiaHetCho3(n, a); cout &lt;&lt; &quot;So cac phan tu duong: &quot; &lt;&lt; demSoDuong(n, a) &lt;&lt; endl; cout &lt;&lt; &quot;Trung binh cong cua mang: &quot; &lt;&lt; trungBinhCong(n, a) &lt;&lt; endl; cout &lt;&lt; &quot;Trung binh cong cac phan tu duong: &quot; &lt;&lt; trungBinhCongSoDuong(n, a) &lt;&lt; endl; xuatSoNguyenTo(n, a); cout &lt;&lt; &quot;So cac phan tu nguyen to: &quot; &lt;&lt; demSoNguyenTo(n, a) &lt;&lt; endl; cout &lt;&lt; &quot;Tong cac so nguyen to: &quot; &lt;&lt; tongSoNguyenTo(n, a) &lt;&lt; endl; cout &lt;&lt; &quot;Trung binh cong cac so nguyen to: &quot; &lt;&lt; tbcSoNguyenTo(n, a) &lt;&lt; endl; ptuDuongDauTien(n, a); ptuDuongCuoiCung(n, a); cout &lt;&lt; &quot;Phan tu lon nhat: &quot; &lt;&lt; Max(n, a) &lt;&lt; endl; cout &lt;&lt; &quot;Phan tu nho nhat: &quot; &lt;&lt; Min(n, a) &lt;&lt; endl; return 0; }  ","version":null,"tagName":"h3"},{"title":"Bài 6: Kiểu dữ liệu cấu trúc - struct​","type":1,"pageTitle":"Lập trình cơ bản","url":"/basic-programming/#bài-6-kiểu-dữ-liệu-cấu-trúc---struct","content":"Câu 1: Định nghĩa kiểu dữ liệu phần số gồm số và màu số. Viết chương trình thực hiện: a. Nhập 1 phần số.b. Xuất phần số.c. Rút gọn phần số.d. Tính tổng 2 phần số.e. So sánh 2 phần số. Câu 2: Làm tiếp câu 1, cài đặt các hàm sau: a. Nhập vào dãy phần số. b. Xuất dãy phần số. c. Tính tổng dãy. d. Tìm phần số lớn nhất. e. Sắp xếp dãy phần số tăng dần. Câu 3: Viết hàm nhập dữ liệu cho một sinh viên, thông tin về sinh viên gồm: a. Mã sinh viên (chuỗi 10 ký tự).b. Tên (là chuỗi tối đa 10 ký tự).c. Ngày tháng năm sinh (theo kiểu int, ví dụ: ngày/tháng/năm).d. Giới tính (Nam hoặc Nữ).e. Lớp (chuỗi 7 ký tự, trong đó 2 ký tự là năm vào học, 1 ký tự tiếp theo là bậc học (D: Đại học, C: Cao đẳng), 2 ký tự tiếp theo là ngành học (TH: Tin học, KT: Kế toán, QT: Quản trị, ĐT: Điện tử, DT: Điện thoại, ...)).f. Điểm toàn, lý, tin (Kiểu số thực). ","version":null,"tagName":"h3"},{"title":"Clean Code concepts adapted for .NET/.NET Core","type":0,"sectionRef":"#","url":"/2024/1/9/Clean-code","content":"","keywords":"","version":null},{"title":"Naming​","type":1,"pageTitle":"Clean Code concepts adapted for .NET/.NET Core","url":"/2024/1/9/Clean-code#naming","content":"Avoid using bad names A good name allows the code to be used by many developers. The name should reflect what it does and give context. Bad: int d;  Good: int daySinceModification;  Avoid Misleading Names Name the variable to reflect what it is used for. Bad: var dataFromDb = db.GetFromService().ToList();  Good: var listOfEmployee = _employeeService.GetEmployees().ToList();  Avoid Hungarian notation Hungarian Notation restates the type which is already present in the declaration. This is pointless since modern IDEs will identify the type. Bad: int iCounter; string strFullName; DateTime dModifiedDate;  Good: int counter; string fullName; DateTime modifiedDate;  Hungarian Notation should also not be used in paramaters. Bad: public bool IsShopOpen(string pDay, int pAmount) { // some logic }  Good: public bool IsShopOpen(string day, int amount) { // some logic }  Use consistent capitalization Capitalization tells you a lot about your variables, functions, etc. These rules are subjective, so your team can choose whatever they want. The point is, no matter what you all choose, just be consistent. Bad: const int DAYS_IN_WEEK = 7; const int daysInMonth = 30; var songs = new List&lt;string&gt; { 'Back In Black', 'Stairway to Heaven', 'Hey Jude' }; var Artists = new List&lt;string&gt; { 'ACDC', 'Led Zeppelin', 'The Beatles' }; bool EraseDatabase() {} bool Restore_database() {} class animal {} class Alpaca {}  Good: const int DaysInWeek = 7; const int DaysInMonth = 30; var songs = new List&lt;string&gt; { 'Back In Black', 'Stairway to Heaven', 'Hey Jude' }; var artists = new List&lt;string&gt; { 'ACDC', 'Led Zeppelin', 'The Beatles' }; bool EraseDatabase() {} bool RestoreDatabase() {} class Animal {} class Alpaca {}  Use pronounceable names It will take time to investigate the meaning of the variables and functions when they are not pronounceable. Bad: public class Employee { public Datetime sWorkDate { get; set; } // what the heck is this public Datetime modTime { get; set; } // same here }  Good: public class Employee { public Datetime StartWorkingDate { get; set; } public Datetime ModificationTime { get; set; } }  Use Camelcase notation Use Camelcase Notation for variable and method paramaters. Bad: var employeephone; public double CalculateSalary(int workingdays, int workinghours) { // some logic }  Good: var employeePhone; public double CalculateSalary(int workingDays, int workingHours) { // some logic }  Use domain name People who read your code are also programmers. Naming things right will help everyone be on the same page. We don't want to take time to explain to everyone what a variable or function is for. Good public class SingleObject { // create an object of SingleObject private static SingleObject _instance = new SingleObject(); // make the constructor private so that this class cannot be instantiated private SingleObject() {} // get the only object available public static SingleObject GetInstance() { return _instance; } public string ShowMessage() { return &quot;Hello World!&quot;; } } public static void main(String[] args) { // illegal construct // var object = new SingleObject(); // Get the only object available var singletonObject = SingleObject.GetInstance(); // show the message singletonObject.ShowMessage(); }  ","version":null,"tagName":"h2"},{"title":"Variables​","type":1,"pageTitle":"Clean Code concepts adapted for .NET/.NET Core","url":"/2024/1/9/Clean-code#variables","content":"Avoid nesting too deeply and return early Too many if else statements can make the code hard to follow. Explicit is better than implicit. Bad: public bool IsShopOpen(string day) { if (!string.IsNullOrEmpty(day)) { day = day.ToLower(); if (day == &quot;friday&quot;) { return true; } else if (day == &quot;saturday&quot;) { return true; } else if (day == &quot;sunday&quot;) { return true; } else { return false; } } else { return false; } }  Good: public bool IsShopOpen(string day) { if (string.IsNullOrEmpty(day)) { return false; } var openingDays = new[] { &quot;friday&quot;, &quot;saturday&quot;, &quot;sunday&quot; }; return openingDays.Any(d =&gt; d == day.ToLower()); }  Bad: public long Fibonacci(int n) { if (n &lt; 50) { if (n != 0) { if (n != 1) { return Fibonacci(n - 1) + Fibonacci(n - 2); } else { return 1; } } else { return 0; } } else { throw new System.Exception(&quot;Not supported&quot;); } }  Good: public long Fibonacci(int n) { if (n == 0) { return 0; } if (n == 1) { return 1; } if (n &gt; 50) { throw new System.Exception(&quot;Not supported&quot;); } return Fibonacci(n - 1) + Fibonacci(n - 2); }  Avoid mental mapping Don’t force the reader of your code to translate what the variable means. Explicit is better than implicit. Bad: var l = new[] { &quot;Austin&quot;, &quot;New York&quot;, &quot;San Francisco&quot; }; for (var i = 0; i &lt; l.Count(); i++) { var li = l[i]; DoStuff(); DoSomeOtherStuff(); // ... // ... // ... // Wait, what is `li` for again? Dispatch(li); }  Good: var locations = new[] { &quot;Austin&quot;, &quot;New York&quot;, &quot;San Francisco&quot; }; foreach (var location in locations) { DoStuff(); DoSomeOtherStuff(); // ... // ... // ... Dispatch(location); }  Avoid magic string Magic strings are string values that are specified directly within application code that have an impact on the application’s behavior. Frequently, such strings will end up being duplicated within the system, and since they cannot automatically be updated using refactoring tools, they become a common source of bugs when changes are made to some strings but not others. Bad if (userRole == &quot;Admin&quot;) { // logic in here }  Good const string ADMIN_ROLE = &quot;Admin&quot; if (userRole == ADMIN_ROLE) { // logic in here }  Using this we only have to change in centralize place and others will adapt it. Don't add unneeded context If your class/object name tells you something, don't repeat that in your variable name. Bad: public class Car { public string CarMake { get; set; } public string CarModel { get; set; } public string CarColor { get; set; } //... }  Good: public class Car { public string Make { get; set; } public string Model { get; set; } public string Color { get; set; } //... }  Use meaningful and pronounceable variable names Bad: var ymdstr = DateTime.UtcNow.ToString(&quot;MMMM dd, yyyy&quot;);  Good: var currentDate = DateTime.UtcNow.ToString(&quot;MMMM dd, yyyy&quot;);  Use the same vocabulary for the same type of variable Bad: GetUserInfo(); GetUserData(); GetUserRecord(); GetUserProfile();  Good: GetUser();  Use searchable names (part 1) We will read more code than we will ever write. It's important that the code we do write is readable and searchable. By not naming variables that end up being meaningful for understanding our program, we hurt our readers. Make your names searchable. Bad: // What the heck is data for? var data = new { Name = &quot;John&quot;, Age = 42 }; var stream1 = new MemoryStream(); var ser1 = new DataContractJsonSerializer(typeof(object)); ser1.WriteObject(stream1, data); stream1.Position = 0; var sr1 = new StreamReader(stream1); Console.Write(&quot;JSON form of Data object: &quot;); Console.WriteLine(sr1.ReadToEnd());  Good: var person = new Person { Name = &quot;John&quot;, Age = 42 }; var stream2 = new MemoryStream(); var ser2 = new DataContractJsonSerializer(typeof(Person)); ser2.WriteObject(stream2, data); stream2.Position = 0; var sr2 = new StreamReader(stream2); Console.Write(&quot;JSON form of Data object: &quot;); Console.WriteLine(sr2.ReadToEnd());  Use searchable names (part 2) Bad: var data = new { Name = &quot;John&quot;, Age = 42, PersonAccess = 4}; // What the heck is 4 for? if (data.PersonAccess == 4) { // do edit ... }  Good: public enum PersonAccess : int { ACCESS_READ = 1, ACCESS_CREATE = 2, ACCESS_UPDATE = 4, ACCESS_DELETE = 8 } var person = new Person { Name = &quot;John&quot;, Age = 42, PersonAccess= PersonAccess.ACCESS_CREATE }; if (person.PersonAccess == PersonAccess.ACCESS_UPDATE) { // do edit ... }  Use explanatory variables Bad: const string Address = &quot;One Infinite Loop, Cupertino 95014&quot;; var cityZipCodeRegex = @&quot;/^[^,\\]+[,\\\\s]+(.+?)\\s*(\\d{5})?$/&quot;; var matches = Regex.Matches(Address, cityZipCodeRegex); if (matches[0].Success == true &amp;&amp; matches[1].Success == true) { SaveCityZipCode(matches[0].Value, matches[1].Value); }  Good: Decrease dependence on regex by naming subpatterns. const string Address = &quot;One Infinite Loop, Cupertino 95014&quot;; var cityZipCodeWithGroupRegex = @&quot;/^[^,\\]+[,\\\\s]+(?&lt;city&gt;.+?)\\s*(?&lt;zipCode&gt;\\d{5})?$/&quot;; var matchesWithGroup = Regex.Match(Address, cityZipCodeWithGroupRegex); var cityGroup = matchesWithGroup.Groups[&quot;city&quot;]; var zipCodeGroup = matchesWithGroup.Groups[&quot;zipCode&quot;]; if(cityGroup.Success == true &amp;&amp; zipCodeGroup.Success == true) { SaveCityZipCode(cityGroup.Value, zipCodeGroup.Value); }  Use default arguments instead of short circuiting or conditionals Not good: This is not good because breweryName can be NULL. This opinion is more understandable than the previous version, but it better controls the value of the variable. public void CreateMicrobrewery(string name = null) { var breweryName = !string.IsNullOrEmpty(name) ? name : &quot;Hipster Brew Co.&quot;; // ... }  Good: public void CreateMicrobrewery(string breweryName = &quot;Hipster Brew Co.&quot;) { // ... }  ","version":null,"tagName":"h2"},{"title":"Functions​","type":1,"pageTitle":"Clean Code concepts adapted for .NET/.NET Core","url":"/2024/1/9/Clean-code#functions","content":"Avoid side effects A function produces a side effect if it does anything other than take a value in and return another value or values. A side effect could be writing to a file, modifying some global variable, or accidentally wiring all your money to a stranger. Now, you do need to have side effects in a program on occasion. Like the previous example, you might need to write to a file. What you want to do is to centralize where you are doing this. Don't have several functions and classes that write to a particular file. Have one service that does it. One and only one. The main point is to avoid common pitfalls like sharing state between objects without any structure, using mutable data types that can be written to by anything, and not centralizing where your side effects occur. If you can do this, you will be happier than the vast majority of other programmers. Bad: // Global variable referenced by following function. // If we had another function that used this name, now it'd be an array and it could break it. var name = &quot;Ryan McDermott&quot;; public void SplitAndEnrichFullName() { var temp = name.Split(&quot; &quot;); name = $&quot;His first name is {temp[0]}, and his last name is {temp[1]}&quot;; // side effect } SplitAndEnrichFullName(); Console.WriteLine(name); // His first name is Ryan, and his last name is McDermott  Good: public string SplitAndEnrichFullName(string name) { var temp = name.Split(&quot; &quot;); return $&quot;His first name is {temp[0]}, and his last name is {temp[1]}&quot;; } var name = &quot;Ryan McDermott&quot;; var fullName = SplitAndEnrichFullName(name); Console.WriteLine(name); // Ryan McDermott Console.WriteLine(fullName); // His first name is Ryan, and his last name is McDermott  Avoid negative conditionals Bad: public bool IsDOMNodeNotPresent(string node) { // ... } if (!IsDOMNodeNotPresent(node)) { // ... }  Good: public bool IsDOMNodePresent(string node) { // ... } if (IsDOMNodePresent(node)) { // ... }  Avoid conditionals This seems like an impossible task. Upon first hearing this, most people say, &quot;how am I supposed to do anything without an if statement?&quot; The answer is that you can use polymorphism to achieve the same task in many cases. The second question is usually, &quot;well that's great but why would I want to do that?&quot; The answer is a previous clean code concept we learned: a function should only do one thing. When you have classes and functions that have if statements, you are telling your user that your function does more than one thing. Remember, just do one thing. Bad: class Airplane { // ... public double GetCruisingAltitude() { switch (_type) { case '777': return GetMaxAltitude() - GetPassengerCount(); case 'Air Force One': return GetMaxAltitude(); case 'Cessna': return GetMaxAltitude() - GetFuelExpenditure(); } } }  Good: interface IAirplane { // ... double GetCruisingAltitude(); } class Boeing777 : IAirplane { // ... public double GetCruisingAltitude() { return GetMaxAltitude() - GetPassengerCount(); } } class AirForceOne : IAirplane { // ... public double GetCruisingAltitude() { return GetMaxAltitude(); } } class Cessna : IAirplane { // ... public double GetCruisingAltitude() { return GetMaxAltitude() - GetFuelExpenditure(); } }  Avoid type-checking (part 1) Bad: public Path TravelToTexas(object vehicle) { if (vehicle.GetType() == typeof(Bicycle)) { (vehicle as Bicycle).PeddleTo(new Location(&quot;texas&quot;)); } else if (vehicle.GetType() == typeof(Car)) { (vehicle as Car).DriveTo(new Location(&quot;texas&quot;)); } }  Good: public Path TravelToTexas(Traveler vehicle) { vehicle.TravelTo(new Location(&quot;texas&quot;)); }  or // pattern matching public Path TravelToTexas(object vehicle) { if (vehicle is Bicycle bicycle) { bicycle.PeddleTo(new Location(&quot;texas&quot;)); } else if (vehicle is Car car) { car.DriveTo(new Location(&quot;texas&quot;)); } }  Avoid type-checking (part 2) Bad: public int Combine(dynamic val1, dynamic val2) { int value; if (!int.TryParse(val1, out value) || !int.TryParse(val2, out value)) { throw new Exception('Must be of type Number'); } return val1 + val2; }  Good: public int Combine(int val1, int val2) { return val1 + val2; }  Avoid flags in method parameters A flag indicates that the method has more than one responsibility. It is best if the method only has a single responsibility. Split the method into two if a boolean parameter adds multiple responsibilities to the method. Bad: public void CreateFile(string name, bool temp = false) { if (temp) { Touch(&quot;./temp/&quot; + name); } else { Touch(name); } }  Good: public void CreateFile(string name) { Touch(name); } public void CreateTempFile(string name) { Touch(&quot;./temp/&quot; + name); }  Don't write to global functions Polluting globals is a bad practice in many languages because you could clash with another library and the user of your API would be none-the-wiser until they get an exception in production. Let's think about an example: what if you wanted to have configuration array. You could write global function like Config(), but it could clash with another library that tried to do the same thing. Bad: public Dictionary&lt;string, string&gt; Config() { return new Dictionary&lt;string,string&gt;(){ [&quot;foo&quot;] = &quot;bar&quot; }; }  Good: class Configuration { private Dictionary&lt;string, string&gt; _configuration; public Configuration(Dictionary&lt;string, string&gt; configuration) { _configuration = configuration; } public string[] Get(string key) { return _configuration.ContainsKey(key) ? _configuration[key] : null; } }  Load configuration and create instance of Configuration class var configuration = new Configuration(new Dictionary&lt;string, string&gt;() { [&quot;foo&quot;] = &quot;bar&quot; });  And now you must use instance of Configuration in your application. Don't use a Singleton pattern Singleton is an anti-pattern. Paraphrased from Brian Button: They are generally used as a global instance, why is that so bad? Because you hide the dependencies of your application in your code, instead of exposing them through the interfaces. Making something global to avoid passing it around is a code smell.They violate the single responsibility principle: by virtue of the fact that they control their own creation and lifecycle.They inherently cause code to be tightly coupled. This makes faking them out under test rather difficult in many cases.They carry state around for the lifetime of the application. Another hit to testing since you can end up with a situation where tests need to be ordered which is a big no for unit tests. Why? Because each unit test should be independent from the other. There is also very good thoughts by Misko Hevery about the root of problem. Bad: class DBConnection { private static DBConnection _instance; private DBConnection() { // ... } public static GetInstance() { if (_instance == null) { _instance = new DBConnection(); } return _instance; } // ... } var singleton = DBConnection.GetInstance();  Good: class DBConnection { public DBConnection(IOptions&lt;DbConnectionOption&gt; options) { // ... } // ... }  Create instance of DBConnection class and configure it with Option pattern. var options = &lt;resolve from IOC&gt;; var connection = new DBConnection(options);  And now you must use instance of DBConnection in your application. Function arguments (2 or fewer ideally) Limiting the amount of function parameters is incredibly important because it makes testing your function easier. Having more than three leads to a combinatorial explosion where you have to test tons of different cases with each separate argument. Zero arguments is the ideal case. One or two arguments is ok, and three should be avoided. Anything more than that should be consolidated. Usually, if you have more than two arguments then your function is trying to do too much. In cases where it's not, most of the time a higher-level object will suffice as an argument. Bad: public void CreateMenu(string title, string body, string buttonText, bool cancellable) { // ... }  Good: public class MenuConfig { public string Title { get; set; } public string Body { get; set; } public string ButtonText { get; set; } public bool Cancellable { get; set; } } var config = new MenuConfig { Title = &quot;Foo&quot;, Body = &quot;Bar&quot;, ButtonText = &quot;Baz&quot;, Cancellable = true }; public void CreateMenu(MenuConfig config) { // ... }  Functions should do one thing This is by far the most important rule in software engineering. When functions do more than one thing, they are harder to compose, test, and reason about. When you can isolate a function to just one action, they can be refactored easily and your code will read much cleaner. If you take nothing else away from this guide other than this, you'll be ahead of many developers. Bad: public void SendEmailToListOfClients(string[] clients) { foreach (var client in clients) { var clientRecord = db.Find(client); if (clientRecord.IsActive()) { Email(client); } } }  Good: public void SendEmailToListOfClients(string[] clients) { var activeClients = GetActiveClients(clients); // Do some logic } public List&lt;Client&gt; GetActiveClients(string[] clients) { return db.Find(clients).Where(s =&gt; s.Status == &quot;Active&quot;); }  Function names should say what they do Bad: public class Email { //... public void Handle() { SendMail(this._to, this._subject, this._body); } } var message = new Email(...); // What is this? A handle for the message? Are we writing to a file now? message.Handle();  Good: public class Email { //... public void Send() { SendMail(this._to, this._subject, this._body); } } var message = new Email(...); // Clear and obvious message.Send();  Functions should only be one level of abstraction Not finished yet When you have more than one level of abstraction your function is usually doing too much. Splitting up functions leads to reusability and easier testing. Bad: public string ParseBetterJSAlternative(string code) { var regexes = [ // ... ]; var statements = explode(&quot; &quot;, code); var tokens = new string[] {}; foreach (var regex in regexes) { foreach (var statement in statements) { // ... } } var ast = new string[] {}; foreach (var token in tokens) { // lex... } foreach (var node in ast) { // parse... } }  Bad too: We have carried out some of the functionality, but the ParseBetterJSAlternative() function is still very complex and not testable. public string Tokenize(string code) { var regexes = new string[] { // ... }; var statements = explode(&quot; &quot;, code); var tokens = new string[] {}; foreach (var regex in regexes) { foreach (var statement in statements) { tokens[] = /* ... */; } } return tokens; } public string Lexer(string[] tokens) { var ast = new string[] {}; foreach (var token in tokens) { ast[] = /* ... */; } return ast; } public string ParseBetterJSAlternative(string code) { var tokens = Tokenize(code); var ast = Lexer(tokens); foreach (var node in ast) { // parse... } }  Good: The best solution is move out the dependencies of ParseBetterJSAlternative() function. class Tokenizer { public string Tokenize(string code) { var regexes = new string[] { // ... }; var statements = explode(&quot; &quot;, code); var tokens = new string[] {}; foreach (var regex in regexes) { foreach (var statement in statements) { tokens[] = /* ... */; } } return tokens; } } class Lexer { public string Lexify(string[] tokens) { var ast = new[] {}; foreach (var token in tokens) { ast[] = /* ... */; } return ast; } } class BetterJSAlternative { private string _tokenizer; private string _lexer; public BetterJSAlternative(Tokenizer tokenizer, Lexer lexer) { _tokenizer = tokenizer; _lexer = lexer; } public string Parse(string code) { var tokens = _tokenizer.Tokenize(code); var ast = _lexer.Lexify(tokens); foreach (var node in ast) { // parse... } } }  Function callers and callees should be close If a function calls another, keep those functions vertically close in the source file. Ideally, keep the caller right above the callee. We tend to read code from top-to-bottom, like a newspaper. Because of this, make your code read that way. Bad: class PerformanceReview { private readonly Employee _employee; public PerformanceReview(Employee employee) { _employee = employee; } private IEnumerable&lt;PeersData&gt; LookupPeers() { return db.lookup(_employee, 'peers'); } private ManagerData LookupManager() { return db.lookup(_employee, 'manager'); } private IEnumerable&lt;PeerReviews&gt; GetPeerReviews() { var peers = LookupPeers(); // ... } public PerfReviewData PerfReview() { GetPeerReviews(); GetManagerReview(); GetSelfReview(); } public ManagerData GetManagerReview() { var manager = LookupManager(); } public EmployeeData GetSelfReview() { // ... } } var review = new PerformanceReview(employee); review.PerfReview();  Good: class PerformanceReview { private readonly Employee _employee; public PerformanceReview(Employee employee) { _employee = employee; } public PerfReviewData PerfReview() { GetPeerReviews(); GetManagerReview(); GetSelfReview(); } private IEnumerable&lt;PeerReviews&gt; GetPeerReviews() { var peers = LookupPeers(); // ... } private IEnumerable&lt;PeersData&gt; LookupPeers() { return db.lookup(_employee, 'peers'); } private ManagerData GetManagerReview() { var manager = LookupManager(); return manager; } private ManagerData LookupManager() { return db.lookup(_employee, 'manager'); } private EmployeeData GetSelfReview() { // ... } } var review = new PerformanceReview(employee); review.PerfReview();  Encapsulate conditionals Bad: if (article.state == &quot;published&quot;) { // ... }  Good: if (article.IsPublished()) { // ... }  Remove dead code Dead code is just as bad as duplicate code. There's no reason to keep it in your codebase. If it's not being called, get rid of it! It will still be safe in your version history if you still need it. Bad: public void OldRequestModule(string url) { // ... } public void NewRequestModule(string url) { // ... } var request = NewRequestModule(requestUrl); InventoryTracker(&quot;apples&quot;, request, &quot;www.inventory-awesome.io&quot;);  Good: public void RequestModule(string url) { // ... } var request = RequestModule(requestUrl); InventoryTracker(&quot;apples&quot;, request, &quot;www.inventory-awesome.io&quot;);  ","version":null,"tagName":"h2"},{"title":"Objects and Data Structures​","type":1,"pageTitle":"Clean Code concepts adapted for .NET/.NET Core","url":"/2024/1/9/Clean-code#objects-and-data-structures","content":"Use getters and setters In C# / VB.NET you can set public, protected and private keywords for methods. Using it, you can control properties modification on an object. When you want to do more beyond getting an object property, you don't have to look up and change every accessor in your codebase.Makes adding validation simple when doing a set.Encapsulates the internal representation.Easy to add logging and error handling when getting and setting.Inheriting this class, you can override default functionality.You can lazy load your object's properties, let's say getting it from a server. Additionally, this is part of Open/Closed principle, from object-oriented design principles. Bad: class BankAccount { public double Balance = 1000; } var bankAccount = new BankAccount(); // Fake buy shoes... bankAccount.Balance -= 100;  Good: class BankAccount { private double _balance = 0.0D; pubic double Balance { get { return _balance; } } public BankAccount(balance = 1000) { _balance = balance; } public void WithdrawBalance(int amount) { if (amount &gt; _balance) { throw new Exception('Amount greater than available balance.'); } _balance -= amount; } public void DepositBalance(int amount) { _balance += amount; } } var bankAccount = new BankAccount(); // Buy shoes... bankAccount.WithdrawBalance(price); // Get balance balance = bankAccount.Balance;  Make objects have private/protected members Bad: class Employee { public string Name { get; set; } public Employee(string name) { Name = name; } } var employee = new Employee(&quot;John Doe&quot;); Console.WriteLine(employee.Name); // Employee name: John Doe  Good: class Employee { public string Name { get; } public Employee(string name) { Name = name; } } var employee = new Employee(&quot;John Doe&quot;); Console.WriteLine(employee.Name); // Employee name: John Doe  ","version":null,"tagName":"h2"},{"title":"Classes​","type":1,"pageTitle":"Clean Code concepts adapted for .NET/.NET Core","url":"/2024/1/9/Clean-code#classes","content":"Use method chaining This pattern is very useful and commonly used in many libraries. It allows your code to be expressive, and less verbose. For that reason, use method chaining and take a look at how clean your code will be. Good: public static class ListExtensions { public static List&lt;T&gt; FluentAdd&lt;T&gt;(this List&lt;T&gt; list, T item) { list.Add(item); return list; } public static List&lt;T&gt; FluentClear&lt;T&gt;(this List&lt;T&gt; list) { list.Clear(); return list; } public static List&lt;T&gt; FluentForEach&lt;T&gt;(this List&lt;T&gt; list, Action&lt;T&gt; action) { list.ForEach(action); return list; } public static List&lt;T&gt; FluentInsert&lt;T&gt;(this List&lt;T&gt; list, int index, T item) { list.Insert(index, item); return list; } public static List&lt;T&gt; FluentRemoveAt&lt;T&gt;(this List&lt;T&gt; list, int index) { list.RemoveAt(index); return list; } public static List&lt;T&gt; FluentReverse&lt;T&gt;(this List&lt;T&gt; list) { list.Reverse(); return list; } } internal static void ListFluentExtensions() { var list = new List&lt;int&gt;() { 1, 2, 3, 4, 5 } .FluentAdd(1) .FluentInsert(0, 0) .FluentRemoveAt(1) .FluentReverse() .FluentForEach(value =&gt; value.WriteLine()) .FluentClear(); }  Prefer composition over inheritance As stated famously in Design Patterns by the Gang of Four, you should prefer composition over inheritance where you can. There are lots of good reasons to use inheritance and lots of good reasons to use composition. The main point for this maxim is that if your mind instinctively goes for inheritance, try to think if composition could model your problem better. In some cases it can. You might be wondering then, &quot;when should I use inheritance?&quot; It depends on your problem at hand, but this is a decent list of when inheritance makes more sense than composition: Your inheritance represents an &quot;is-a&quot; relationship and not a &quot;has-a&quot; relationship (Human-&gt;Animal vs. User-&gt;UserDetails).You can reuse code from the base classes (Humans can move like all animals).You want to make global changes to derived classes by changing a base class (Change the caloric expenditure of all animals when they move). Bad: class Employee { private string Name { get; set; } private string Email { get; set; } public Employee(string name, string email) { Name = name; Email = email; } // ... } // Bad because Employees &quot;have&quot; tax data. // EmployeeTaxData is not a type of Employee class EmployeeTaxData : Employee { private string Name { get; } private string Email { get; } public EmployeeTaxData(string name, string email, string ssn, string salary) { // ... } // ... }  Good: class EmployeeTaxData { public string Ssn { get; } public string Salary { get; } public EmployeeTaxData(string ssn, string salary) { Ssn = ssn; Salary = salary; } // ... } class Employee { public string Name { get; } public string Email { get; } public EmployeeTaxData TaxData { get; } public Employee(string name, string email) { Name = name; Email = email; } public void SetTax(string ssn, double salary) { TaxData = new EmployeeTaxData(ssn, salary); } // ... }  ","version":null,"tagName":"h2"},{"title":"SOLID​","type":1,"pageTitle":"Clean Code concepts adapted for .NET/.NET Core","url":"/2024/1/9/Clean-code#solid","content":"What is SOLID? SOLID is the mnemonic acronym introduced by Michael Feathers for the first five principles named by Robert Martin, which meant five basic principles of object-oriented programming and design. S: Single Responsibility Principle (SRP)O: Open/Closed Principle (OCP)L: Liskov Substitution Principle (LSP)I: Interface Segregation Principle (ISP)D: Dependency Inversion Principle (DIP) Single Responsibility Principle (SRP) As stated in Clean Code, &quot;There should never be more than one reason for a class to change&quot;. It's tempting to jam-pack a class with a lot of functionality, like when you can only take one suitcase on your flight. The issue with this is that your class won't be conceptually cohesive and it will give it many reasons to change. Minimizing the amount of times you need to change a class is important. It's important because if too much functionality is in one class and you modify a piece of it, it can be difficult to understand how that will affect other dependent modules in your codebase. Bad: class UserSettings { private User User; public UserSettings(User user) { User = user; } public void ChangeSettings(Settings settings) { if (verifyCredentials()) { // ... } } private bool VerifyCredentials() { // ... } }  Good: class UserAuth { private User User; public UserAuth(User user) { User = user; } public bool VerifyCredentials() { // ... } } class UserSettings { private User User; private UserAuth Auth; public UserSettings(User user) { User = user; Auth = new UserAuth(user); } public void ChangeSettings(Settings settings) { if (Auth.VerifyCredentials()) { // ... } } }  Open/Closed Principle (OCP) As stated by Bertrand Meyer, &quot;software entities (classes, modules, functions, etc.) should be open for extension, but closed for modification.&quot; What does that mean though? This principle basically states that you should allow users to add new functionalities without changing existing code. Bad: abstract class AdapterBase { protected string Name; public string GetName() { return Name; } } class AjaxAdapter : AdapterBase { public AjaxAdapter() { Name = &quot;ajaxAdapter&quot;; } } class NodeAdapter : AdapterBase { public NodeAdapter() { Name = &quot;nodeAdapter&quot;; } } class HttpRequester : AdapterBase { private readonly AdapterBase Adapter; public HttpRequester(AdapterBase adapter) { Adapter = adapter; } public bool Fetch(string url) { var adapterName = Adapter.GetName(); if (adapterName == &quot;ajaxAdapter&quot;) { return MakeAjaxCall(url); } else if (adapterName == &quot;httpNodeAdapter&quot;) { return MakeHttpCall(url); } } private bool MakeAjaxCall(string url) { // request and return promise } private bool MakeHttpCall(string url) { // request and return promise } }  Good: interface IAdapter { bool Request(string url); } class AjaxAdapter : IAdapter { public bool Request(string url) { // request and return promise } } class NodeAdapter : IAdapter { public bool Request(string url) { // request and return promise } } class HttpRequester { private readonly IAdapter Adapter; public HttpRequester(IAdapter adapter) { Adapter = adapter; } public bool Fetch(string url) { return Adapter.Request(url); } }  Liskov Substitution Principle (LSP) This is a scary term for a very simple concept. It's formally defined as &quot;If S is a subtype of T, then objects of type T may be replaced with objects of type S (i.e., objects of type S may substitute objects of type T) without altering any of the desirable properties of that program (correctness, task performed, etc.).&quot; That's an even scarier definition. The best explanation for this is if you have a parent class and a child class, then the base class and child class can be used interchangeably without getting incorrect results. This might still be confusing, so let's take a look at the classic Square-Rectangle example. Mathematically, a square is a rectangle, but if you model it using the &quot;is-a&quot; relationship via inheritance, you quickly get into trouble. Bad: class Rectangle { protected double Width = 0; protected double Height = 0; public Drawable Render(double area) { // ... } public void SetWidth(double width) { Width = width; } public void SetHeight(double height) { Height = height; } public double GetArea() { return Width * Height; } } class Square : Rectangle { public double SetWidth(double width) { Width = Height = width; } public double SetHeight(double height) { Width = Height = height; } } Drawable RenderLargeRectangles(Rectangle rectangles) { foreach (rectangle in rectangles) { rectangle.SetWidth(4); rectangle.SetHeight(5); var area = rectangle.GetArea(); // BAD: Will return 25 for Square. Should be 20. rectangle.Render(area); } } var rectangles = new[] { new Rectangle(), new Rectangle(), new Square() }; RenderLargeRectangles(rectangles);  Good: abstract class ShapeBase { protected double Width = 0; protected double Height = 0; abstract public double GetArea(); public Drawable Render(double area) { // ... } } class Rectangle : ShapeBase { public void SetWidth(double width) { Width = width; } public void SetHeight(double height) { Height = height; } public double GetArea() { return Width * Height; } } class Square : ShapeBase { private double Length = 0; public double SetLength(double length) { Length = length; } public double GetArea() { return Math.Pow(Length, 2); } } Drawable RenderLargeRectangles(Rectangle rectangles) { foreach (rectangle in rectangles) { if (rectangle is Square) { rectangle.SetLength(5); } else if (rectangle is Rectangle) { rectangle.SetWidth(4); rectangle.SetHeight(5); } var area = rectangle.GetArea(); rectangle.Render(area); } } var shapes = new[] { new Rectangle(), new Rectangle(), new Square() }; RenderLargeRectangles(shapes);  Interface Segregation Principle (ISP) ISP states that &quot;Clients should not be forced to depend upon interfaces that they do not use.&quot; A good example to look at that demonstrates this principle is for classes that require large settings objects. Not requiring clients to setup huge amounts of options is beneficial, because most of the time they won't need all of the settings. Making them optional helps prevent having a &quot;fat interface&quot;. Bad: public interface IEmployee { void Work(); void Eat(); } public class Human : IEmployee { public void Work() { // ....working } public void Eat() { // ...... eating in lunch break } } public class Robot : IEmployee { public void Work() { //.... working much more } public void Eat() { //.... robot can't eat, but it must implement this method } }  Good: Not every worker is an employee, but every employee is an worker. public interface IWorkable { void Work(); } public interface IFeedable { void Eat(); } public interface IEmployee : IFeedable, IWorkable { } public class Human : IEmployee { public void Work() { // ....working } public void Eat() { //.... eating in lunch break } } // robot can only work public class Robot : IWorkable { public void Work() { // ....working } }  Dependency Inversion Principle (DIP) This principle states two essential things: High-level modules should not depend on low-level modules. Both should depend on abstractions.Abstractions should not depend upon details. Details should depend on abstractions. This can be hard to understand at first, but if you've worked with .NET/.NET Core framework, you've seen an implementation of this principle in the form of Dependency Injection (DI). While they are not identical concepts, DIP keeps high-level modules from knowing the details of its low-level modules and setting them up. It can accomplish this through DI. A huge benefit of this is that it reduces the coupling between modules. Coupling is a very bad development pattern because it makes your code hard to refactor. Bad: public abstract class EmployeeBase { protected virtual void Work() { // ....working } } public class Human : EmployeeBase { public override void Work() { //.... working much more } } public class Robot : EmployeeBase { public override void Work() { //.... working much, much more } } public class Manager { private readonly Robot _robot; private readonly Human _human; public Manager(Robot robot, Human human) { _robot = robot; _human = human; } public void Manage() { _robot.Work(); _human.Work(); } }  Good: public interface IEmployee { void Work(); } public class Human : IEmployee { public void Work() { // ....working } } public class Robot : IEmployee { public void Work() { //.... working much more } } public class Manager { private readonly IEnumerable&lt;IEmployee&gt; _employees; public Manager(IEnumerable&lt;IEmployee&gt; employees) { _employees = employees; } public void Manage() { foreach (var employee in _employees) { _employee.Work(); } } }  Don’t repeat yourself (DRY) Try to observe the DRY principle. Do your absolute best to avoid duplicate code. Duplicate code is bad because it means that there's more than one place to alter something if you need to change some logic. Imagine if you run a restaurant and you keep track of your inventory: all your tomatoes, onions, garlic, spices, etc. If you have multiple lists that you keep this on, then all have to be updated when you serve a dish with tomatoes in them. If you only have one list, there's only one place to update! Oftentimes you have duplicate code because you have two or more slightly different things, that share a lot in common, but their differences force you to have two or more separate functions that do much of the same things. Removing duplicate code means creating an abstraction that can handle this set of different things with just one function/module/class. Getting the abstraction right is critical, that's why you should follow the SOLID principles laid out in the Classes section. Bad abstractions can be worse than duplicate code, so be careful! Having said this, if you can make a good abstraction, do it! Don't repeat yourself, otherwise you'll find yourself updating multiple places anytime you want to change one thing. Bad: public List&lt;EmployeeData&gt; ShowDeveloperList(Developers developers) { foreach (var developers in developer) { var expectedSalary = developer.CalculateExpectedSalary(); var experience = developer.GetExperience(); var githubLink = developer.GetGithubLink(); var data = new[] { expectedSalary, experience, githubLink }; Render(data); } } public List&lt;ManagerData&gt; ShowManagerList(Manager managers) { foreach (var manager in managers) { var expectedSalary = manager.CalculateExpectedSalary(); var experience = manager.GetExperience(); var githubLink = manager.GetGithubLink(); var data = new[] { expectedSalary, experience, githubLink }; render(data); } }  Good: public List&lt;EmployeeData&gt; ShowList(Employee employees) { foreach (var employee in employees) { var expectedSalary = employees.CalculateExpectedSalary(); var experience = employees.GetExperience(); var githubLink = employees.GetGithubLink(); var data = new[] { expectedSalary, experience, githubLink }; render(data); } }  Very good: It is better to use a compact version of the code. public List&lt;EmployeeData&gt; ShowList(Employee employees) { foreach (var employee in employees) { render(new[] { employee.CalculateExpectedSalary(), employee.GetExperience(), employee.GetGithubLink() }); } }  ","version":null,"tagName":"h2"},{"title":"Testing​","type":1,"pageTitle":"Clean Code concepts adapted for .NET/.NET Core","url":"/2024/1/9/Clean-code#testing","content":"Basic concept of testing Testing is more important than shipping. If you have no tests or an inadequate amount, then every time you ship code you won't be sure that you didn't break anything. Deciding on what constitutes an adequate amount is up to your team, but having 100% coverage (all statements and branches) is how you achieve very high confidence and developer peace of mind. This means that in addition to having a great testing framework, you also need to use a good coverage tool. There's no excuse to not write tests. There's plenty of good .NET test frameworks, so find one that your team prefers. When you find one that works for your team, then aim to always write tests for every new feature/module you introduce. If your preferred method is Test Driven Development (TDD), that is great, but the main point is to just make sure you are reaching your coverage goals before launching any feature, or refactoring an existing one. Single concept per test Ensures that your tests are laser focused and not testing miscellaenous (non-related) things, forces AAA patern used to make your codes more clean and readable. Bad:  public class MakeDotNetGreatAgainTests { [Fact] public void HandleDateBoundaries() { var date = new MyDateTime(&quot;1/1/2015&quot;); date.AddDays(30); Assert.Equal(&quot;1/31/2015&quot;, date); date = new MyDateTime(&quot;2/1/2016&quot;); date.AddDays(28); Assert.Equal(&quot;02/29/2016&quot;, date); date = new MyDateTime(&quot;2/1/2015&quot;); date.AddDays(28); Assert.Equal(&quot;03/01/2015&quot;, date); } }  Good:  public class MakeDotNetGreatAgainTests { [Fact] public void Handle30DayMonths() { // Arrange var date = new MyDateTime(&quot;1/1/2015&quot;); // Act date.AddDays(30); // Assert Assert.Equal(&quot;1/31/2015&quot;, date); } [Fact] public void HandleLeapYear() { // Arrange var date = new MyDateTime(&quot;2/1/2016&quot;); // Act date.AddDays(28); // Assert Assert.Equal(&quot;02/29/2016&quot;, date); } [Fact] public void HandleNonLeapYear() { // Arrange var date = new MyDateTime(&quot;2/1/2015&quot;); // Act date.AddDays(28); // Assert Assert.Equal(&quot;03/01/2015&quot;, date); } }  Soure https://www.codingblocks.net/podcast/how-to-write-amazing-unit-tests ","version":null,"tagName":"h2"},{"title":"Concurrency​","type":1,"pageTitle":"Clean Code concepts adapted for .NET/.NET Core","url":"/2024/1/9/Clean-code#concurrency","content":"Use Async/Await Summary of Asynchronous Programming Guidelines Name\tDescription\tExceptionsAvoid async void\tPrefer async Task methods over async void methods\tEvent handlers Async all the way\tDon't mix blocking and async code\tConsole main method (C# &lt;= 7.0) Configure context\tUse ConfigureAwait(false) when you can\tMethods that require con­text The Async Way of Doing Things To Do This ...\tInstead of This ...\tUse ThisRetrieve the result of a background task\tTask.Wait or Task.Result\tawait Wait for any task to complete\tTask.WaitAny\tawait Task.WhenAny Retrieve the results of multiple tasks\tTask.WaitAll\tawait Task.WhenAll Wait a period of time\tThread.Sleep\tawait Task.Delay Best practice The async/await is the best for IO bound tasks (networking communication, database communication, http request, etc.) but it is not good to apply on computational bound tasks (traverse on the huge list, render a hugge image, etc.). Because it will release the holding thread to the thread pool and CPU/cores available will not involve to process those tasks. Therefore, we should avoid using Async/Await for computional bound tasks. For dealing with computational bound tasks, prefer to use Task.Factory.CreateNew with TaskCreationOptions is LongRunning. It will start a new background thread to process a heavy computational bound task without release it back to the thread pool until the task being completed. Know Your Tools There's a lot to learn about async and await, and it's natural to get a little disoriented. Here's a quick reference of solutions to common problems. Solutions to Common Async Problems Problem\tSolutionCreate a task to execute code\tTask.Run or TaskFactory.StartNew (not the Task constructor or Task.Start) Create a task wrapper for an operation or event\tTaskFactory.FromAsync or TaskCompletionSource&lt;T&gt; Support cancellation\tCancellationTokenSource and CancellationToken Report progress\tIProgress&lt;T&gt; and Progress&lt;T&gt; Handle streams of data\tTPL Dataflow or Reactive Extensions Synchronize access to a shared resource\tSemaphoreSlim Asynchronously initialize a resource\tAsyncLazy&lt;T&gt; Async-ready producer/consumer structures\tTPL Dataflow or AsyncCollection&lt;T&gt; Read the Task-based Asynchronous Pattern (TAP) document. It is extremely well-written, and includes guidance on API design and the proper use of async/await (including cancellation and progress reporting). There are many new await-friendly techniques that should be used instead of the old blocking techniques. If you have any of these Old examples in your new async code, you're Doing It Wrong(TM): Old\tNew\tDescriptiontask.Wait\tawait task\tWait/await for a task to complete task.Result\tawait task\tGet the result of a completed task Task.WaitAny\tawait Task.WhenAny\tWait/await for one of a collection of tasks to complete Task.WaitAll\tawait Task.WhenAll\tWait/await for every one of a collection of tasks to complete Thread.Sleep\tawait Task.Delay\tWait/await for a period of time Task constructor\tTask.Run or TaskFactory.StartNew\tCreate a code-based task Source https://gist.github.com/jonlabelle/841146854b23b305b50fa5542f84b20c ","version":null,"tagName":"h2"},{"title":"Error Handling​","type":1,"pageTitle":"Clean Code concepts adapted for .NET/.NET Core","url":"/2024/1/9/Clean-code#error-handling","content":"Basic concept of error handling Thrown errors are a good thing! They mean the runtime has successfully identified when something in your program has gone wrong and it's letting you know by stopping function execution on the current stack, killing the process (in .NET/.NET Core), and notifying you in the console with a stack trace. Don't use 'throw ex' in catch block If you need to re-throw an exception after catching it, use just 'throw' By using this, you will save the stack trace. But in the bad option below, you will lost the stack trace. Bad: try { // Do something.. } catch (Exception ex) { // Any action something like roll-back or logging etc. throw ex; }  Good: try { // Do something.. } catch (Exception ex) { // Any action something like roll-back or logging etc. throw; }  Don't ignore caught errors Doing nothing with a caught error doesn't give you the ability to ever fix or react to said error. Throwing the error isn't much better as often times it can get lost in a sea of things printed to the console. If you wrap any bit of code in a try/catch it means you think an error may occur there and therefore you should have a plan, or create a code path, for when it occurs. Bad: try { FunctionThatMightThrow(); } catch (Exception ex) { // silent exception }  Good: try { FunctionThatMightThrow(); } catch (Exception error) { NotifyUserOfError(error); // Another option ReportErrorToService(error); }  Use multiple catch block instead of if conditions. If you need to take action according to type of the exception, you better use multiple catch block for exception handling. Bad: try { // Do something.. } catch (Exception ex) { if (ex is TaskCanceledException) { // Take action for TaskCanceledException } else if (ex is TaskSchedulerException) { // Take action for TaskSchedulerException } }  Good: try { // Do something.. } catch (TaskCanceledException ex) { // Take action for TaskCanceledException } catch (TaskSchedulerException ex) { // Take action for TaskSchedulerException }  Keep exception stack trace when rethrowing exceptions C# allows the exception to be rethrown in a catch block using the throw keyword. It is a bad practice to throw a caught exception using throw e;. This statement resets the stack trace. Instead use throw;. This will keep the stack trace and provide a deeper insight about the exception. Another option is to use a custom exception. Simply instantiate a new exception and set its inner exception property to the caught exception with throw new CustomException(&quot;some info&quot;, e);. Adding information to an exception is a good practice as it will help with debugging. However, if the objective is to log an exception then use throw; to pass the buck to the caller. Bad: try { FunctionThatMightThrow(); } catch (Exception ex) { logger.LogInfo(ex); throw ex; }  Good: try { FunctionThatMightThrow(); } catch (Exception error) { logger.LogInfo(error); throw; }  Good: try { FunctionThatMightThrow(); } catch (Exception error) { logger.LogInfo(error); throw new CustomException(error); }  ","version":null,"tagName":"h2"},{"title":"Formatting​","type":1,"pageTitle":"Clean Code concepts adapted for .NET/.NET Core","url":"/2024/1/9/Clean-code#formatting","content":"Uses .editorconfig file Bad: Has many code formatting styles in the project. For example, indent style is space and tab mixed in the project. Good: Define and maintain consistent code style in your codebase with the use of an .editorconfig file root = true [*] indent_style = space indent_size = 2 end_of_line = lf charset = utf-8 trim_trailing_whitespace = true insert_final_newline = true # C# files [*.cs] indent_size = 4 # New line preferences csharp_new_line_before_open_brace = all csharp_new_line_before_else = true csharp_new_line_before_catch = true csharp_new_line_before_finally = true csharp_new_line_before_members_in_object_initializers = true csharp_new_line_before_members_in_anonymous_types = true csharp_new_line_within_query_expression_clauses = true # Code files [*.{cs,csx,vb,vbx}] indent_size = 4 # Indentation preferences csharp_indent_block_contents = true csharp_indent_braces = false csharp_indent_case_contents = true csharp_indent_switch_labels = true csharp_indent_labels = one_less_than_current # avoid this. unless absolutely necessary dotnet_style_qualification_for_field = false:suggestion dotnet_style_qualification_for_property = false:suggestion dotnet_style_qualification_for_method = false:suggestion dotnet_style_qualification_for_event = false:suggestion # only use var when it's obvious what the variable type is # csharp_style_var_for_built_in_types = false:none # csharp_style_var_when_type_is_apparent = false:none # csharp_style_var_elsewhere = false:suggestion # use language keywords instead of BCL types dotnet_style_predefined_type_for_locals_parameters_members = true:suggestion dotnet_style_predefined_type_for_member_access = true:suggestion # name all constant fields using PascalCase dotnet_naming_rule.constant_fields_should_be_pascal_case.severity = suggestion dotnet_naming_rule.constant_fields_should_be_pascal_case.symbols = constant_fields dotnet_naming_rule.constant_fields_should_be_pascal_case.style = pascal_case_style dotnet_naming_symbols.constant_fields.applicable_kinds = field dotnet_naming_symbols.constant_fields.required_modifiers = const dotnet_naming_style.pascal_case_style.capitalization = pascal_case # static fields should have s_ prefix dotnet_naming_rule.static_fields_should_have_prefix.severity = suggestion dotnet_naming_rule.static_fields_should_have_prefix.symbols = static_fields dotnet_naming_rule.static_fields_should_have_prefix.style = static_prefix_style dotnet_naming_symbols.static_fields.applicable_kinds = field dotnet_naming_symbols.static_fields.required_modifiers = static dotnet_naming_style.static_prefix_style.required_prefix = s_ dotnet_naming_style.static_prefix_style.capitalization = camel_case # internal and private fields should be _camelCase dotnet_naming_rule.camel_case_for_private_internal_fields.severity = suggestion dotnet_naming_rule.camel_case_for_private_internal_fields.symbols = private_internal_fields dotnet_naming_rule.camel_case_for_private_internal_fields.style = camel_case_underscore_style dotnet_naming_symbols.private_internal_fields.applicable_kinds = field dotnet_naming_symbols.private_internal_fields.applicable_accessibilities = private, internal dotnet_naming_style.camel_case_underscore_style.required_prefix = _ dotnet_naming_style.camel_case_underscore_style.capitalization = camel_case # Code style defaults dotnet_sort_system_directives_first = true csharp_preserve_single_line_blocks = true csharp_preserve_single_line_statements = false # Expression-level preferences dotnet_style_object_initializer = true:suggestion dotnet_style_collection_initializer = true:suggestion dotnet_style_explicit_tuple_names = true:suggestion dotnet_style_coalesce_expression = true:suggestion dotnet_style_null_propagation = true:suggestion # Expression-bodied members csharp_style_expression_bodied_methods = false:none csharp_style_expression_bodied_constructors = false:none csharp_style_expression_bodied_operators = false:none csharp_style_expression_bodied_properties = true:none csharp_style_expression_bodied_indexers = true:none csharp_style_expression_bodied_accessors = true:none # Pattern matching csharp_style_pattern_matching_over_is_with_cast_check = true:suggestion csharp_style_pattern_matching_over_as_with_null_check = true:suggestion csharp_style_inlined_variable_declaration = true:suggestion # Null checking preferences csharp_style_throw_expression = true:suggestion csharp_style_conditional_delegate_call = true:suggestion # Space preferences csharp_space_after_cast = false csharp_space_after_colon_in_inheritance_clause = true csharp_space_after_comma = true csharp_space_after_dot = false csharp_space_after_keywords_in_control_flow_statements = true csharp_space_after_semicolon_in_for_statement = true csharp_space_around_binary_operators = before_and_after csharp_space_around_declaration_statements = do_not_ignore csharp_space_before_colon_in_inheritance_clause = true csharp_space_before_comma = false csharp_space_before_dot = false csharp_space_before_open_square_brackets = false csharp_space_before_semicolon_in_for_statement = false csharp_space_between_empty_square_brackets = false csharp_space_between_method_call_empty_parameter_list_parentheses = false csharp_space_between_method_call_name_and_opening_parenthesis = false csharp_space_between_method_call_parameter_list_parentheses = false csharp_space_between_method_declaration_empty_parameter_list_parentheses = false csharp_space_between_method_declaration_name_and_open_parenthesis = false csharp_space_between_method_declaration_parameter_list_parentheses = false csharp_space_between_parentheses = false csharp_space_between_square_brackets = false [*.{asm,inc}] indent_size = 8 # Xml project files [*.{csproj,vcxproj,vcxproj.filters,proj,nativeproj,locproj}] indent_size = 2 # Xml config files [*.{props,targets,config,nuspec}] indent_size = 2 [CMakeLists.txt] indent_size = 2 [*.cmd] indent_size = 2  ","version":null,"tagName":"h2"},{"title":"Comments​","type":1,"pageTitle":"Clean Code concepts adapted for .NET/.NET Core","url":"/2024/1/9/Clean-code#comments","content":"Avoid positional markers They usually just add noise. Let the functions and variable names along with the proper indentation and formatting give the visual structure to your code. Bad: //////////////////////////////////////////////////////////////////////////////// // Scope Model Instantiation //////////////////////////////////////////////////////////////////////////////// var model = new[] { menu: 'foo', nav: 'bar' }; //////////////////////////////////////////////////////////////////////////////// // Action setup //////////////////////////////////////////////////////////////////////////////// void Actions() { // ... };  Bad:  #region Scope Model Instantiation var model = { menu: 'foo', nav: 'bar' }; #endregion #region Action setup void Actions() { // ... }; #endregion  Good: var model = new[] { menu: 'foo', nav: 'bar' }; void Actions() { // ... };  Don't leave commented out code in your codebase Version control exists for a reason. Leave old code in your history. Bad: doStuff(); // doOtherStuff(); // doSomeMoreStuff(); // doSoMuchStuff();  Good: doStuff();  Don't have journal comments Remember, use version control! There's no need for dead code, commented code, and especially journal comments. Use git log to get history! Bad: /** * 2018-12-20: Removed monads, didn't understand them (RM) * 2017-10-01: Improved using special monads (JP) * 2016-02-03: Removed type-checking (LI) * 2015-03-14: Added combine with type-checking (JR) */ public int Combine(int a,int b) { return a + b; }  Good: public int Combine(int a,int b) { return a + b; }  Only comment things that have business logic complexity Comments are an apology, not a requirement. Good code mostly documents itself. Bad: public int HashIt(string data) { // The hash var hash = 0; // Length of string var length = data.length; // Loop through every character in data for (var i = 0; i &lt; length; i++) { // Get character code. const char = data.charCodeAt(i); // Make the hash hash = ((hash &lt;&lt; 5) - hash) + char; // Convert to 32-bit integer hash &amp;= hash; } }  Better but still Bad: public int HashIt(string data) { var hash = 0; var length = data.length; for (var i = 0; i &lt; length; i++) { const char = data.charCodeAt(i); hash = ((hash &lt;&lt; 5) - hash) + char; // Convert to 32-bit integer hash &amp;= hash; } }  If a comment explains WHAT the code is doing, it is probably a useless comment and can be implemented with a well named variable or function. The comment in the previous code could be replaced with a function named ConvertTo32bitInt so this comment is still useless. However it would be hard to express by code WHY the developer chose djb2 hash algorithm instead of sha-1 or another hash function. In that case a comment is acceptable. Good: public int Hash(string data) { var hash = 0; var length = data.length; for (var i = 0; i &lt; length; i++) { var character = data[i]; // use of djb2 hash algorithm as it has a good compromise // between speed and low collision with a very simple implementation hash = ((hash &lt;&lt; 5) - hash) + character; hash = ConvertTo32BitInt(hash); } return hash; } private int ConvertTo32BitInt(int value) { return value &amp; value; }  ","version":null,"tagName":"h2"}],"options":{"id":"default"}}