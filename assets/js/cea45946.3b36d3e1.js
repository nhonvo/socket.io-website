"use strict";(self.webpackChunksample_website=self.webpackChunksample_website||[]).push([[9516],{5680:(e,n,t)=>{t.d(n,{xA:()=>c,yg:()=>y});var i=t(6540);function a(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function r(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);n&&(i=i.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,i)}return t}function s(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?r(Object(t),!0).forEach((function(n){a(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):r(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function o(e,n){if(null==e)return{};var t,i,a=function(e,n){if(null==e)return{};var t,i,a={},r=Object.keys(e);for(i=0;i<r.length;i++)t=r[i],n.indexOf(t)>=0||(a[t]=e[t]);return a}(e,n);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(i=0;i<r.length;i++)t=r[i],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(a[t]=e[t])}return a}var l=i.createContext({}),p=function(e){var n=i.useContext(l),t=n;return e&&(t="function"==typeof e?e(n):s(s({},n),e)),t},c=function(e){var n=p(e.components);return i.createElement(l.Provider,{value:n},e.children)},g="mdxType",u={inlineCode:"code",wrapper:function(e){var n=e.children;return i.createElement(i.Fragment,{},n)}},d=i.forwardRef((function(e,n){var t=e.components,a=e.mdxType,r=e.originalType,l=e.parentName,c=o(e,["components","mdxType","originalType","parentName"]),g=p(t),d=a,y=g["".concat(l,".").concat(d)]||g[d]||u[d]||r;return t?i.createElement(y,s(s({ref:n},c),{},{components:t})):i.createElement(y,s({ref:n},c))}));function y(e,n){var t=arguments,a=n&&n.mdxType;if("string"==typeof e||a){var r=t.length,s=new Array(r);s[0]=d;var o={};for(var l in n)hasOwnProperty.call(n,l)&&(o[l]=n[l]);o.originalType=e,o[g]="string"==typeof e?e:a,s[1]=o;for(var p=2;p<r;p++)s[p]=t[p];return i.createElement.apply(null,s)}return i.createElement.apply(null,t)}d.displayName="MDXCreateElement"},699:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>l,default:()=>y,frontMatter:()=>o,metadata:()=>p,toc:()=>g});var i=t(8168),a=(t(6540),t(5680)),r=t(1653),s=t(6025);const o={title:"Using multiple nodes",sidebar_position:7,slug:"/using-multiple-nodes/"},l=void 0,p={unversionedId:"categories/Server/using-multiple-nodes",id:"categories/Server/using-multiple-nodes",title:"Using multiple nodes",description:"When deploying multiple Socket.IO servers, there are two things to take care of:",source:"@site/docs/categories/02-Server/using-multiple-nodes.md",sourceDirName:"categories/02-Server",slug:"/using-multiple-nodes/",permalink:"/socket.io-website/docs/v4/using-multiple-nodes/",draft:!1,editUrl:"https://github.com/socketio/socket.io-website/edit/main/docs/categories/02-Server/using-multiple-nodes.md",tags:[],version:"current",lastUpdatedAt:1711351980,formattedLastUpdatedAt:"Mar 25, 2024",sidebarPosition:7,frontMatter:{title:"Using multiple nodes",sidebar_position:7,slug:"/using-multiple-nodes/"},sidebar:"sidebar",previous:{title:"Behind a reverse proxy",permalink:"/socket.io-website/docs/v4/reverse-proxy/"},next:{title:"Handling CORS",permalink:"/socket.io-website/docs/v4/handling-cors/"}},c={},g=[{value:"Sticky load balancing",id:"sticky-load-balancing",level:2},{value:"Why is sticky-session required",id:"why-is-sticky-session-required",level:3},{value:"Enabling sticky-session",id:"enabling-sticky-session",level:3},{value:"nginx configuration",id:"nginx-configuration",level:3},{value:"nginx Ingress (Kubernetes)",id:"nginx-ingress-kubernetes",level:3},{value:"Apache HTTPD configuration",id:"apache-httpd-configuration",level:3},{value:"HAProxy configuration",id:"haproxy-configuration",level:3},{value:"Traefik",id:"traefik",level:3},{value:"Using Node.js Cluster",id:"using-nodejs-cluster",level:3},{value:"Passing events between nodes",id:"passing-events-between-nodes",level:2}],u={toc:g},d="wrapper";function y(e){let{components:n,...t}=e;return(0,a.yg)(d,(0,i.A)({},u,t,{components:n,mdxType:"MDXLayout"}),(0,a.yg)("p",null,"When deploying multiple Socket.IO servers, there are two things to take care of:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"enabling sticky session, if HTTP long-polling is enabled (which is the default): see ",(0,a.yg)("a",{parentName:"li",href:"#enabling-sticky-session"},"below")),(0,a.yg)("li",{parentName:"ul"},"using a compatible adapter, see ",(0,a.yg)("a",{parentName:"li",href:"/socket.io-website/docs/v4/adapter/"},"here"))),(0,a.yg)("h2",{id:"sticky-load-balancing"},"Sticky load balancing"),(0,a.yg)("p",null,"If you plan to distribute the load of connections among different processes or machines, you have to make sure that all requests associated with a particular session ID reach the process that originated them."),(0,a.yg)("h3",{id:"why-is-sticky-session-required"},"Why is sticky-session required"),(0,a.yg)("p",null,"This is because the HTTP long-polling transport sends multiple HTTP requests during the lifetime of the Socket.IO session."),(0,a.yg)("p",null,"In fact, Socket.IO could technically work without sticky sessions, with the following synchronization (in dashed lines):"),(0,a.yg)(r.A,{alt:"Using multiple nodes without sticky sessions",sources:{light:(0,s.A)("/images/mutiple-nodes-no-sticky.png"),dark:(0,s.A)("/images/multiple-nodes-no-sticky-dark.png")},mdxType:"ThemedImage"}),(0,a.yg)("p",null,"While obviously possible to implement, we think that this synchronization process between the Socket.IO servers would result in a big performance hit for your application."),(0,a.yg)("p",null,"Remarks:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},'without enabling sticky-session, you will experience HTTP 400 errors due to "Session ID unknown"'),(0,a.yg)("li",{parentName:"ul"},"the WebSocket transport does not have this limitation, since it relies on a single TCP connection for the whole session. Which means that if you disable the HTTP long-polling transport (which is a perfectly valid choice in 2021), you won't need sticky sessions:")),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-js"},'const socket = io("https://io.yourhost.com", {\n  // WARNING: in that case, there is no fallback to long-polling\n  transports: [ "websocket" ] // or [ "websocket", "polling" ] (the order matters)\n});\n')),(0,a.yg)("p",null,"Documentation: ",(0,a.yg)("a",{parentName:"p",href:"/socket.io-website/docs/v4/client-options/#transports"},(0,a.yg)("inlineCode",{parentName:"a"},"transports"))),(0,a.yg)("h3",{id:"enabling-sticky-session"},"Enabling sticky-session"),(0,a.yg)("p",null,"To achieve sticky-session, there are two main solutions:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"routing clients based on a cookie (recommended solution)"),(0,a.yg)("li",{parentName:"ul"},"routing clients based on their originating address")),(0,a.yg)("p",null,"You will find below some examples with common load-balancing solutions:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("a",{parentName:"li",href:"#nginx-configuration"},"nginx")," (IP-based)"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("a",{parentName:"li",href:"#nginx-ingress-kubernetes"},"nginx Ingress (Kubernetes)")," (IP-based)"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("a",{parentName:"li",href:"#apache-httpd-configuration"},"Apache HTTPD")," (cookie-based)"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("a",{parentName:"li",href:"#haproxy-configuration"},"HAProxy")," (cookie-based)"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("a",{parentName:"li",href:"#traefik"},"Traefik")," (cookie-based)"),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("a",{parentName:"li",href:"#using-nodejs-cluster"},"Node.js ",(0,a.yg)("inlineCode",{parentName:"a"},"cluster")," module"))),(0,a.yg)("p",null,"For other platforms, please refer to the relevant documentation:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},"Kubernetes: ",(0,a.yg)("a",{parentName:"li",href:"https://kubernetes.github.io/ingress-nginx/examples/affinity/cookie/"},"https://kubernetes.github.io/ingress-nginx/examples/affinity/cookie/")),(0,a.yg)("li",{parentName:"ul"},"AWS (Application Load Balancers): ",(0,a.yg)("a",{parentName:"li",href:"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/sticky-sessions.html"},"https://docs.aws.amazon.com/elasticloadbalancing/latest/application/sticky-sessions.html")),(0,a.yg)("li",{parentName:"ul"},"GCP: ",(0,a.yg)("a",{parentName:"li",href:"https://cloud.google.com/load-balancing/docs/backend-service#session_affinity"},"https://cloud.google.com/load-balancing/docs/backend-service#session_affinity")),(0,a.yg)("li",{parentName:"ul"},"Heroku: ",(0,a.yg)("a",{parentName:"li",href:"https://devcenter.heroku.com/articles/session-affinity"},"https://devcenter.heroku.com/articles/session-affinity"))),(0,a.yg)("p",null,(0,a.yg)("strong",{parentName:"p"},"Important note"),": if you are in a CORS situation (the front domain is different from the server domain) and session affinity is achieved with a cookie, you need to allow credentials:"),(0,a.yg)("p",null,(0,a.yg)("em",{parentName:"p"},"Server")),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-js"},'const io = require("socket.io")(httpServer, {\n  cors: {\n    origin: "https://front-domain.com",\n    methods: ["GET", "POST"],\n    credentials: true\n  }\n});\n')),(0,a.yg)("p",null,(0,a.yg)("em",{parentName:"p"},"Client")),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-js"},'const io = require("socket.io-client");\nconst socket = io("https://server-domain.com", {\n  withCredentials: true\n});\n')),(0,a.yg)("p",null,'Without it, the cookie will not be sent by the browser and you will experience HTTP 400 "Session ID unknown" responses. More information ',(0,a.yg)("a",{parentName:"p",href:"https://developer.mozilla.org/en-US/docs/Web/API/XMLHttpRequest/withCredentials"},"here"),"."),(0,a.yg)("h3",{id:"nginx-configuration"},"nginx configuration"),(0,a.yg)("p",null,"Within the ",(0,a.yg)("inlineCode",{parentName:"p"},"http { }")," section of your ",(0,a.yg)("inlineCode",{parentName:"p"},"nginx.conf")," file, you can declare a ",(0,a.yg)("inlineCode",{parentName:"p"},"upstream")," section with a list of Socket.IO process you want to balance load between:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-nginx"},'http {\n  server {\n    listen 3000;\n    server_name io.yourhost.com;\n\n    location / {\n      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n      proxy_set_header Host $host;\n\n      proxy_pass http://nodes;\n\n      # enable WebSockets\n      proxy_http_version 1.1;\n      proxy_set_header Upgrade $http_upgrade;\n      proxy_set_header Connection "upgrade";\n    }\n  }\n\n  upstream nodes {\n    # enable sticky session with either "hash" (uses the complete IP address)\n    hash $remote_addr consistent;\n    # or "ip_hash" (uses the first three octets of the client IPv4 address, or the entire IPv6 address)\n    # ip_hash;\n    # or "sticky" (needs commercial subscription)\n    # sticky cookie srv_id expires=1h domain=.example.com path=/;\n\n    server app01:3000;\n    server app02:3000;\n    server app03:3000;\n  }\n}\n')),(0,a.yg)("p",null,"Notice the ",(0,a.yg)("inlineCode",{parentName:"p"},"hash")," instruction that indicates the connections will be sticky."),(0,a.yg)("p",null,"Make sure you also configure ",(0,a.yg)("inlineCode",{parentName:"p"},"worker_processes")," in the topmost level to indicate how many workers nginx should use. You might also want to look into tweaking the ",(0,a.yg)("inlineCode",{parentName:"p"},"worker_connections")," setting within the ",(0,a.yg)("inlineCode",{parentName:"p"},"events { }")," block."),(0,a.yg)("p",null,"Links:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("a",{parentName:"li",href:"https://github.com/socketio/socket.io/tree/main/examples/cluster-nginx"},"Example")),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("a",{parentName:"li",href:"http://nginx.org/en/docs/http/ngx_http_upstream_module.html#hash"},"nginx Documentation"))),(0,a.yg)("admonition",{type:"caution"},(0,a.yg)("p",{parentName:"admonition"},"The value of nginx's ",(0,a.yg)("a",{parentName:"p",href:"https://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_read_timeout"},(0,a.yg)("inlineCode",{parentName:"a"},"proxy_read_timeout"))," (60 seconds by default) must be bigger than Socket.IO's ",(0,a.yg)("a",{parentName:"p",href:"/socket.io-website/docs/v4/server-options/#pinginterval"},(0,a.yg)("inlineCode",{parentName:"a"},"pingInterval + pingTimeout")),' (45 seconds by default), else nginx will forcefully close the connection if no data is sent after the given delay and the client will get a "transport close" error.')),(0,a.yg)("h3",{id:"nginx-ingress-kubernetes"},"nginx Ingress (Kubernetes)"),(0,a.yg)("p",null,"Within the ",(0,a.yg)("inlineCode",{parentName:"p"},"annotations")," section of your Ingress configuration, you can declare an upstream hashing based on the client's IP address, so that the Ingress controller always assigns the requests from a given IP address to the same pod:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: your-ingress\n  namespace: your-namespace\n  annotations:\n    nginx.ingress.kubernetes.io/configuration-snippet: |\n      set $forwarded_client_ip "";\n      if ($http_x_forwarded_for ~ "^([^,]+)") {\n        set $forwarded_client_ip $1;\n      }\n      set $client_ip $remote_addr;\n      if ($forwarded_client_ip != "") {\n        set $client_ip $forwarded_client_ip;\n      }\n    nginx.ingress.kubernetes.io/upstream-hash-by: "$client_ip"\nspec:\n  ingressClassName: nginx\n  rules:\n    - host: io.yourhost.com\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: your-service\n                port:\n                  number: 80\n')),(0,a.yg)("p",null,"Notes:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},'nginx.ingress.kubernetes.io/upstream-hash-by: "$client_ip"'))),(0,a.yg)("p",null,"This annotation instructs the NGINX Ingress Controller to use the client's IP address for routing incoming traffic to a specific Pod in your Kubernetes cluster. This is crucial for maintaining sticky sessions."),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("inlineCode",{parentName:"li"},"nginx.ingress.kubernetes.io/configuration-snippet"))),(0,a.yg)("p",null,"This custom NGINX configuration snippet serves a dual purpose:"),(0,a.yg)("ol",null,(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("p",{parentName:"li"},"If the request passes through upstream reverse proxies or API gateways that append an ",(0,a.yg)("inlineCode",{parentName:"p"},"X-Forwarded-For")," header, this snippet extracts the first IP address from that header and uses it to update the $client_ip.")),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("p",{parentName:"li"},"In the absence of such proxies or gateways, the snippet simply uses the remote_addr, which is the IP address of the client directly connected to the ingress."))),(0,a.yg)("p",null,"This ensures that the correct client IP is used for the sticky session logic, enabled by the ",(0,a.yg)("inlineCode",{parentName:"p"},'nginx.ingress.kubernetes.io/upstream-hash-by: "$client_ip"')," annotation. The snippet is particularly important when your architecture includes upstream network components like reverse proxies or API gateways."),(0,a.yg)("p",null,"Links:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("a",{parentName:"li",href:"https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/#custom-nginx-upstream-hashing"},"Ingress Nginx Documentation")),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("a",{parentName:"li",href:"https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-Forwarded-For"},"X-Forwarded-For Header"))),(0,a.yg)("h3",{id:"apache-httpd-configuration"},"Apache HTTPD configuration"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-apache"},'Header add Set-Cookie "SERVERID=sticky.%{BALANCER_WORKER_ROUTE}e; path=/" env=BALANCER_ROUTE_CHANGED\n\n<Proxy "balancer://nodes_polling">\n    BalancerMember "http://app01:3000" route=app01\n    BalancerMember "http://app02:3000" route=app02\n    BalancerMember "http://app03:3000" route=app03\n    ProxySet stickysession=SERVERID\n</Proxy>\n\n<Proxy "balancer://nodes_ws">\n    BalancerMember "ws://app01:3000" route=app01\n    BalancerMember "ws://app02:3000" route=app02\n    BalancerMember "ws://app03:3000" route=app03\n    ProxySet stickysession=SERVERID\n</Proxy>\n\nRewriteEngine On\nRewriteCond %{HTTP:Upgrade} =websocket [NC]\nRewriteRule /(.*) balancer://nodes_ws/$1 [P,L]\nRewriteCond %{HTTP:Upgrade} !=websocket [NC]\nRewriteRule /(.*) balancer://nodes_polling/$1 [P,L]\n\n# must be bigger than pingInterval (25s by default) + pingTimeout (20s by default)\nProxyTimeout 60\n')),(0,a.yg)("p",null,"Links:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("a",{parentName:"li",href:"https://github.com/socketio/socket.io/tree/main/examples/cluster-httpd"},"Example")),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("a",{parentName:"li",href:"https://httpd.apache.org/docs/2.4/en/mod/mod_proxy.html#proxypass"},"Documentation"))),(0,a.yg)("h3",{id:"haproxy-configuration"},"HAProxy configuration"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre"},"# Reference: http://blog.haproxy.com/2012/11/07/websockets-load-balancing-with-haproxy/\n\nlisten chat\n  bind *:80\n  default_backend nodes\n\nbackend nodes\n  option httpchk HEAD /health\n  http-check expect status 200\n  cookie io prefix indirect nocache # using the `io` cookie set upon handshake\n  server app01 app01:3000 check cookie app01\n  server app02 app02:3000 check cookie app02\n  server app03 app03:3000 check cookie app03\n")),(0,a.yg)("p",null,"Links:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("a",{parentName:"li",href:"https://github.com/socketio/socket.io/tree/main/examples/cluster-haproxy"},"Example")),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("a",{parentName:"li",href:"http://cbonte.github.io/haproxy-dconv/2.4/configuration.html#cookie"},"Documentation"))),(0,a.yg)("h3",{id:"traefik"},"Traefik"),(0,a.yg)("p",null,"Using container labels:"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-yaml"},'# docker-compose.yml\nservices:\n  traefik:\n    image: traefik:2.4\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n    links:\n      - server\n\n  server:\n    image: my-image:latest\n    labels:\n      - "traefik.http.routers.my-service.rule=PathPrefix(`/`)"\n      - traefik.http.services.my-service.loadBalancer.sticky.cookie.name=server_id\n      - traefik.http.services.my-service.loadBalancer.sticky.cookie.httpOnly=true\n')),(0,a.yg)("p",null,"With the ",(0,a.yg)("a",{parentName:"p",href:"https://doc.traefik.io/traefik/v2.0/providers/file/"},"File provider"),":"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-yaml"},'## Dynamic configuration\nhttp:\n  services:\n    my-service:\n      rule: "PathPrefix(`/`)"\n      loadBalancer:\n        sticky:\n          cookie:\n            name: server_id\n            httpOnly: true\n')),(0,a.yg)("p",null,"Links:"),(0,a.yg)("ul",null,(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("a",{parentName:"li",href:"https://github.com/socketio/socket.io/tree/main/examples/cluster-traefik"},"Example")),(0,a.yg)("li",{parentName:"ul"},(0,a.yg)("a",{parentName:"li",href:"https://doc.traefik.io/traefik/v2.0/routing/services/#sticky-sessions"},"Documentation"))),(0,a.yg)("h3",{id:"using-nodejs-cluster"},"Using Node.js Cluster"),(0,a.yg)("p",null,"Just like nginx, Node.js comes with built-in clustering support through the ",(0,a.yg)("inlineCode",{parentName:"p"},"cluster")," module."),(0,a.yg)("p",null,"There are several solutions, depending on your use case:"),(0,a.yg)("table",null,(0,a.yg)("thead",{parentName:"table"},(0,a.yg)("tr",{parentName:"thead"},(0,a.yg)("th",{parentName:"tr",align:"center"},"NPM package"),(0,a.yg)("th",{parentName:"tr",align:null},"How it works"))),(0,a.yg)("tbody",{parentName:"table"},(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:"center"},(0,a.yg)("a",{parentName:"td",href:"https://github.com/darrachequesne/socket.io-sticky"},(0,a.yg)("inlineCode",{parentName:"a"},"@socket.io/sticky"))),(0,a.yg)("td",{parentName:"tr",align:null},"the routing is based on the ",(0,a.yg)("inlineCode",{parentName:"td"},"sid")," query parameter")),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:"center"},(0,a.yg)("a",{parentName:"td",href:"https://github.com/indutny/sticky-session"},(0,a.yg)("inlineCode",{parentName:"a"},"sticky-session"))),(0,a.yg)("td",{parentName:"tr",align:null},"the routing is based on ",(0,a.yg)("inlineCode",{parentName:"td"},"connection.remoteAddress"))),(0,a.yg)("tr",{parentName:"tbody"},(0,a.yg)("td",{parentName:"tr",align:"center"},(0,a.yg)("a",{parentName:"td",href:"https://github.com/wzrdtales/socket-io-sticky-session"},(0,a.yg)("inlineCode",{parentName:"a"},"socketio-sticky-session"))),(0,a.yg)("td",{parentName:"tr",align:null},"the routing based on the ",(0,a.yg)("inlineCode",{parentName:"td"},"x-forwarded-for")," header)")))),(0,a.yg)("p",null,"Example with ",(0,a.yg)("inlineCode",{parentName:"p"},"@socket.io/sticky"),":"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-js"},'const cluster = require("cluster");\nconst http = require("http");\nconst { Server } = require("socket.io");\nconst numCPUs = require("os").cpus().length;\nconst { setupMaster, setupWorker } = require("@socket.io/sticky");\nconst { createAdapter, setupPrimary } = require("@socket.io/cluster-adapter");\n\nif (cluster.isMaster) {\n  console.log(`Master ${process.pid} is running`);\n\n  const httpServer = http.createServer();\n\n  // setup sticky sessions\n  setupMaster(httpServer, {\n    loadBalancingMethod: "least-connection",\n  });\n\n  // setup connections between the workers\n  setupPrimary();\n\n  // needed for packets containing buffers (you can ignore it if you only send plaintext objects)\n  // Node.js < 16.0.0\n  cluster.setupMaster({\n    serialization: "advanced",\n  });\n  // Node.js > 16.0.0\n  // cluster.setupPrimary({\n  //   serialization: "advanced",\n  // });\n\n  httpServer.listen(3000);\n\n  for (let i = 0; i < numCPUs; i++) {\n    cluster.fork();\n  }\n\n  cluster.on("exit", (worker) => {\n    console.log(`Worker ${worker.process.pid} died`);\n    cluster.fork();\n  });\n} else {\n  console.log(`Worker ${process.pid} started`);\n\n  const httpServer = http.createServer();\n  const io = new Server(httpServer);\n\n  // use the cluster adapter\n  io.adapter(createAdapter());\n\n  // setup connection with the primary process\n  setupWorker(io);\n\n  io.on("connection", (socket) => {\n    /* ... */\n  });\n}\n')),(0,a.yg)("h2",{id:"passing-events-between-nodes"},"Passing events between nodes"),(0,a.yg)("p",null,"Now that you have multiple Socket.IO nodes accepting connections, if you want to broadcast events to all clients (or to the clients in a certain ",(0,a.yg)("a",{parentName:"p",href:"/socket.io-website/docs/v4/rooms/"},"room"),") you","\u2019","ll need some way of passing messages between processes or computers."),(0,a.yg)("p",null,"The interface in charge of routing messages is what we call the ",(0,a.yg)("a",{parentName:"p",href:"/socket.io-website/docs/v4/adapter/"},"Adapter"),"."))}y.isMDXComponent=!0}}]);